{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e452a6d-614a-43a1-8037-138959b41be4",
   "metadata": {},
   "source": [
    "# Batch Processing Experiment  \n",
    "\n",
    "Author - Ryan Folks  \n",
    "Purpose - To determine if batch processing is faster for ultralytics yolo models.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da9f0aa-4a47-4c1c-beac-71a3b08724af",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e5c6af5-ddf5-4055-92cb-06f9a44f72e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(\"/home/ryanf/Documents/GitHub/ChartExtractor/src\")\n",
    "\n",
    "# builtin imports\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from typing import List\n",
    "\n",
    "# internal imports\n",
    "from object_detection_models.ultralytics_yolov8 import UltralyticsYOLOv8\n",
    "from utilities.tiling import tile_image\n",
    "\n",
    "# external imports\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6b5b11a-c302-46dd-9530-c38089872b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_chart_images: Path = Path(\"..\") / \"..\" / \"data\" / \"chart_images\"\n",
    "path_to_digit_model: Path = Path(\"..\")/\"..\"/\"data\"/\"models\"/\"combined_digit_yolov11m.pt\"\n",
    "images_to_process: List[str] = [\n",
    "    path_to_chart_images/\"RC_0001_intraoperative.JPG\",\n",
    "    path_to_chart_images/\"RC_0002_intraoperative.JPG\",\n",
    "    path_to_chart_images/\"RC_0003_intraoperative.JPG\",\n",
    "    path_to_chart_images/\"RC_0004_intraoperative.JPG\",\n",
    "    path_to_chart_images/\"RC_0005_intraoperative.JPG\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d60ae5-c850-4877-8223-8bd60fc6533c",
   "metadata": {},
   "source": [
    "## Non-Batched Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e08803e9-9455-46e6-8aa4-0016fd0f9ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model: UltralyticsYOLOv8 = UltralyticsYOLOv8.from_weights_path(path_to_digit_model)\n",
    "images: List[Image.Image] = [Image.open(str(path)) for path in images_to_process]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7bb08b9-997d-46a3-b0ed-80ce8110f850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.6 s ± 148 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "\n",
    "for im in images:\n",
    "    size: int = min(im.size[0]//6, im.size[1]//6)\n",
    "    tiles: List[List[Image.Image]] = tile_image(im, size, size, 0.5, 0.5)\n",
    "    for row in tiles:\n",
    "        for tile in row:\n",
    "            model(tile, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dd4a51-487f-47ee-aab1-d285d5c488a8",
   "metadata": {},
   "source": [
    "## Batched Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acfcbb08-ef56-45a9-aeb3-a996c06281a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This module implements the `UltralyticsYOLOv8` wrapper class\n",
    "\n",
    "The `UltralyticsYOLOv8` class, which inherits from the `ObjectDetectionModel` interface,\n",
    "provides a wrapper for the YOLOv8 object detection model from the Ultralytics library.\n",
    "It enables you to use the YOLOv8 model within your program through the common interface defined\n",
    "in `object_detection_model.py`.\n",
    "\n",
    "Key functionalities include:\n",
    "    - Provides a common interface for detections (via the __call__ method).\n",
    "    - Loading the YOLOv8 model from a weights file path.\n",
    "    - Performing object detection on an image using the YOLOv8 model.\n",
    "    - Converting the YOLOv8 model's output to a list of Detection objects.\n",
    "\n",
    "These `Detection` objects encapsulate details about detected objects, including bounding boxes,\n",
    "confidence scores, and potentially keypoints (if available in the model's output).\n",
    "\n",
    "This approach simplifies the integration and usage of YOLOv8 within this program, promoting code\n",
    "modularity and reusability.\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "from utilities.detections import Detection\n",
    "from utilities.annotations import BoundingBox, Keypoint, Point\n",
    "from object_detection_models.object_detection_model import ObjectDetectionModel\n",
    "\n",
    "\n",
    "class UltralyticsYOLOv8(ObjectDetectionModel):\n",
    "    \"\"\"Provides a wrapper for the YOLOv8 object detection model from the Ultralytics library.\n",
    "\n",
    "    This class inherits from the `ObjectDetectionModel` interface, enabling us to use the YOLOv8\n",
    "    model within our program through a consistent interface.\n",
    "\n",
    "    Attributes:\n",
    "        model:\n",
    "            The underlying Ultralytics YOLOv8 model object.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model):\n",
    "        \"\"\"Initializes the UltralyticsYOLOv8 object.\n",
    "\n",
    "        Args:\n",
    "            model:\n",
    "                The Ultralytics class for the YOLOv8 model.\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "\n",
    "    @staticmethod\n",
    "    def from_weights_path(weights_path: Path) -> \"UltralyticsYOLOv8\":\n",
    "        \"\"\"Creates an UltralyticsYOLOv8 object from a path to the weights file.\n",
    "\n",
    "        Args:\n",
    "            weights_path (Path):\n",
    "                A path leading to the model's weights.pt file.\n",
    "\n",
    "        Returns (UltralyticsYOLOv8):\n",
    "            An UltralyticsYOLOv8 object.\n",
    "        \"\"\"\n",
    "        model = YOLO(str(weights_path))\n",
    "        return UltralyticsYOLOv8.from_model(model)\n",
    "\n",
    "    @staticmethod\n",
    "    def from_model(model) -> \"UltralyticsYOLOv8\":\n",
    "        \"\"\"Creates an UltralyticsYOLOv8 object from the Ultralytics model object.\n",
    "\n",
    "        Args:\n",
    "            model:\n",
    "                The Ultralytics class for the YOLOv8 model.\n",
    "        \"\"\"\n",
    "        return UltralyticsYOLOv8(model)\n",
    "\n",
    "    def __call__(self, image: Image.Image, **kwargs) -> List[Detection]:\n",
    "        \"\"\"Runs the model on a single image and returns a list of Detection objects.\n",
    "\n",
    "        Args:\n",
    "            `image` (Image.Image):\n",
    "                The image to detect on.\n",
    "            `kwargs`:\n",
    "                Any argument that Ultralytics Yolo model will take. Mostly\n",
    "                used for 'conf' and 'verbose'.\n",
    "        Returns:\n",
    "            A list of Detection objects.\n",
    "        \"\"\"\n",
    "        if isinstance(image, Image.Image):\n",
    "            image = [image]\n",
    "        results = self.model(image, **kwargs)\n",
    "        detections = [self.yolov8_results_to_detections(r) for r in results]\n",
    "        return detections\n",
    "\n",
    "    def yolov8_results_to_detections(self, results) -> List[Detection]:\n",
    "        \"\"\"Converts ultralytics' YOLOv8 model object's results to a list of Detection objects.\n",
    "\n",
    "        Args:\n",
    "            results:\n",
    "                List containing the output from a YOLOv8 model prediction. Refer to the YOLOv8\n",
    "                documentation for details on the output format.\n",
    "\n",
    "        Returns:\n",
    "            A list of Detection objects. Each Detection object contains information about a\n",
    "            detected object including its bounding box (category, coordinates), and confidence\n",
    "            score. Additionally, if keypoints are present in the results, they are added\n",
    "            to the Detection objects.\n",
    "\n",
    "        Raises:\n",
    "            Exception:\n",
    "                If an error occurs during processing of the results (e.g., keypoints are\n",
    "                not found).\n",
    "        \"\"\"\n",
    "        detections: List[Detection] = [\n",
    "            Detection(\n",
    "                annotation=BoundingBox(\n",
    "                    category=results[0].names[box_conf_cls[5]],\n",
    "                    left=box_conf_cls[0],\n",
    "                    top=box_conf_cls[1],\n",
    "                    right=box_conf_cls[2],\n",
    "                    bottom=box_conf_cls[3],\n",
    "                ),\n",
    "                confidence=box_conf_cls[4],\n",
    "            )\n",
    "            for box_conf_cls in results.boxes.data.tolist()\n",
    "        ]\n",
    "        try:\n",
    "            keypoints = results[0].keypoints.data.tolist()\n",
    "            detections = [\n",
    "                Detection(\n",
    "                    Keypoint(Point(*keypoints[ix][0]), d.annotation), d.confidence\n",
    "                )\n",
    "                for ix, d in enumerate(detections)\n",
    "            ]\n",
    "        except Exception:\n",
    "            pass\n",
    "        return detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5794e2c9-3f94-4848-942c-ee2a37803c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "model: UltralyticsYOLOv8 = UltralyticsYOLOv8.from_weights_path(path_to_digit_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2660bbf-27dd-471b-83e6-bdb5a67914aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.23 s ± 179 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "\n",
    "for im in images:\n",
    "    size: int = min(im.size[0]//6, im.size[1]//6)\n",
    "    tiles: List[List[Image.Image]] = tile_image(im, size, size, 0.5, 0.5)\n",
    "    for row in tiles:\n",
    "        model(row, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecda7053-44fd-4739-bdaf-35d4894da55e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
