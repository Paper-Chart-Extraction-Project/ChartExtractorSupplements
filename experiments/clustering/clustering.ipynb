{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering Experiment \n",
    "#### By: Charbel Marche\n",
    "\n",
    "We decided to individually tackle the problem using 1 method, and by the time we are all done we will be able to merge our techniques and select the optimal techinque. Currently we are determining only the indiviudal digits, but we need to recognize these as coherent numbers and be able to assign entries to numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register Images to Start\n",
    "\n",
    "To start, we need to register images using the `utilities/conversion/apply_homography_to_labels.ipynb` notebook. This should be run before running this notebook. This notebook is built on the assumption that the `data/registered_images` directory has been created and populated. Additionally it assumes that the `data/yolo_data.json` file is created. Both of these are created in the referenced notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install Packages\n",
    "\n",
    "These are the necessary packages to run the functions and scripts below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start By Loading YOLO Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start I want to bring in the YOLO formatted data for each sheet and I can additionally load the respective images. As mentioned above you must have ran the `utilities/conversion/apply_homography_to_labels.ipynb` notebook to generate this YOLO data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19 sheets in yolo_data.json\n"
     ]
    }
   ],
   "source": [
    "# Load yolo_data.json\n",
    "PATH_TO_YOLO_DATA = '../../data/yolo_data.json'\n",
    "PATH_TO_REGISTERED_IMAGES = '../../data/registered_images'\n",
    "UNIFIED_IMAGE_PATH = '../../data/unified_intraoperative_preoperative_flowsheet_v1_1_front.png'\n",
    "with open(PATH_TO_YOLO_DATA) as json_file:\n",
    "    yolo_data = json.load(json_file)\n",
    "\n",
    "# See how many intraoperative images are registered\n",
    "print(f\"Found {len(yolo_data)} sheets in yolo_data.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's select relevant bounding boxes from the blood pressure and HR zone. \n",
    "\n",
    "Start by defining functions to convert YOLO bounding box format to pixels (to see if the bounding box is within region of interest). Then create a function that allows you to select ROI and returns a list of bounding boxes within this ROI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def YOLO_to_pixels(x_center, y_center, width, height, image_width, image_height):\n",
    "    \"\"\"\n",
    "    Convert YOLO bounding box format to pixel coordinates\n",
    "\n",
    "    Args:\n",
    "        x_center: float, x center of the bounding box\n",
    "        y_center: float, y center of the bounding box\n",
    "        width: float, width of the bounding box\n",
    "        height: float, height of the bounding box\n",
    "        image_width: int, width of the image\n",
    "        image_height: int, height of the image\n",
    "\n",
    "    Returns:\n",
    "        A single tuple with the following values:\n",
    "            x_min: int, minimum x coordinate of the bounding box in pixels\n",
    "            y_min: int, minimum y coordinate of the bounding box in pixels\n",
    "            x_max: int, maximum x coordinate of the bounding box in pixels\n",
    "            y_max: int, maximum y coordinate of the bounding box in pixels\n",
    "    \"\"\"\n",
    "    x_min = int((float(x_center) * image_width) - (width * image_width) / 2)\n",
    "    y_min = int((float(y_center) * image_height) - (height * image_height) / 2)\n",
    "    x_max = int((float(x_center) * image_width) + (width * image_width) / 2)\n",
    "    y_max = int((float(y_center) * image_height) + (height * image_height) / 2)\n",
    "    return x_min, y_min, x_max, y_max\n",
    "\n",
    "# Function to determine whether a point is above or below the diagonal line\n",
    "def is_point_in_above(x_center, y_center, m, b):\n",
    "    \"\"\"\n",
    "    Determine if a point is above or below the diagonal line y = mx + b.\n",
    "    For our purposes we use it to check if a bounding box is in the top-right region -- meaning time labels.\n",
    "\n",
    "    Args:\n",
    "        x_center: float, x coordinate of the point\n",
    "        y_center: float, y coordinate of the point\n",
    "        m: float, slope of the diagonal line\n",
    "        b: float, intercept of the diagonal line\n",
    "    \n",
    "    Returns:\n",
    "        bool, True if the point is above the line, False otherwise\n",
    "    \"\"\"\n",
    "    # Calculate the y value on the line for the given x_center\n",
    "    y_line = m * x_center + b\n",
    "    return y_center > y_line\n",
    "\n",
    "\n",
    "\n",
    "def select_relevant_bounding_boxes(sheet_data: List[str], path_to_image: Path, show_images: bool = False) -> Tuple[List[str], List[str]]:\n",
    "    \"\"\"\n",
    "    Given sheet data for bounding boxes in YOLO format, display the image and allow the user to select a region of interest (ROI).\n",
    "    Identify bounding boxes that are within the selected region and draw rectangles around them. \n",
    "    Return the bounding boxes that are within the selected region split into two lists: time labels and numerical values.\n",
    "\n",
    "    Args:\n",
    "        sheet_data: List of bounding boxes in YOLO format.\n",
    "        path_to_image: Path to the image file.\n",
    "\n",
    "    Returns:\n",
    "        Tuple of Lists of string representations of bounding boxes that are within the selected region, in YOLO format.\n",
    "        The first list contains bounding boxes in the top-right region -- representing time labels.\n",
    "        The second list contains bounding boxes in the bottom-left region -- representing numerical values for mmHg and bpm.\n",
    "            (bounding_boxes_time, bounding_boxes_numbers)\n",
    "    \"\"\"\n",
    "    # Load the image\n",
    "    image = cv2.imread(path_to_image)\n",
    "\n",
    "    # Display the image and allow the user to select a ROI\n",
    "    resized_image = cv2.resize(image, (800, 600))\n",
    "    roi = cv2.selectROI(\"Select Region of Interest\", resized_image)\n",
    "    print(f\"ROI selected: {roi}\")\n",
    "\n",
    "    # Unpack ROI\n",
    "    x, y, w, h = roi\n",
    "    print(f\"Selected region: x={x}, y={y}, w={w}, h={h}\")\n",
    "\n",
    "    # Calculate the coordinates of the top-left and bottom-right corners of the selected region\n",
    "    x_top_left = x\n",
    "    y_top_left = y\n",
    "    x_bottom_right = x + w\n",
    "    y_bottom_right = y + h\n",
    "\n",
    "    # Draw the diagonal line of the selected region from top-left to bottom-right\n",
    "    cv2.line(resized_image, (x_top_left, y_top_left), (x_bottom_right, y_bottom_right), (0, 255, 0), 1)\n",
    "    # Calculate the slope (m) and intercept (b) of the diagonal line.\n",
    "    # This will allow us to determine if a bounding box is in the top-right region or bottom-left region\n",
    "    # Top-right region is where time labels are located\n",
    "    # Bottom-left region is where numerical values for mmHg and bpm are located\n",
    "    m = (y_bottom_right - y_top_left) / (x_bottom_right - x_top_left)\n",
    "    b = y_top_left - m * x_top_left\n",
    "\n",
    "    # List of bounding boxes in the top-right and bottom-left regions\n",
    "    bounding_boxes_time = []\n",
    "    bounding_boxes_numbers = []\n",
    "\n",
    "    # Process the bounding boxes\n",
    "    for bounding_box in sheet_data:\n",
    "        # Bounding boxes are in YOLO format; convert them to pixels\n",
    "        identifier, x_center, y_center, bb_width, bb_height = bounding_box.split(' ') # Identifier is the value in the bounding box, we don't need that here\n",
    "        x_min, y_min, x_max, y_max  = YOLO_to_pixels(float(x_center), float(y_center), float(bb_width), float(bb_height), 800, 600)\n",
    "        \n",
    "        # Check if the bounding box is within the selected region\n",
    "        if x_min >= x and y_min >= y and x_max <= x + w and y_max <= y + h:\n",
    "            # Calculate the center of the bounding box\n",
    "            x_center_bb = (x_min + x_max) / 2\n",
    "            y_center_bb = (y_min + y_max) / 2\n",
    "            \n",
    "            # If we want to generalize this function we can add the option to disregard the diagonal line\n",
    "\n",
    "            # Determine if the bounding box center is in the top-right region\n",
    "            if is_point_in_above(x_center_bb, y_center_bb, m, b):\n",
    "                # Bounding box is in the top-right region\n",
    "                cv2.rectangle(resized_image, (x_min, y_min), (x_max, y_max), (255, 255, 0), 1)\n",
    "                bounding_boxes_numbers.append(bounding_box)\n",
    "            else:\n",
    "                # Bounding box is in the bottom-left region\n",
    "                cv2.rectangle(resized_image, (x_min, y_min), (x_max, y_max), (255, 0, 255), 1)\n",
    "                bounding_boxes_time.append(bounding_box)\n",
    "\n",
    "    # Close all OpenCV windows, always do this or it will annoyingly not go away\n",
    "    # You can also manually quit out with ESC key.\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # If we are showing the images, display the image with the selected region and bounding boxes\n",
    "    # Bounding boxes in the top-right region (time) are in one color while those in the bottom left (numerical) are in another\n",
    "    if show_images:\n",
    "        # Display the image with the selected region and bounding boxes\n",
    "        resized_image = cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB)\n",
    "        resized_image = Image.fromarray(resized_image)\n",
    "        resized_image.show()\n",
    "\n",
    "    # Return a tuple of bounding boxes in the top-right and bottom-left regions\n",
    "    return (bounding_boxes_time, bounding_boxes_numbers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function for K-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_kmeans(bounding_boxes: List[str], number_of_clusters: int) -> List[int]:\n",
    "    \"\"\"\n",
    "    Cluster bounding boxes using K-Means clustering algorithm.\n",
    "\n",
    "    Args:\n",
    "        bounding_boxes: List of bounding boxes in YOLO format.\n",
    "        number_of_clusters: Number of clusters to use in K-Means clustering.\n",
    "\n",
    "    Returns:\n",
    "        List of cluster labels.\n",
    "    \"\"\"\n",
    "    # Convert to a NumPy array (using only x_center and y_center)\n",
    "    data = np.array([[float(box.split(' ')[1]), float(box.split(' ')[2])] for box in bounding_boxes])\n",
    "\n",
    "    # Apply K-Means\n",
    "    kmeans = KMeans(n_clusters=number_of_clusters, init='k-means++', n_init=10, max_iter=300, tol=1e-8, random_state=42)\n",
    "    kmeans.fit(data)\n",
    "\n",
    "    # Get cluster labels\n",
    "    labels = kmeans.predict(data)\n",
    "\n",
    "    return labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to create a result dictionary that we can save as a JSON file to analyze performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_result_dictionary(labels: List[str], bounding_boxes: List[str]) -> Dict[int, int]:\n",
    "    \"\"\"\n",
    "    Create a dictionary with cluster labels as keys and lists of bounding boxes as values.\n",
    "\n",
    "    Args:\n",
    "        labels: List of cluster labels.\n",
    "        bounding_boxes: List of bounding boxes in YOLO format.\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with cluster labels as keys and bounding box values as values.\n",
    "    \"\"\"\n",
    "    # Create a dictionary to store labelled elements\n",
    "    label_dict = {}\n",
    "\n",
    "    # Iterate over both lists\n",
    "    for label, element in zip(labels, bounding_boxes):\n",
    "        label = int(label)\n",
    "        element = str(element)\n",
    "        if label not in label_dict:\n",
    "            # Create a new list for this label if it doesn't exist\n",
    "            label_dict[label] = []\n",
    "        # Append the element to the corresponding label list\n",
    "        label_dict[label].append(element)\n",
    "\n",
    "    # Sort the lists in the dictionary by x_center\n",
    "    for key in label_dict:\n",
    "        label_dict[key] = sorted(label_dict[key], key=lambda x: float(x.split(' ')[1]))\n",
    "        label_dict[key] = [element.split(' ')[0] for element in label_dict[key]]\n",
    "        # Turn list of strings into a string\n",
    "        label_dict[key] = int(''.join(label_dict[key]))\n",
    "    \n",
    "    return label_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets use these functions to get the relevant bounding boxes for clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sheet: RC_0001_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images\\RC_0001_intraoperative.JPG\n",
      "ROI selected: (102, 221, 634, 203)\n",
      "Selected region: x=102, y=221, w=634, h=203\n",
      "Sheet: RC_0002_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images\\RC_0002_intraoperative.JPG\n",
      "ROI selected: (102, 220, 635, 204)\n",
      "Selected region: x=102, y=220, w=635, h=204\n",
      "Sheet: RC_0003_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images\\RC_0003_intraoperative.JPG\n",
      "ROI selected: (102, 220, 634, 204)\n",
      "Selected region: x=102, y=220, w=634, h=204\n",
      "Sheet: RC_0004_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images\\RC_0004_intraoperative.JPG\n",
      "ROI selected: (104, 222, 631, 201)\n",
      "Selected region: x=104, y=222, w=631, h=201\n",
      "Sheet: RC_0005_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images\\RC_0005_intraoperative.JPG\n",
      "ROI selected: (103, 221, 631, 203)\n",
      "Selected region: x=103, y=221, w=631, h=203\n",
      "Sheet: RC_0006_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images\\RC_0006_intraoperative.JPG\n",
      "ROI selected: (103, 221, 633, 203)\n",
      "Selected region: x=103, y=221, w=633, h=203\n",
      "Sheet: RC_0007_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images\\RC_0007_intraoperative.JPG\n",
      "ROI selected: (102, 220, 635, 205)\n",
      "Selected region: x=102, y=220, w=635, h=205\n",
      "Sheet: RC_0008_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images\\RC_0008_intraoperative.JPG\n",
      "ROI selected: (103, 220, 632, 203)\n",
      "Selected region: x=103, y=220, w=632, h=203\n",
      "Sheet: RC_0009_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images\\RC_0009_intraoperative.JPG\n",
      "ROI selected: (103, 221, 632, 204)\n",
      "Selected region: x=103, y=221, w=632, h=204\n",
      "Sheet: RC_0010_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images\\RC_0010_intraoperative.JPG\n",
      "ROI selected: (101, 219, 633, 204)\n",
      "Selected region: x=101, y=219, w=633, h=204\n",
      "Sheet: RC_0011_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images\\RC_0011_intraoperative.JPG\n",
      "ROI selected: (102, 219, 633, 205)\n",
      "Selected region: x=102, y=219, w=633, h=205\n",
      "Sheet: RC_0012_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images\\RC_0012_intraoperative.JPG\n",
      "ROI selected: (103, 220, 630, 205)\n",
      "Selected region: x=103, y=220, w=630, h=205\n",
      "Sheet: RC_0013_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images\\RC_0013_intraoperative.JPG\n",
      "ROI selected: (102, 220, 634, 202)\n",
      "Selected region: x=102, y=220, w=634, h=202\n",
      "Sheet: RC_0014_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images\\RC_0014_intraoperative.JPG\n",
      "ROI selected: (101, 221, 634, 204)\n",
      "Selected region: x=101, y=221, w=634, h=204\n",
      "Sheet: RC_0015_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images\\RC_0015_intraoperative.JPG\n",
      "ROI selected: (104, 221, 628, 204)\n",
      "Selected region: x=104, y=221, w=628, h=204\n",
      "Sheet: RC_0016_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images\\RC_0016_intraoperative.JPG\n",
      "ROI selected: (104, 222, 630, 201)\n",
      "Selected region: x=104, y=222, w=630, h=201\n",
      "Sheet: RC_0017_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images\\RC_0017_intraoperative.JPG\n",
      "ROI selected: (104, 221, 630, 200)\n",
      "Selected region: x=104, y=221, w=630, h=200\n",
      "Sheet: RC_0018_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images\\RC_0018_intraoperative.JPG\n",
      "ROI selected: (102, 221, 633, 204)\n",
      "Selected region: x=102, y=221, w=633, h=204\n",
      "Sheet: RC_0019_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images\\RC_0019_intraoperative.JPG\n",
      "ROI selected: (102, 220, 633, 204)\n",
      "Selected region: x=102, y=220, w=633, h=204\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Iterate over all images and their bounding boxes\n",
    "for sheet, bounding_boxes in yolo_data.items():\n",
    "    print(f\"Sheet: {sheet}\")\n",
    "    full_image_path = os.path.join(PATH_TO_REGISTERED_IMAGES, sheet)\n",
    "    print(f\"Full image path: {full_image_path}\")\n",
    "\n",
    "    # Call the analyze_sheet function with data from the loop\n",
    "    time_bounding_boxes, number_bounding_boxes = select_relevant_bounding_boxes(bounding_boxes, full_image_path)\n",
    "\n",
    "    # Now we need to cluster the bounding boxes that pertain to the same multi-digit number\n",
    "    time_labels = cluster_kmeans(time_bounding_boxes, 42)\n",
    "    number_labels = cluster_kmeans(number_bounding_boxes, 20)\n",
    "\n",
    "    # Create an image object\n",
    "    image: Image = Image.open(full_image_path)\n",
    "    image_width, image_height = image.size\n",
    "\n",
    "    label_color_map = {}\n",
    "    for i, label in enumerate(time_labels):\n",
    "\n",
    "        # Get the bounding box\n",
    "        bounding_box = time_bounding_boxes[i]\n",
    "        value, x_center, y_center, width, height = bounding_box.split(' ')\n",
    "        x_min, y_min, x_max, y_max = YOLO_to_pixels(float(x_center), float(y_center), float(width), float(height), image_width, image_height)\n",
    "\n",
    "        # Draw bounding boxes on the image\n",
    "        generate_color = lambda: \"#%06x\" % random.randint(0, 0xFFFFFF)\n",
    "\n",
    "\n",
    "        # If the label is not in the color map, generate a new color\n",
    "        if label not in label_color_map:\n",
    "            label_color_map[label] = generate_color()\n",
    "\n",
    "        # Open the image\n",
    "        draw = ImageDraw.Draw(image)\n",
    "\n",
    "        box = [\n",
    "            x_min,\n",
    "            y_min,\n",
    "            x_max,\n",
    "            y_max,\n",
    "        ]\n",
    "        draw.rectangle(box, outline=label_color_map[label], width=3)\n",
    "\n",
    "    # Save the image with the bounding boxes to the kmeans_clustered_images folder\n",
    "    image.save(f'../../data/kmeans_clustered_images/time/{sheet}')\n",
    "\n",
    "    # Save the clustered bounding boxes to a JSON file\n",
    "    with open(f'../../data/kmeans_clustered_images/results/time/{sheet}.json', 'w') as f:\n",
    "        json.dump(create_result_dictionary(time_labels, time_bounding_boxes), f)\n",
    "\n",
    "    # Create an image object\n",
    "    image: Image = Image.open(full_image_path)\n",
    "    image_width, image_height = image.size\n",
    "\n",
    "    label_color_map = {}\n",
    "    for i, label in enumerate(number_labels):\n",
    "\n",
    "        # Get the bounding box\n",
    "        bounding_box = number_bounding_boxes[i]\n",
    "        value, x_center, y_center, width, height = bounding_box.split(' ')\n",
    "        x_min, y_min, x_max, y_max = YOLO_to_pixels(float(x_center), float(y_center), float(width), float(height), image_width, image_height)\n",
    "\n",
    "        # Draw bounding boxes on the image\n",
    "        generate_color = lambda: \"#%06x\" % random.randint(0, 0xFFFFFF)\n",
    "\n",
    "\n",
    "        # If the label is not in the color map, generate a new color\n",
    "        if label not in label_color_map:\n",
    "            label_color_map[label] = generate_color()\n",
    "\n",
    "        # Open the image\n",
    "        draw = ImageDraw.Draw(image)\n",
    "\n",
    "        box = [\n",
    "            x_min,\n",
    "            y_min,\n",
    "            x_max,\n",
    "            y_max,\n",
    "        ]\n",
    "        draw.rectangle(box, outline=label_color_map[label], width=3)\n",
    "\n",
    "    # Save the image with the bounding boxes to the kmeans_clustered_images folder\n",
    "    image.save(f'../../data/kmeans_clustered_images/number/{sheet}')\n",
    "\n",
    "    # Save the clustered bounding boxes to a JSON file\n",
    "    with open(f'../../data/kmeans_clustered_images/results/number/{sheet}.json', 'w') as f:\n",
    "        json.dump(create_result_dictionary(number_labels, number_bounding_boxes), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Cluster Mapping\n",
    "Contains a cluster number that maps list of numbers that belong to that cluster *in-order*\n",
    "\n",
    "This will allow us to easily impute meanings of the labels since we have them split by time and number (mmHg and HR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# For each cluster in time cluster, sort by left most to right most\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cluster \u001b[38;5;129;01min\u001b[39;00m time_clusters:\n\u001b[1;32m---> 18\u001b[0m     cluster \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcluster\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m final_time_clusters[sheet] \u001b[38;5;241m=\u001b[39m time_clusters\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(NUMBER_JSON, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msheet\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m'\u001b[39m)) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "Cell \u001b[1;32mIn[27], line 18\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# For each cluster in time cluster, sort by left most to right most\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cluster \u001b[38;5;129;01min\u001b[39;00m time_clusters:\n\u001b[1;32m---> 18\u001b[0m     cluster \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(cluster, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     19\u001b[0m final_time_clusters[sheet] \u001b[38;5;241m=\u001b[39m time_clusters\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(NUMBER_JSON, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msheet\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m'\u001b[39m)) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Since this work is done above, we can simply read in from the JSON files created in the previous step and work from there.\n",
    "\n",
    "# Paths to the JSON files\n",
    "PATH_TO_KMEANS_RESULTS = '../../data/kmeans_clustered_images/results'\n",
    "TIME_JSON = os.path.join(PATH_TO_KMEANS_RESULTS, 'time')\n",
    "NUMBER_JSON = os.path.join(PATH_TO_KMEANS_RESULTS, 'number')\n",
    "\n",
    "final_time_clusters = {}\n",
    "final_number_clusters = {}\n",
    "\n",
    "# Iterate over all images and their bounding boxes\n",
    "for sheet, bounding_boxes in yolo_data.items():\n",
    "    # Load JSON\n",
    "    with open(os.path.join(TIME_JSON, f'{sheet}.json')) as f:\n",
    "        time_clusters = json.load(f)\n",
    "    \n",
    "    # Each cluster contains the number (integer) that the cluster represents\n",
    "    # We know what integers should be represented in the time labels, lets check that they are all there.\n",
    "    # Keep track of any false positives (new clusters that don't exist) or negatives (missing clusters)\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyze accuracy\n",
    "\n",
    "Below we use assumptions on what we know the labels should represent in both the time and number groups. We check that these values are present within clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'relevant_bounding_boxes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 23\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m index, value \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[0;32m     20\u001b[0m       \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Index \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 23\u001b[0m relevant_numbers \u001b[38;5;241m=\u001b[39m [box\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m box \u001b[38;5;129;01min\u001b[39;00m \u001b[43mrelevant_bounding_boxes\u001b[49m]\n\u001b[0;32m     24\u001b[0m print_classes_and_values(labels, relevant_numbers)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'relevant_bounding_boxes' is not defined"
     ]
    }
   ],
   "source": [
    "def print_classes_and_values(classes, values):\n",
    "  \"\"\"Prints the class number followed by all the indices and values belonging to that class.\n",
    "\n",
    "  Args:\n",
    "    classes: A list of class labels for each value.\n",
    "    values: A list of values.\n",
    "  \"\"\"\n",
    "\n",
    "  # Create a dictionary to store indices and values by class\n",
    "  class_data = {}\n",
    "  for i, class_label in enumerate(classes):\n",
    "    if class_label not in class_data:\n",
    "      class_data[class_label] = []\n",
    "    class_data[class_label].append((i, values[i]))\n",
    "\n",
    "  # Print the class number followed by the indices and values\n",
    "  for class_label, data in class_data.items():\n",
    "    print(f\"Class {class_label}:\")\n",
    "    for index, value in data:\n",
    "      print(f\"  Index {index}: {value}\")\n",
    "\n",
    "\n",
    "relevant_numbers = [box.split(\" \")[0] for box in relevant_bounding_boxes]\n",
    "print_classes_and_values(labels, relevant_numbers)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
