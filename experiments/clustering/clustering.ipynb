{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering Experiment\n",
    "\n",
    "We have put all of our methods together for direct comparison in a single notebook.\n",
    "\n",
    "Problem: Currently we are determining only the indiviudal digits, but we need to recognize these as coherent numbers and be able to assign entries to numbers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register Images to Start\n",
    "\n",
    "To start, we need to register images using the `utilities/conversion/apply_homography_to_labels.ipynb` notebook. This should be run before running this notebook. This notebook is built on the assumption that the `data/registered_images` directory has been created and populated. Additionally it assumes that the `data/yolo_data.json` file is created. Both of these are created in the referenced notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install Packages\n",
    "\n",
    "These are the necessary packages to run the functions and scripts below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Literal, Dict\n",
    "\n",
    "# Third-party libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "# Local libraries\n",
    "from utils.annotations import BoundingBox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start By Loading YOLO Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start I want to bring in the YOLO formatted data for each sheet and I can additionally load the respective images. As mentioned above you must have ran the `utilities/conversion/apply_homography_to_labels.ipynb` notebook to generate this YOLO data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19 sheets in yolo_data.json\n",
      "Found 19 items in bp_and_hr_cluster_locations.json\n"
     ]
    }
   ],
   "source": [
    "# Load yolo_data.json\n",
    "PATH_TO_YOLO_DATA = \"../../data/yolo_data.json\"\n",
    "PATH_TO_REGISTERED_IMAGES = \"../../data/registered_images\"\n",
    "UNIFIED_IMAGE_PATH = (\n",
    "    \"../../data/unified_intraoperative_preoperative_flowsheet_v1_1_front.png\"\n",
    ")\n",
    "\n",
    "# Load yolo_data.json\n",
    "with open(PATH_TO_YOLO_DATA) as json_file:\n",
    "    yolo_data = json.load(json_file)\n",
    "\n",
    "# See how many intraoperative images are registered\n",
    "print(f\"Found {len(yolo_data)} sheets in yolo_data.json\")\n",
    "\n",
    "# Load the json for bp and hr cluster locations\n",
    "PATH_TO_CLUSTER_LOCATIONS = \"../../data/bp_and_hr_cluster_locations.json\"\n",
    "with open(PATH_TO_CLUSTER_LOCATIONS) as json_file:\n",
    "    bp_hr_cluster_locations = json.load(json_file)\n",
    "    print(f\"Found {len(bp_hr_cluster_locations)} items in bp_and_hr_cluster_locations.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Constants Used In Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DESIRED_IMAGE_WIDTH = 800\n",
    "DESIRED_IMAGE_HEIGHT = 600"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's select relevant bounding boxes from the blood pressure and HR zone.\n",
    "\n",
    "Start by defining functions to convert YOLO bounding box format to pixels (to see if the bounding box is within region of interest). Then create a function that allows you to select ROI and returns a list of bounding boxes within this ROI.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_density_max(values: List[int], search_area: int) -> int:\n",
    "    \"\"\"\n",
    "    Given a list of values and a search area, find the index of where the highest density is.\n",
    "    The list of values correspond to identifying points for the bounding boxes and the search area corresponds to the images height or width.\n",
    "\n",
    "    Args:\n",
    "        values: List of identifying points for the bounding boxes\n",
    "        search_area: height/width of the image dependent on whether x or y axis is being search.\n",
    "\n",
    "    Returns:\n",
    "        The axis value that has the highest density of bounding boxes.\n",
    "    \"\"\"\n",
    "    kde = gaussian_kde(values, bw_method=0.2)\n",
    "\n",
    "    x_values = np.linspace(0, search_area, 10000)\n",
    "\n",
    "    kde_vals = kde(x_values)\n",
    "\n",
    "    max_index = np.argmax(kde_vals)\n",
    "    return x_values[max_index]\n",
    "\n",
    "def remove_bb_outliers(boxes: List[BoundingBox]) -> List[BoundingBox]:\n",
    "    \"\"\"\n",
    "    Given a list of bounding boxes, remove the outliers from the x axis, then remove the outliers from the y axis\n",
    "\n",
    "    Args:\n",
    "        boxes: List of Bounding Boxes to filter\n",
    "\n",
    "    Returns:\n",
    "        Filtered list of Bounding Boxes\n",
    "    \"\"\"\n",
    "    x_vals = [bb.left for bb in boxes]\n",
    "    # find the 25th percentile\n",
    "    x_Q1 = np.percentile(x_vals, 25)\n",
    "    # find the 75th percentile\n",
    "    x_Q3 = np.percentile(x_vals, 75)\n",
    "    # find the IQR\n",
    "    x_IQR = x_Q3 - x_Q1\n",
    "    # determine lower and upper bounds\n",
    "    x_lower = x_Q1 - 1.5*x_IQR\n",
    "    x_upper = x_Q3 + 1.5*x_IQR\n",
    "    # remove outliers via the x axis\n",
    "    x_filtered = [bb for bb in boxes if x_lower <= bb.left <= x_upper]\n",
    "\n",
    "    y_vals = [bb.top for bb in x_filtered]\n",
    "    # find the 25th percentile\n",
    "    y_Q1 = np.percentile(y_vals, 25)\n",
    "    # find the 75th percentile\n",
    "    y_Q3 = np.percentile(y_vals, 75)\n",
    "    # find the IQR\n",
    "    y_IQR = y_Q3 - y_Q1\n",
    "    # determine the lower and upper bounds\n",
    "    y_lower = y_Q1 - 1.5*y_IQR\n",
    "    y_upper = y_Q3 + 1.5*y_IQR\n",
    "    # remove outliers via the y axis\n",
    "    filtered = [bb for bb in x_filtered if y_lower <= bb.top <= y_upper]\n",
    "\n",
    "    return x_filtered\n",
    "\n",
    "\n",
    "\n",
    "def select_relevant_bounding_boxes(\n",
    "    sheet_data: List[str],\n",
    "    path_to_image: Path,\n",
    "    show_images: bool = False,\n",
    "    desired_img_width: int = DESIRED_IMAGE_WIDTH,\n",
    "    desired_img_height: int = DESIRED_IMAGE_HEIGHT,\n",
    ") -> Tuple[List[str], List[str]]:\n",
    "    \"\"\"\n",
    "    Given sheet data for bounding boxes in YOLO format, find the bounding boxes corresponding to the number and time on the BP chart.\n",
    "    Return the bounding boxes that are within the selected region split into two lists: time labels and numerical values.\n",
    "\n",
    "    Args:\n",
    "        sheet_data: List of bounding boxes in YOLO format.\n",
    "        path_to_image: Path to the image file.\n",
    "\n",
    "    Returns:\n",
    "        Tuple of Lists of string representations of bounding boxes that are within the selected region, in YOLO format.\n",
    "        The first list contains bounding boxes in the top-right region -- representing time labels.\n",
    "        The second list contains bounding boxes in the bottom-left region -- representing numerical values for mmHg and bpm.\n",
    "            (bounding_boxes_time, bounding_boxes_numbers)\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the image\n",
    "    image = cv2.imread(path_to_image)\n",
    "\n",
    "    # Display the image and allow the user to select a ROI\n",
    "    resized_image = cv2.resize(image, (desired_img_width, desired_img_height))\n",
    "\n",
    "    # convert the YOLO data to Bounding Boxes\n",
    "    bboxes: List[BoundingBox] = [\n",
    "        BoundingBox.from_yolo(yolo_bb, desired_img_width, desired_img_height)\n",
    "        for yolo_bb in sheet_data\n",
    "    ]\n",
    "\n",
    "    # generate a list of the digit categories\n",
    "    digit_categories: List[str] = [str(i) for i in range(10)]\n",
    "\n",
    "    # filter out non bounding boxes and those whose category is not a digit\n",
    "    bboxes: List[BoundingBox] = list(\n",
    "        filter(\n",
    "            lambda bb: isinstance(bb, BoundingBox) and bb.category in digit_categories,\n",
    "            bboxes,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # find the point with the maximum density of bounding boxes\n",
    "    bboxes_right: List[int] = [bb.right for bb in bboxes]\n",
    "    # x_loc is the vertical line to the left of the time axis and right of the numbers axis\n",
    "    x_loc: int = find_density_max(bboxes_right, desired_img_width)\n",
    "\n",
    "    bboxes_bottom: List[int] = [bb.bottom for bb in bboxes]\n",
    "    # y_loc is the horizontal line undert the time axis and above the number axis\n",
    "    y_loc: int = find_density_max(bboxes_bottom, desired_img_height)\n",
    "\n",
    "\n",
    "    bounding_boxes_time = []\n",
    "    bounding_boxes_numbers = []\n",
    "\n",
    "    # Process the bounding boxes\n",
    "    for bounding_box in bboxes:\n",
    "        # get the center point of the bounding box for comparison\n",
    "        x_center_bb, y_center_bb = bounding_box.center\n",
    "\n",
    "        # check if the bounding box is a number on the BP chart by comparing to the KDE index + a threshold\n",
    "        if (x_center_bb > x_loc-15 and x_center_bb < x_loc+2):\n",
    "            bounding_boxes_numbers.append(bounding_box)\n",
    "        # check if the bounding box is a time on the BP chart by comparing to the KDE index + a threshold\n",
    "        elif (y_center_bb > y_loc-10 and y_center_bb < y_loc+2):\n",
    "            bounding_boxes_time.append(bounding_box)\n",
    "    \n",
    "    bounding_boxes_numbers = remove_bb_outliers(bounding_boxes_numbers)\n",
    "    bounding_boxes_time = remove_bb_outliers(bounding_boxes_time)\n",
    "\n",
    "    for bounding_box in bounding_boxes_numbers:\n",
    "        x_min = int(bounding_box.left)\n",
    "        x_max = int(bounding_box.right)\n",
    "        y_min = int(bounding_box.top)\n",
    "        y_max = int(bounding_box.bottom)\n",
    "\n",
    "        # Bounding box is in the top-right region\n",
    "        cv2.rectangle(\n",
    "            resized_image, (x_min, y_min), (x_max, y_max), (255, 255, 0), 1\n",
    "        )\n",
    "    \n",
    "    for bounding_box in bounding_boxes_time:\n",
    "        x_min = int(bounding_box.left)\n",
    "        x_max = int(bounding_box.right)\n",
    "        y_min = int(bounding_box.top)\n",
    "        y_max = int(bounding_box.bottom)\n",
    "\n",
    "        cv2.rectangle(\n",
    "            resized_image, (x_min, y_min), (x_max, y_max), (255, 0, 255), 1\n",
    "        )\n",
    "            \n",
    "    # plot the lines of the KDE index found for debugging\n",
    "    # numbers_start = (int(x_loc), 0)\n",
    "    # numbers_end = (int(x_loc), desired_img_height)\n",
    "\n",
    "    # time_start = (0, int(y_loc))\n",
    "    # time_end = (desired_img_width, int(y_loc))\n",
    "\n",
    "    # cv2.line(resized_image, numbers_start, numbers_end, (255,255,0), 1)\n",
    "    # cv2.line(resized_image, time_start, time_end, (255,0,255), 1)\n",
    "\n",
    "    # Close all OpenCV windows, always do this or it will annoyingly not go away\n",
    "    # You can also manually quit out with ESC key.\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # If we are showing the images, display the image with the selected region and bounding boxes\n",
    "    # Bounding boxes in the top-right region (time) are in one color while those in the bottom left (numerical) are in another\n",
    "    if show_images:\n",
    "        # Display the image with the selected region and bounding boxes\n",
    "        resized_image = cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB)\n",
    "        resized_image = Image.fromarray(resized_image)\n",
    "        resized_image.show()\n",
    "\n",
    "    # Return a tuple of bounding boxes in the top-right and bottom-left regions\n",
    "    return (bounding_boxes_time, bounding_boxes_numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create functions for K-means clustering, dbscan clustering, and agglomerative clustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_kmeans(\n",
    "    bounding_boxes: List[BoundingBox], possible_nclusters: List[int]\n",
    ") -> List[int]:\n",
    "    \"\"\"\n",
    "    Cluster bounding boxes using K-Means clustering algorithm.\n",
    "\n",
    "    Args:\n",
    "        bounding_boxes: List of bounding boxes in YOLO format.\n",
    "        possible_nclusters: List of possible number of clusters to try.\n",
    "\n",
    "    Returns:\n",
    "        List of cluster labels.\n",
    "    \"\"\"\n",
    "    # Convert to a NumPy array (using only x_center and y_center)\n",
    "    data = np.array([box.center for box in bounding_boxes])\n",
    "\n",
    "    cluster_performance_map = {}\n",
    "    for number_of_clusters in possible_nclusters:\n",
    "        if number_of_clusters > len(data):\n",
    "            raise (\n",
    "                f\"Number of clusters {number_of_clusters} is greater than number of bounding boxes {len(data)}.\"\n",
    "            )\n",
    "        if number_of_clusters < 1:\n",
    "            raise (f\"Number of clusters {number_of_clusters} must be greater than 0.\")\n",
    "        # Apply K-Means\n",
    "        kmeans = KMeans(\n",
    "            n_clusters=number_of_clusters,\n",
    "            init=\"k-means++\",\n",
    "            n_init=20,\n",
    "            max_iter=500,\n",
    "            tol=1e-8,\n",
    "            random_state=42,\n",
    "        )\n",
    "        kmeans.fit(data)\n",
    "\n",
    "        # Get cluster labels\n",
    "        labels = kmeans.predict(data)\n",
    "        silhouette_avg = silhouette_score(data, labels)\n",
    "\n",
    "        # print(\n",
    "        #     f\"Number of clusters: {number_of_clusters}, Silhouette score: {silhouette_avg}\"\n",
    "        # )\n",
    "\n",
    "        cluster_performance_map[number_of_clusters] = {\n",
    "            \"score\": silhouette_avg,\n",
    "            \"labels\": labels,\n",
    "        }\n",
    "\n",
    "    # Evaluate the performance of each number of clusters and select the one with the highest silhouette score\n",
    "    # if it is 0.003 greater than what should be the number of clusters otherwise go with proper_nclusters\n",
    "    n_clusters_max_silhouette = max(\n",
    "        cluster_performance_map, key=lambda x: cluster_performance_map[x][\"score\"]\n",
    "    )\n",
    "    best_n_clusters = (\n",
    "        n_clusters_max_silhouette\n",
    "        if (\n",
    "            (\n",
    "                cluster_performance_map[n_clusters_max_silhouette][\"score\"]\n",
    "                - cluster_performance_map[max(possible_nclusters)][\"score\"]\n",
    "            )\n",
    "            >= 0.005\n",
    "        )\n",
    "        else max(possible_nclusters)\n",
    "    )\n",
    "    return cluster_performance_map[best_n_clusters][\"labels\"]\n",
    "\n",
    "\n",
    "def dbscan_clustering(\n",
    "    bounding_boxes: List[BoundingBox], defined_eps: float, min_samples: int\n",
    ") -> List[int]:\n",
    "    \"\"\"\n",
    "    Cluster bounding boxes density based spatial clustering algorithm.\n",
    "\n",
    "    Args:\n",
    "        bounding_boxes: List of bounding boxes.\n",
    "        defined_eps: Maximum distance between two samples to be in the neighborhood of one another (center of BB).\n",
    "        min_samples: The number of samples (or total weight) for a point to be considered as core\n",
    "\n",
    "    Returns:\n",
    "        List of cluster labels.\n",
    "    \"\"\"\n",
    "    # Convert to a NumPy array (using only x_center and y_center)\n",
    "    data = np.array([box.center for box in bounding_boxes])\n",
    "\n",
    "    # DBSCAN\n",
    "    scan = DBSCAN(eps=defined_eps, min_samples=min_samples)\n",
    "    labels = scan.fit_predict(data)\n",
    "\n",
    "    return labels\n",
    "\n",
    "\n",
    "def agglomerative_clustering(\n",
    "    bounding_boxes: List[BoundingBox], possible_nclusters: List[int]\n",
    ") -> List[int]:\n",
    "    # make the bonding box data into a Numpy array\n",
    "    data = np.array([box.center for box in bounding_boxes])\n",
    "\n",
    "    # follow suit of the cluster_kmeans algorithm to measure accuracy through silhoutte scores\n",
    "    cluster_performance_map = {}\n",
    "    for number_of_clusters in possible_nclusters:\n",
    "        if number_of_clusters > len(data):\n",
    "            raise (\n",
    "                f\"Number of clusters {number_of_clusters} is greater than number of bounding boxes {len(data)}.\"\n",
    "            )\n",
    "        if number_of_clusters < 1:\n",
    "            raise (f\"Number of clusters {number_of_clusters} must be greater than 0.\")\n",
    "        # use agglomerative clustering\n",
    "        agg = AgglomerativeClustering(n_clusters=number_of_clusters, linkage=\"single\")\n",
    "        # get labels\n",
    "        labels = agg.fit_predict(data)\n",
    "        # compute the silhoutte scores\n",
    "        silhouette_avg = silhouette_score(data, labels)\n",
    "\n",
    "        cluster_performance_map[number_of_clusters] = {\n",
    "            \"score\": silhouette_avg,\n",
    "            \"labels\": labels,\n",
    "        }\n",
    "\n",
    "    # get the number of clusters with the best silhoutte score\n",
    "    n_clusters_max_silhouette = max(\n",
    "        cluster_performance_map, key=lambda x: cluster_performance_map[x][\"score\"]\n",
    "    )\n",
    "\n",
    "    best_n_clusters = (\n",
    "        n_clusters_max_silhouette\n",
    "        if (\n",
    "            (\n",
    "                cluster_performance_map[n_clusters_max_silhouette][\"score\"]\n",
    "                - cluster_performance_map[max(possible_nclusters)][\"score\"]\n",
    "            )\n",
    "            >= 0.003\n",
    "        )\n",
    "        else max(possible_nclusters)\n",
    "    )\n",
    "    return cluster_performance_map[best_n_clusters][\"labels\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to create a result dictionary that we can save as a JSON file to analyze performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_result_dictionary(\n",
    "    labels: List[str], bounding_boxes: List[BoundingBox], expected_clusters: dict\n",
    ") -> Dict[int, int]:\n",
    "    \"\"\"\n",
    "    Create a dictionary with cluster labels as keys and lists of bounding boxes as values.\n",
    "\n",
    "    Args:\n",
    "        labels: List of cluster labels.\n",
    "        bounding_boxes: List of bounding boxes.\n",
    "        expected_clusters: dictionary containing expected clustered\n",
    "            - This should be passed as specific for the sheet we are working with. It can be obtained from bp_hr_cluster_locations.json.\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with cluster labels as keys and bounding box values as values.\n",
    "    \"\"\"\n",
    "    # Create a dictionary to store labelled elements\n",
    "    label_dict = {}\n",
    "\n",
    "    # Iterate over both lists for labels and the bounding boxes found\n",
    "    for label, box in zip(labels, bounding_boxes):\n",
    "        label = int(label)\n",
    "        if label not in label_dict:\n",
    "            # Create a new list for this label if it doesn't exist\n",
    "            label_dict[label] = []\n",
    "        # Append the element to the corresponding label list\n",
    "        label_dict[label].append(box)\n",
    "\n",
    "    # So now we have a dictionary with the clusters as keys and a list of bounding box objects as strings as values\n",
    "\n",
    "    # Now we want to impute meaning of these clusters based on how close they are to their expected cluster locations\n",
    "    for key in label_dict:\n",
    "        # For each key get the centers of the bounding boxes, and compute the middle point\n",
    "        x_centers, y_centers  = [element.center[0] for element in label_dict[key]], [element.center[1] for element in label_dict[key]]\n",
    "        x_found, y_found = sum(x_centers) / len(x_centers), sum(y_centers) / len(y_centers)\n",
    "        # Now we have the center point of the cluster\n",
    "        # We will use the euclidean distance to determine the closest expected cluster location and use that as the label\n",
    "        distances = [] # List that contains the distances for each expected cluster from our found cluster\n",
    "        for cluster in expected_clusters[\"annotations\"][0][\"result\"]:\n",
    "            x_expected_perc, y_expected_perc = cluster['value']['x'], cluster['value']['y'] # Get the expected cluster location (percent x and y in the original image space)\n",
    "            x_expected, y_expected = (x_expected_perc/100) * DESIRED_IMAGE_WIDTH, (y_expected_perc/100) * DESIRED_IMAGE_HEIGHT # Convert the expected cluster location to pixel space\n",
    "            #print(f\"Cluster location: {x}, {y}\")\n",
    "            distance = np.sqrt((x_expected - x_found) ** 2 + (y_expected - y_found) ** 2)\n",
    "            #print(f\"Distance: {distance}\")\n",
    "            distances.append(distance)\n",
    "        # Get the index of the minimum distance\n",
    "        min_distance_index = distances.index(min(distances))\n",
    "\n",
    "        # Get the label of the cluster\n",
    "        label_dict[key] = list(expected_clusters[\"annotations\"][0][\"result\"])[min_distance_index]['value']['rectanglelabels'][0]\n",
    "\n",
    "        # Add the distance to the dictionary\n",
    "        label_dict[key] = {\"label\": label_dict[key], \"distance\": min(distances)}\n",
    "\n",
    "    return label_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to generate colors!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw bounding boxes on the image\n",
    "def generate_color():\n",
    "    return \"#%06x\" % random.randint(0, 0xFFFFFF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to generate random Bounding Box formatted occurances.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_time_generate(x):\n",
    "    # erroneous bounding boxes for time ROI\n",
    "    category_int = random.randint(0, 9)\n",
    "    left_int = random.randint(127, 715)\n",
    "\n",
    "    # slope and random points constrained to time (x) axis\n",
    "    top_int = random.uniform(222, 234)\n",
    "\n",
    "    # input generated integers to bounding box\n",
    "    box = BoundingBox(\n",
    "        category=f\"{category_int}\",\n",
    "        left=left_int,\n",
    "        top=top_int,\n",
    "        right=left_int + 4,\n",
    "        bottom=top_int + 6,\n",
    "    )\n",
    "    return box\n",
    "\n",
    "\n",
    "def random_number_generate(x):\n",
    "    # erroneous bounding boxes for number ROI\n",
    "    category_int = random.randint(0, 9)\n",
    "    left_int = random.randint(108, 117)\n",
    "\n",
    "    # slope and random points constrained to number (y) axis\n",
    "    top_int = random.uniform(235, 411)\n",
    "\n",
    "    # input generated integers to bounding box\n",
    "    box = BoundingBox(\n",
    "        category=f\"{category_int}\",\n",
    "        left=left_int,\n",
    "        top=top_int,\n",
    "        right=left_int + 4,\n",
    "        bottom=top_int + 6,\n",
    "    )\n",
    "    return box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to remove 5% bounding boxes and create 5% erroneous.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def erroneous_bounding_boxes(\n",
    "    time_BB: List[str], number_BB: List[str]\n",
    ") -> Tuple[List[str], List[str]]:\n",
    "    \"\"\"\n",
    "    Create 5% erroneous bounding boxes by simultaneously removing and generating time and number BB.\n",
    "\n",
    "    Args:\n",
    "        time_BB: list of time bounding boxes in BoundingBox format\n",
    "        number_BB: list of number bounding boxes in BoundingBox format\n",
    "\n",
    "    Returns:\n",
    "        Tuple: lists of time and number bounding boxes in BoundingBox format\n",
    "    \"\"\"\n",
    "    # make copies of input bounding box lists to avoid unwanted manipulation\n",
    "    time_BB_copy = time_BB.copy()\n",
    "    number_BB_copy = number_BB.copy()\n",
    "\n",
    "    # subset and remove 5% of bounding boxes from time/number_bounding_boxes lists\n",
    "    ## sample\n",
    "    time_BB_sample = list(random.sample(time_BB_copy, 4))\n",
    "    number_BB_sample = list(random.sample(number_BB_copy, 4))\n",
    "    ## remove\n",
    "    _ = [time_BB_copy.remove(line) for line in time_BB_sample]\n",
    "    _ = [number_BB_copy.remove(line) for line in number_BB_sample]\n",
    "\n",
    "    # use random bounding box generation to refill removed BBs with erroneous boxes\n",
    "    time_BB_generate = list(map(random_time_generate, range(len(time_BB_sample))))\n",
    "    number_BB_generate = list(map(random_number_generate, range(len(number_BB_sample))))\n",
    "\n",
    "    # append BB generated list back to copy with 5% removal\n",
    "    time_BB_erroneous = time_BB_copy + time_BB_generate\n",
    "    number_BB_erroneous = number_BB_copy + number_BB_generate\n",
    "\n",
    "    return (time_BB_erroneous, number_BB_erroneous)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function that tests the clustering methods with our without erroneous boxes\n",
    "\n",
    "Now lets use these functions to get the relevant bounding boxes for clustering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_clustering_methods(add_erroneous = True) -> None:\n",
    "    \"\"\"\n",
    "    Test the clustering methods on the YOLO data.\n",
    "    Saves the clustered images and the clustered bounding boxes to JSON files.\n",
    "\n",
    "    Args:\n",
    "        add_erroneous: Boolean flag to add erroneous bounding boxes to the data.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    sheet_num = 0\n",
    "    # Iterate over all images and their bounding boxes\n",
    "    for sheet, yolo_bbs in yolo_data.items():\n",
    "        #print(f\"Sheet: {sheet}\")\n",
    "        full_image_path = os.path.join(PATH_TO_REGISTERED_IMAGES, sheet)\n",
    "        #print(f\"Full image path: {full_image_path}\")\n",
    "\n",
    "        # Call the analyze_sheet function with data from the loop\n",
    "        time_bounding_boxes, number_bounding_boxes = select_relevant_bounding_boxes(\n",
    "            yolo_bbs, full_image_path\n",
    "        )\n",
    "\n",
    "        if add_erroneous:\n",
    "            # make erroneous bounding boxes -- simultaneously add and remove %5 of boxes\n",
    "            time_bounding_boxes, number_bounding_boxes = erroneous_bounding_boxes(\n",
    "                time_bounding_boxes, number_bounding_boxes\n",
    "            )\n",
    "\n",
    "        for method in [\"kmeans\", \"dbscan\", \"agglomerative\"]:\n",
    "            # Now we need to cluster the bounding boxes that pertain to the same multi-digit number\n",
    "            if method == \"kmeans\":\n",
    "                time_labels = cluster_kmeans(time_bounding_boxes, [40, 41, 42])\n",
    "                number_labels = cluster_kmeans(number_bounding_boxes, [18, 19, 20])\n",
    "            elif method == \"dbscan\":\n",
    "                time_labels = dbscan_clustering(\n",
    "                    time_bounding_boxes, defined_eps=5, min_samples=1\n",
    "                )\n",
    "                number_labels = dbscan_clustering(\n",
    "                    number_bounding_boxes, defined_eps=5, min_samples=2\n",
    "                )\n",
    "            elif method == \"agglomerative\":\n",
    "                time_labels = agglomerative_clustering(\n",
    "                    time_bounding_boxes, [40, 41, 42]\n",
    "                )\n",
    "                number_labels = agglomerative_clustering(\n",
    "                    number_bounding_boxes, [18, 19, 20]\n",
    "                )\n",
    "            else:\n",
    "                raise ValueError(f\"Invalid clustering method: {method}\")\n",
    "\n",
    "            # Create an image object\n",
    "            image: Image = Image.open(full_image_path)\n",
    "            image_width, image_height = image.size\n",
    "\n",
    "            label_color_map = {}\n",
    "            for i, label in enumerate(time_labels):\n",
    "                # Get the bounding box\n",
    "                bounding_box = time_bounding_boxes[i]\n",
    "                x_min, y_min, x_max, y_max = [\n",
    "                    (coor / 800) * image_width\n",
    "                    if i % 2 == 0\n",
    "                    else (coor / 600) * image_height\n",
    "                    for i, coor in enumerate(bounding_box.box)\n",
    "                ]\n",
    "\n",
    "                # If the label is not in the color map, generate a new color\n",
    "                if label not in label_color_map:\n",
    "                    label_color_map[label] = generate_color()\n",
    "\n",
    "                # Open the image\n",
    "                draw = ImageDraw.Draw(image)\n",
    "\n",
    "                draw.rectangle(\n",
    "                    [\n",
    "                        x_min,\n",
    "                        y_min,\n",
    "                        x_max,\n",
    "                        y_max,\n",
    "                    ],\n",
    "                    outline=label_color_map[label],\n",
    "                    width=3,\n",
    "                )\n",
    "\n",
    "            # Save the image with the bounding boxes to the kmeans_clustered_images folder\n",
    "            image.save(f\"../../data/{method}_clustered_images/time/{sheet}\")\n",
    "\n",
    "            # Save the clustered bounding boxes to a JSON file\n",
    "            with open(\n",
    "                f\"../../data/{method}_clustered_images/results/time/{sheet.split('.')[0]}.json\",\n",
    "                \"w\",\n",
    "            ) as f:\n",
    "                json.dump(\n",
    "                    create_result_dictionary(time_labels, time_bounding_boxes, bp_hr_cluster_locations[sheet_num]),\n",
    "                    f,\n",
    "                )\n",
    "\n",
    "            # Create an image object\n",
    "            image: Image = Image.open(full_image_path)\n",
    "            image_width, image_height = image.size\n",
    "            label_color_map = {}\n",
    "            for i, label in enumerate(number_labels):\n",
    "                # Get the bounding box\n",
    "                bounding_box = number_bounding_boxes[i]\n",
    "                x_min, y_min, x_max, y_max = [\n",
    "                    (coor / 800) * image_width\n",
    "                    if i % 2 == 0\n",
    "                    else (coor / 600) * image_height\n",
    "                    for i, coor in enumerate(bounding_box.box)\n",
    "                ]\n",
    "\n",
    "                # If the label is not in the color map, generate a new color\n",
    "                if label not in label_color_map:\n",
    "                    label_color_map[label] = generate_color()\n",
    "\n",
    "                # Open the image\n",
    "                draw = ImageDraw.Draw(image)\n",
    "\n",
    "                draw.rectangle(\n",
    "                    [\n",
    "                        x_min,\n",
    "                        y_min,\n",
    "                        x_max,\n",
    "                        y_max,\n",
    "                    ],\n",
    "                    outline=label_color_map[label],\n",
    "                    width=3,\n",
    "                )\n",
    "\n",
    "            # Save the image with the bounding boxes to the kmeans_clustered_images folder\n",
    "            image.save(f\"../../data/{method}_clustered_images/number/{sheet}\")\n",
    "\n",
    "            # Save the clustered bounding boxes to a JSON file\n",
    "            with open(\n",
    "                f\"../../data/{method}_clustered_images/results/number/{sheet.split('.')[0]}.json\",\n",
    "                \"w\",\n",
    "            ) as f:\n",
    "                json.dump(\n",
    "                    create_result_dictionary(\n",
    "                        number_labels, number_bounding_boxes, bp_hr_cluster_locations[sheet_num]\n",
    "                    ),\n",
    "                    f,\n",
    "                )\n",
    "\n",
    "        sheet_num += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyze accuracy\n",
    "\n",
    "Below we write a function that analyzes the accuracy of our clustering methods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_accuracy():\n",
    "    # Since this work is done above, we can simply read in from the JSON files created in the previous step and work from there.\n",
    "    for method in [\"kmeans\", \"dbscan\", \"agglomerative\"]:\n",
    "        print(f\"Method: {method}\")\n",
    "        # Paths to the JSON files\n",
    "        PATH_TO_KMEANS_RESULTS = f\"../../data/{method}_clustered_images/results\"\n",
    "        TIME_JSON = os.path.join(PATH_TO_KMEANS_RESULTS, \"time\")\n",
    "        NUMBER_JSON = os.path.join(PATH_TO_KMEANS_RESULTS, \"number\")\n",
    "\n",
    "        time_wrong_clusters_count = 0\n",
    "        time_correct_clusters_count = 0\n",
    "        number_wrong_clusters_count = 0\n",
    "        number_correct_clusters_count = 0\n",
    "\n",
    "        # Iterate over all images and their bounding boxes\n",
    "        number_distance_values = []\n",
    "        time_distance_values = []\n",
    "        number_distance_values_erroneous = []\n",
    "        time_distance_values_erroneous = []\n",
    "        # Undetected clusters\n",
    "        undetected_time_clusters = []\n",
    "        undetected_number_clusters = []\n",
    "        for sheet, yolo_bb in yolo_data.items():\n",
    "            full_image_path = os.path.join(PATH_TO_REGISTERED_IMAGES, sheet)\n",
    "            time_bounding_boxes, number_bounding_boxes = select_relevant_bounding_boxes(\n",
    "                yolo_bb, full_image_path,\n",
    "            )\n",
    "            # Convert the bounding boxes to a list of strings with proper suffixes\n",
    "            expected_time_values = [\n",
    "                \"0_mins\",\n",
    "                \"5_mins\",\n",
    "                \"10_mins\",\n",
    "                \"15_mins\",\n",
    "                \"20_mins\",\n",
    "                \"25_mins\",\n",
    "                \"30_mins\",\n",
    "                \"35_mins\",\n",
    "                \"40_mins\",\n",
    "                \"45_mins\",\n",
    "                \"50_mins\",\n",
    "                \"55_mins\",\n",
    "                \"60_mins\",\n",
    "                \"65_mins\",\n",
    "                \"70_mins\",\n",
    "                \"75_mins\",\n",
    "                \"80_mins\",\n",
    "                \"85_mins\",\n",
    "                \"90_mins\",\n",
    "                \"95_mins\",\n",
    "                \"100_mins\",\n",
    "                \"105_mins\",\n",
    "                \"110_mins\",\n",
    "                \"115_mins\",\n",
    "                \"120_mins\",\n",
    "                \"125_mins\",\n",
    "                \"130_mins\",\n",
    "                \"135_mins\",\n",
    "                \"140_mins\",\n",
    "                \"145_mins\",\n",
    "                \"150_mins\",\n",
    "                \"155_mins\",\n",
    "                \"160_mins\",\n",
    "                \"165_mins\",\n",
    "                \"170_mins\",\n",
    "                \"175_mins\",\n",
    "                \"180_mins\",\n",
    "                \"185_mins\",\n",
    "                \"190_mins\",\n",
    "                \"195_mins\",\n",
    "                \"200_mins\",\n",
    "                \"205_mins\",\n",
    "            ]\n",
    "\n",
    "            expected_number_values = [\n",
    "                \"30_mmhg\",\n",
    "                \"40_mmhg\",\n",
    "                \"50_mmhg\",\n",
    "                \"60_mmhg\",\n",
    "                \"70_mmhg\",\n",
    "                \"80_mmhg\",\n",
    "                \"90_mmhg\",\n",
    "                \"100_mmhg\",\n",
    "                \"110_mmhg\",\n",
    "                \"120_mmhg\",\n",
    "                \"130_mmhg\",\n",
    "                \"140_mmhg\",\n",
    "                \"150_mmhg\",\n",
    "                \"160_mmhg\",\n",
    "                \"170_mmhg\",\n",
    "                \"180_mmhg\",\n",
    "                \"190_mmhg\",\n",
    "                \"200_mmhg\",\n",
    "                \"210_mmhg\",\n",
    "                \"220_mmhg\",\n",
    "            ]\n",
    "\n",
    "            # Load JSON\n",
    "            with open(os.path.join(TIME_JSON, f\"{sheet.split('.')[0]}.json\")) as f:\n",
    "                time_clusters = json.load(f)\n",
    "\n",
    "            # Each cluster contains the number (integer) that the cluster represents\n",
    "            # We know what integers should be represented in the time labels, lets check that they are all there.\n",
    "            # Keep track of any false positives (new clusters that don't exist) or negatives (missing clusters)\n",
    "            for cluster, value in time_clusters.items():\n",
    "                if value['label'] not in expected_time_values:\n",
    "                    # Print the sheet, value that is not in the expected values\n",
    "                    #print(f\"Time -> Sheet: {sheet}, Value: {value[\"label\"]}.\")\n",
    "                    # We have an erroneous cluster\n",
    "                    time_wrong_clusters_count += 1\n",
    "                    time_distance_values_erroneous.append(value['distance'])\n",
    "                else:\n",
    "                    # We have a correct cluster\n",
    "                    expected_time_values.remove(value['label'])\n",
    "                    time_correct_clusters_count += 1\n",
    "                    time_distance_values.append(value['distance'])\n",
    "            \n",
    "            undetected_time_clusters += expected_time_values\n",
    "\n",
    "            # Load JSON\n",
    "            with open(os.path.join(NUMBER_JSON, f\"{sheet.split('.')[0]}.json\")) as f:\n",
    "                number_clusters = json.load(f)\n",
    "\n",
    "            # Each cluster contains the number (integer) that the cluster represents\n",
    "            # We know what integers should be represented in the time labels, lets check that they are all there.\n",
    "            # Keep track of any false positives (new clusters that don't exist) or negatives (missing clusters)\n",
    "            for cluster, value in number_clusters.items():\n",
    "                if value['label'] not in expected_number_values:\n",
    "                    #print(f\"Number -> Sheet: {sheet}, Value: {value}\")\n",
    "                    # We have an erroneous cluster\n",
    "                    number_wrong_clusters_count += 1\n",
    "                    number_distance_values_erroneous.append(value['distance'])\n",
    "                else:\n",
    "                    # We have a correct cluster\n",
    "                    expected_number_values.remove(value['label'])\n",
    "                    number_correct_clusters_count += 1\n",
    "                    number_distance_values.append(value['distance'])\n",
    "\n",
    "            undetected_number_clusters += expected_number_values\n",
    "\n",
    "        print(\n",
    "            f\"Time labels: {time_correct_clusters_count} correct clusters, {time_wrong_clusters_count} incorrect clusters. There were {len(undetected_time_clusters)} undetected clusters. The accuracy is {(time_correct_clusters_count - (time_wrong_clusters_count + len(undetected_time_clusters))) / (42 * 19) * 100:.2f}%.\\nAverage distance when correct: {sum(time_distance_values) / len(time_distance_values):.2f}px, incorrect: {sum(time_distance_values_erroneous) / 1 if len(time_distance_values_erroneous) == 0 else len(time_distance_values_erroneous):.2f}px, and overall: {sum(time_distance_values + time_distance_values_erroneous) / (len(time_distance_values) + len(time_distance_values_erroneous)):.2f}px\"\n",
    "        )\n",
    "        print(\"\\n\")\n",
    "        print(\n",
    "            f\"Number labels: {number_correct_clusters_count} correct clusters, {number_wrong_clusters_count} incorrect clusters. There were {len(undetected_number_clusters)} undetected clusters. The accuracy is {(number_correct_clusters_count - (number_wrong_clusters_count + len(undetected_number_clusters))) / (20 * 19) * 100:.2f}%.\\nAverage distance when correct: {sum(number_distance_values) / len(number_distance_values):.2f}px, incorrect: {sum(number_distance_values_erroneous) / 1 if len(number_distance_values_erroneous) == 0 else len(number_distance_values_erroneous):.2f}px, and overall: {sum(number_distance_values + number_distance_values_erroneous) / (len(number_distance_values) + len(number_distance_values_erroneous)):.2f}px\"\n",
    "        )\n",
    "        print(\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test without Erroneous bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: kmeans\n",
      "Time labels: 796 correct clusters, 1 incorrect clusters. There were 2 undetected clusters. The accuracy is 99.37%.\n",
      "Average distance when correct: 4.83px, incorrect: 1.00px, and overall: 4.83px\n",
      "\n",
      "\n",
      "Number labels: 379 correct clusters, 1 incorrect clusters. There were 1 undetected clusters. The accuracy is 99.21%.\n",
      "Average distance when correct: 6.16px, incorrect: 1.00px, and overall: 6.16px\n",
      "\n",
      "\n",
      "\n",
      "Method: dbscan\n",
      "Time labels: 796 correct clusters, 1 incorrect clusters. There were 2 undetected clusters. The accuracy is 99.37%.\n",
      "Average distance when correct: 4.83px, incorrect: 1.00px, and overall: 4.83px\n",
      "\n",
      "\n",
      "Number labels: 379 correct clusters, 1 incorrect clusters. There were 1 undetected clusters. The accuracy is 99.21%.\n",
      "Average distance when correct: 6.16px, incorrect: 1.00px, and overall: 6.16px\n",
      "\n",
      "\n",
      "\n",
      "Method: agglomerative\n",
      "Time labels: 796 correct clusters, 1 incorrect clusters. There were 2 undetected clusters. The accuracy is 99.37%.\n",
      "Average distance when correct: 4.83px, incorrect: 1.00px, and overall: 4.83px\n",
      "\n",
      "\n",
      "Number labels: 379 correct clusters, 1 incorrect clusters. There were 1 undetected clusters. The accuracy is 99.21%.\n",
      "Average distance when correct: 6.16px, incorrect: 1.00px, and overall: 6.16px\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test the clustering methods with errouneous bounding boxes\n",
    "test_clustering_methods(add_erroneous=False)\n",
    "analyze_accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with Erroneous bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: kmeans\n",
      "Time labels: 771 correct clusters, 5 incorrect clusters. There were 27 undetected clusters. The accuracy is 92.61%.\n",
      "Average distance when correct: 4.92px, incorrect: 5.00px, and overall: 4.92px\n",
      "\n",
      "\n",
      "Number labels: 366 correct clusters, 8 incorrect clusters. There were 14 undetected clusters. The accuracy is 90.53%.\n",
      "Average distance when correct: 6.19px, incorrect: 8.00px, and overall: 6.19px\n",
      "\n",
      "\n",
      "\n",
      "Method: dbscan\n",
      "Time labels: 780 correct clusters, 38 incorrect clusters. There were 18 undetected clusters. The accuracy is 90.73%.\n",
      "Average distance when correct: 4.87px, incorrect: 38.00px, and overall: 5.00px\n",
      "\n",
      "\n",
      "Number labels: 350 correct clusters, 14 incorrect clusters. There were 30 undetected clusters. The accuracy is 80.53%.\n",
      "Average distance when correct: 6.17px, incorrect: 14.00px, and overall: 6.18px\n",
      "\n",
      "\n",
      "\n",
      "Method: agglomerative\n",
      "Time labels: 774 correct clusters, 10 incorrect clusters. There were 24 undetected clusters. The accuracy is 92.73%.\n",
      "Average distance when correct: 4.91px, incorrect: 10.00px, and overall: 4.94px\n",
      "\n",
      "\n",
      "Number labels: 364 correct clusters, 9 incorrect clusters. There were 16 undetected clusters. The accuracy is 89.21%.\n",
      "Average distance when correct: 6.22px, incorrect: 9.00px, and overall: 6.19px\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test the clustering methods with errouneous bounding boxes\n",
    "test_clustering_methods(add_erroneous=True)\n",
    "analyze_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ChartExtractor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
