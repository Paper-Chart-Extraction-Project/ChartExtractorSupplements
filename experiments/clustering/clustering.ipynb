{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering Experiment\n",
    "\n",
    "We have put all of our methods together for direct comparison in a single notebook.\n",
    "\n",
    "Problem: Currently we are determining only the indiviudal digits, but we need to recognize these as coherent numbers and be able to assign entries to numbers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register Images to Start\n",
    "\n",
    "To start, we need to register images using the `utilities/conversion/apply_homography_to_labels.ipynb` notebook. This should be run before running this notebook. This notebook is built on the assumption that the `data/registered_images` directory has been created and populated. Additionally it assumes that the `data/yolo_data.json` file is created. Both of these are created in the referenced notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install Packages\n",
    "\n",
    "These are the necessary packages to run the functions and scripts below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Literal, Dict\n",
    "\n",
    "# Third-party libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.stats import gaussian_kde\n",
    "import random\n",
    "\n",
    "# Local libraries\n",
    "from utils.annotations import BoundingBox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start By Loading YOLO Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start I want to bring in the YOLO formatted data for each sheet and I can additionally load the respective images. As mentioned above you must have ran the `utilities/conversion/apply_homography_to_labels.ipynb` notebook to generate this YOLO data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19 sheets in yolo_data.json\n"
     ]
    }
   ],
   "source": [
    "# Load yolo_data.json\n",
    "PATH_TO_YOLO_DATA = \"../../data/yolo_data.json\"\n",
    "PATH_TO_REGISTERED_IMAGES = \"../../data/registered_images\"\n",
    "UNIFIED_IMAGE_PATH = (\n",
    "    \"../../data/unified_intraoperative_preoperative_flowsheet_v1_1_front.png\"\n",
    ")\n",
    "with open(PATH_TO_YOLO_DATA) as json_file:\n",
    "    yolo_data = json.load(json_file)\n",
    "\n",
    "# See how many intraoperative images are registered\n",
    "print(f\"Found {len(yolo_data)} sheets in yolo_data.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's select relevant bounding boxes from the blood pressure and HR zone.\n",
    "\n",
    "Start by defining functions to convert YOLO bounding box format to pixels (to see if the bounding box is within region of interest). Then create a function that allows you to select ROI and returns a list of bounding boxes within this ROI.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_bp_section_coordinates(\n",
    "#     image_height: int, bboxes: List[BoundingBox], buffer_pixels: int = 5\n",
    "# ) -> List[int]:\n",
    "#     \"\"\"Crops the blood pressure section out of an image of a chart.\n",
    "\n",
    "#     Args:\n",
    "#         image_height (int):\n",
    "#             The height of the image in pixels.\n",
    "#         bboxes (List[BoundingBox]):\n",
    "#             List of BoundingBoxes within this image.\n",
    "#         buffer_pixels (int):\n",
    "#             An optional integer that specifies the number of pixels around the digit detections to\n",
    "#             'zoom out' by. Defaults to 5 pixels.\n",
    "\n",
    "#     Returns:\n",
    "#         Coordinates of the bounding box that contains the blood pressure section.\n",
    "#     \"\"\"\n",
    "#     # Get bounding boxes from detections and filter non bounding boxes out.\n",
    "#     bboxes: List[BoundingBox] = list(\n",
    "#         filter(lambda ann: isinstance(ann, BoundingBox), bboxes)\n",
    "#     )\n",
    "\n",
    "#     digit_categories: List[str] = [str(i) for i in range(10)]\n",
    "\n",
    "#     # Filter bounding boxes to those which are within the approximate region and are digits.\n",
    "#     bp_legend_digits: List[BoundingBox] = list(\n",
    "#         filter(\n",
    "#             lambda bb: all(\n",
    "#                 [\n",
    "#                     bb.top / image_height > 0.2,\n",
    "#                     bb.top / image_height < 0.8,\n",
    "#                     bb.category in digit_categories,\n",
    "#                 ]\n",
    "#             ),\n",
    "#             bboxes,\n",
    "#         )\n",
    "#     )\n",
    "#     bp_legend_coordinates: List[int] = list(\n",
    "#         map(\n",
    "#             int,\n",
    "#             [\n",
    "#                 min([digit.left for digit in bp_legend_digits]) - buffer_pixels,\n",
    "#                 min([digit.top for digit in bp_legend_digits]) - buffer_pixels,\n",
    "#                 max([digit.right for digit in bp_legend_digits]) + buffer_pixels,\n",
    "#                 max([digit.bottom for digit in bp_legend_digits]) + buffer_pixels,\n",
    "#             ],\n",
    "#         )\n",
    "#     )\n",
    "#     return bp_legend_coordinates\n",
    "\n",
    "\n",
    "# def is_point_in_above(x_center: float, y_center: float, m: float, b: float) -> bool:\n",
    "#     \"\"\"\n",
    "#     Determine if a point is above or below the diagonal line y = mx + b.\n",
    "#     For our purposes we use it to check if a bounding box is in the top-right region -- meaning time labels.\n",
    "\n",
    "#     Args:\n",
    "#         x_center: float, x coordinate of the point\n",
    "#         y_center: float, y coordinate of the point\n",
    "#         m: float, slope of the diagonal line\n",
    "#         b: float, intercept of the diagonal line\n",
    "\n",
    "#     Returns:\n",
    "#         bool, True if the point is above the line, False otherwise\n",
    "#     \"\"\"\n",
    "#     # Calculate the y value on the line for the given x_center\n",
    "#     y_line = m * x_center + b\n",
    "#     return y_center > y_line\n",
    "\n",
    "\n",
    "# def select_relevant_bounding_boxes(\n",
    "#     sheet_data: List[str],\n",
    "#     path_to_image: Path,\n",
    "#     show_images: bool = False,\n",
    "#     desired_img_width: int = 800,\n",
    "#     desired_img_height: int = 600,\n",
    "# ) -> Tuple[List[str], List[str]]:\n",
    "#     \"\"\"\n",
    "#     Given sheet data for bounding boxes in YOLO format, display the image and allow the user to select a region of interest (ROI).\n",
    "#     Identify bounding boxes that are within the selected region and draw rectangles around them.\n",
    "#     Return the bounding boxes that are within the selected region split into two lists: time labels and numerical values.\n",
    "\n",
    "#     Args:\n",
    "#         sheet_data: List of bounding boxes in YOLO format.\n",
    "#         path_to_image: Path to the image file.\n",
    "\n",
    "#     Returns:\n",
    "#         Tuple of Lists of string representations of bounding boxes that are within the selected region, in YOLO format.\n",
    "#         The first list contains bounding boxes in the top-right region -- representing time labels.\n",
    "#         The second list contains bounding boxes in the bottom-left region -- representing numerical values for mmHg and bpm.\n",
    "#             (bounding_boxes_time, bounding_boxes_numbers)\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Load the image\n",
    "#     image = cv2.imread(path_to_image)\n",
    "\n",
    "#     # Display the image and allow the user to select a ROI\n",
    "#     resized_image = cv2.resize(image, (desired_img_width, desired_img_height))\n",
    "\n",
    "#     x_top_left, y_top_left, x_bottom_right, y_bottom_right = get_bp_section_coordinates(\n",
    "#         image_height=desired_img_height,\n",
    "#         bboxes=[\n",
    "#             BoundingBox.from_yolo(yolo_bb, desired_img_width, desired_img_height)\n",
    "#             for yolo_bb in sheet_data\n",
    "#         ],\n",
    "#         buffer_pixels=2,\n",
    "#     )\n",
    "\n",
    "#     cv2.rectangle(\n",
    "#         resized_image,\n",
    "#         (x_top_left, y_top_left),\n",
    "#         (x_bottom_right, y_bottom_right),\n",
    "#         (255, 255, 0),\n",
    "#         1,\n",
    "#     )\n",
    "\n",
    "#     # Draw the diagonal line of the selected region from top-left to bottom-right\n",
    "#     cv2.line(\n",
    "#         resized_image,\n",
    "#         (x_top_left, y_top_left),\n",
    "#         (x_bottom_right, y_bottom_right),\n",
    "#         (0, 255, 0),\n",
    "#         1,\n",
    "#     )\n",
    "#     # Calculate the slope (m) and intercept (b) of the diagonal line.\n",
    "#     # This will allow us to determine if a bounding box is in the top-right region or bottom-left region\n",
    "#     # Top-right region is where time labels are located\n",
    "#     # Bottom-left region is where numerical values for mmHg and bpm are located\n",
    "#     m = (y_bottom_right - y_top_left) / (x_bottom_right - x_top_left)\n",
    "#     b = y_top_left - m * x_top_left\n",
    "\n",
    "#     # List of bounding boxes in the top-right and bottom-left regions\n",
    "#     bounding_boxes_time = []\n",
    "#     bounding_boxes_numbers = []\n",
    "\n",
    "#     # Process the bounding boxes\n",
    "#     for bounding_box in sheet_data:\n",
    "#         # Bounding boxes are in YOLO format; convert them to pixels\n",
    "#         x_min, y_min, x_max, y_max = list(\n",
    "#             map(\n",
    "#                 int,\n",
    "#                 BoundingBox.from_yolo(\n",
    "#                     yolo_line=bounding_box,\n",
    "#                     image_width=desired_img_width,\n",
    "#                     image_height=desired_img_height,\n",
    "#                 ).box,\n",
    "#             )\n",
    "#         )\n",
    "\n",
    "#         # Check if the bounding box is within the selected region\n",
    "#         if (\n",
    "#             x_min >= x_top_left\n",
    "#             and y_min >= y_top_left\n",
    "#             and x_max <= x_bottom_right\n",
    "#             and y_max <= y_bottom_right\n",
    "#         ):\n",
    "#             # Calculate the center of the bounding box\n",
    "#             x_center_bb = (x_min + x_max) / 2\n",
    "#             y_center_bb = (y_min + y_max) / 2\n",
    "\n",
    "#             # If we want to generalize this function we can add the option to disregard the diagonal line\n",
    "\n",
    "#             # Determine if the bounding box center is in the top-right region\n",
    "#             if is_point_in_above(x_center_bb, y_center_bb, m, b):\n",
    "#                 # Bounding box is in the top-right region\n",
    "#                 cv2.rectangle(\n",
    "#                     resized_image, (x_min, y_min), (x_max, y_max), (255, 255, 0), 1\n",
    "#                 )\n",
    "#                 bounding_boxes_numbers.append(\n",
    "#                     BoundingBox.from_yolo(\n",
    "#                         yolo_line=bounding_box,\n",
    "#                         image_width=desired_img_width,\n",
    "#                         image_height=desired_img_height,\n",
    "#                     )\n",
    "#                 )\n",
    "#             else:\n",
    "#                 # Bounding box is in the bottom-left region\n",
    "#                 cv2.rectangle(\n",
    "#                     resized_image, (x_min, y_min), (x_max, y_max), (255, 0, 255), 1\n",
    "#                 )\n",
    "#                 bounding_boxes_time.append(\n",
    "#                     BoundingBox.from_yolo(\n",
    "#                         yolo_line=bounding_box,\n",
    "#                         image_width=desired_img_width,\n",
    "#                         image_height=desired_img_height,\n",
    "#                     )\n",
    "#                 )\n",
    "\n",
    "#     # Close all OpenCV windows, always do this or it will annoyingly not go away\n",
    "#     # You can also manually quit out with ESC key.\n",
    "#     cv2.destroyAllWindows()\n",
    "\n",
    "#     # If we are showing the images, display the image with the selected region and bounding boxes\n",
    "#     # Bounding boxes in the top-right region (time) are in one color while those in the bottom left (numerical) are in another\n",
    "#     if show_images:\n",
    "#         # Display the image with the selected region and bounding boxes\n",
    "#         resized_image = cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB)\n",
    "#         resized_image = Image.fromarray(resized_image)\n",
    "#         resized_image.show()\n",
    "\n",
    "#     # Return a tuple of bounding boxes in the top-right and bottom-left regions\n",
    "#     return (bounding_boxes_time, bounding_boxes_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_density_max(values: List[int], search_area: int) -> int:\n",
    "    \"\"\"\n",
    "    Given a list of values and a search area, find the index of where the highest density is.\n",
    "    The list of values correspond to identifying points for the bounding boxes and the search area corresponds to the images height or width.\n",
    "\n",
    "    Args:\n",
    "        values: List of identifying points for the bounding boxes\n",
    "        search_area: height/width of the image dependent on whether x or y axis is being search.\n",
    "\n",
    "    Returns:\n",
    "        The axis value that has the highest density of bounding boxes.\n",
    "    \"\"\"\n",
    "    kde = gaussian_kde(values, bw_method=0.2)\n",
    "\n",
    "    x_values = np.linspace(0, search_area, 10000)\n",
    "\n",
    "    kde_vals = kde(x_values)\n",
    "\n",
    "    max_index = np.argmax(kde_vals)\n",
    "    return x_values[max_index]\n",
    "\n",
    "\n",
    "def select_relevant_bounding_boxes(\n",
    "    sheet_data: List[str],\n",
    "    path_to_image: Path,\n",
    "    show_images: bool = False,\n",
    "    desired_img_width: int = 800,\n",
    "    desired_img_height: int = 600,\n",
    ") -> Tuple[List[str], List[str]]:\n",
    "    \"\"\"\n",
    "    Given sheet data for bounding boxes in YOLO format, find the bounding boxes corresponding to the number and time on the BP chart.\n",
    "    Return the bounding boxes that are within the selected region split into two lists: time labels and numerical values.\n",
    "\n",
    "    Args:\n",
    "        sheet_data: List of bounding boxes in YOLO format.\n",
    "        path_to_image: Path to the image file.\n",
    "\n",
    "    Returns:\n",
    "        Tuple of Lists of string representations of bounding boxes that are within the selected region, in YOLO format.\n",
    "        The first list contains bounding boxes in the top-right region -- representing time labels.\n",
    "        The second list contains bounding boxes in the bottom-left region -- representing numerical values for mmHg and bpm.\n",
    "            (bounding_boxes_time, bounding_boxes_numbers)\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the image\n",
    "    image = cv2.imread(path_to_image)\n",
    "\n",
    "    # Display the image and allow the user to select a ROI\n",
    "    resized_image = cv2.resize(image, (desired_img_width, desired_img_height))\n",
    "\n",
    "    # convert the YOLO data to Bounding Boxes\n",
    "    bboxes: List[BoundingBox] = [\n",
    "        BoundingBox.from_yolo(yolo_bb, desired_img_width, desired_img_height)\n",
    "        for yolo_bb in sheet_data\n",
    "    ]\n",
    "\n",
    "    # generate a list of the digit categories\n",
    "    digit_categories: List[str] = [str(i) for i in range(10)]\n",
    "\n",
    "    # filter out non bounding boxes and those whose category is not a digit\n",
    "    bboxes: List[BoundingBox] = list(\n",
    "        filter(\n",
    "            lambda bb: isinstance(bb, BoundingBox) and bb.category in digit_categories,\n",
    "            bboxes,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # find the point with the maximum density of bounding boxes\n",
    "    bboxes_right: List[int] = [bb.right for bb in bboxes]\n",
    "    # x_loc is the vertical line to the left of the time axis and right of the numbers axis\n",
    "    x_loc: int = find_density_max(bboxes_right, desired_img_width)\n",
    "\n",
    "    bboxes_bottom: List[int] = [bb.bottom for bb in bboxes]\n",
    "    # y_loc is the horizontal line undert the time axis and above the number axis\n",
    "    y_loc: int = find_density_max(bboxes_bottom, desired_img_height)\n",
    "\n",
    "    # x_loc_right is the vertical line at the end of the time axis\n",
    "    x_loc_right: int = x_loc + 610\n",
    "    # y_loc_bottom is the horizontal line at the bottom of the number axis\n",
    "    y_loc_bottom: int = y_loc + 185\n",
    "\n",
    "    bounding_boxes_time = []\n",
    "    bounding_boxes_numbers = []\n",
    "\n",
    "    # Process the bounding boxes\n",
    "    for bounding_box in bboxes:\n",
    "        # get the pixels for plotting\n",
    "        x_min = int(bounding_box.left)\n",
    "        x_max = int(bounding_box.right)\n",
    "        y_min = int(bounding_box.top)\n",
    "        y_max = int(bounding_box.bottom)\n",
    "        \n",
    "        # get the center point of the bounding box for comparison\n",
    "        x_center_bb, y_center_bb = bounding_box.center\n",
    "\n",
    "        # check if the bounding box is a number on the BP chart by comparing to the KDE index + a threshold\n",
    "        if ((x_center_bb > x_loc-15 and x_center_bb < x_loc+2) and (y_center_bb > y_loc-2 and y_center_bb < y_loc_bottom+2)):\n",
    "            # Bounding box is in the top-right region\n",
    "            cv2.rectangle(\n",
    "                resized_image, (x_min, y_min), (x_max, y_max), (255, 255, 0), 1\n",
    "            )\n",
    "            bounding_boxes_numbers.append(bounding_box)\n",
    "        # check if the bounding box is a time on the BP chart by comparing to the KDE index + a threshold\n",
    "        elif ((y_center_bb > y_loc-10 and y_max < y_loc+2) and (x_center_bb > x_loc-2 and x_center_bb < x_loc_right+2)):\n",
    "            cv2.rectangle(\n",
    "                resized_image, (x_min, y_min), (x_max, y_max), (255, 0, 255), 1\n",
    "            )\n",
    "            bounding_boxes_time.append(bounding_box)\n",
    "    # plot the lines of the KDE index found for debugging\n",
    "    # numbers_start = (int(x_loc), 0)\n",
    "    # numbers_end = (int(x_loc), desired_img_height)\n",
    "\n",
    "    # numbers2_start = (int(x_loc_right), 0)\n",
    "    # numbers2_end = (int(x_loc_right), desired_img_height)\n",
    "\n",
    "    # time_start = (0, int(y_loc))\n",
    "    # time_end = (desired_img_width, int(y_loc))\n",
    "\n",
    "    # time2_start = (0, int(y_loc_bottom))\n",
    "    # time2_end = (desired_img_width, int(y_loc_bottom))\n",
    "\n",
    "    # cv2.line(resized_image, numbers_start, numbers_end, (255,255,0), 1)\n",
    "    # cv2.line(resized_image, numbers2_start, numbers2_end, (255,255,0), 1)\n",
    "    # cv2.line(resized_image, time_start, time_end, (255,0,255), 1)\n",
    "    # cv2.line(resized_image, time2_start, time2_end, (255,0,255), 1)\n",
    "\n",
    "    # Close all OpenCV windows, always do this or it will annoyingly not go away\n",
    "    # You can also manually quit out with ESC key.\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # If we are showing the images, display the image with the selected region and bounding boxes\n",
    "    # Bounding boxes in the top-right region (time) are in one color while those in the bottom left (numerical) are in another\n",
    "    if show_images:\n",
    "        # Display the image with the selected region and bounding boxes\n",
    "        resized_image = cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB)\n",
    "        resized_image = Image.fromarray(resized_image)\n",
    "        resized_image.show()\n",
    "\n",
    "    # Return a tuple of bounding boxes in the top-right and bottom-left regions\n",
    "    return (bounding_boxes_time, bounding_boxes_numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function for K-means clustering, dbscan clustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_kmeans(\n",
    "    bounding_boxes: List[BoundingBox], possible_nclusters: List[int]\n",
    ") -> List[int]:\n",
    "    \"\"\"\n",
    "    Cluster bounding boxes using K-Means clustering algorithm.\n",
    "\n",
    "    Args:\n",
    "        bounding_boxes: List of bounding boxes in YOLO format.\n",
    "        possible_nclusters: List of possible number of clusters to try.\n",
    "\n",
    "    Returns:\n",
    "        List of cluster labels.\n",
    "    \"\"\"\n",
    "    # Convert to a NumPy array (using only x_center and y_center)\n",
    "    data = np.array([box.center for box in bounding_boxes])\n",
    "\n",
    "    cluster_performance_map = {}\n",
    "    for number_of_clusters in possible_nclusters:\n",
    "        if number_of_clusters > len(data):\n",
    "            raise (\n",
    "                f\"Number of clusters {number_of_clusters} is greater than number of bounding boxes {len(data)}.\"\n",
    "            )\n",
    "        if number_of_clusters < 1:\n",
    "            raise (f\"Number of clusters {number_of_clusters} must be greater than 0.\")\n",
    "        # Apply K-Means\n",
    "        kmeans = KMeans(\n",
    "            n_clusters=number_of_clusters,\n",
    "            init=\"k-means++\",\n",
    "            n_init=20,\n",
    "            max_iter=500,\n",
    "            tol=1e-8,\n",
    "            random_state=42,\n",
    "        )\n",
    "        kmeans.fit(data)\n",
    "\n",
    "        # Get cluster labels\n",
    "        labels = kmeans.predict(data)\n",
    "        silhouette_avg = silhouette_score(data, labels)\n",
    "\n",
    "        # print(\n",
    "        #     f\"Number of clusters: {number_of_clusters}, Silhouette score: {silhouette_avg}\"\n",
    "        # )\n",
    "\n",
    "        cluster_performance_map[number_of_clusters] = {\n",
    "            \"score\": silhouette_avg,\n",
    "            \"labels\": labels,\n",
    "        }\n",
    "\n",
    "    # Evaluate the performance of each number of clusters and select the one with the highest silhouette score\n",
    "    # if it is 0.003 greater than what should be the number of clusters otherwise go with proper_nclusters\n",
    "    n_clusters_max_silhouette = max(\n",
    "        cluster_performance_map, key=lambda x: cluster_performance_map[x][\"score\"]\n",
    "    )\n",
    "    best_n_clusters = (\n",
    "        n_clusters_max_silhouette\n",
    "        if (\n",
    "            (\n",
    "                cluster_performance_map[n_clusters_max_silhouette][\"score\"]\n",
    "                - cluster_performance_map[max(possible_nclusters)][\"score\"]\n",
    "            )\n",
    "            >= 0.003\n",
    "        )\n",
    "        else max(possible_nclusters)\n",
    "    )\n",
    "    return cluster_performance_map[best_n_clusters][\"labels\"]\n",
    "\n",
    "\n",
    "def dbscan_clustering(\n",
    "    bounding_boxes: List[BoundingBox], defined_eps: float, min_samples: int\n",
    ") -> List[int]:\n",
    "    \"\"\"\n",
    "    Cluster bounding boxes density based spatial clustering algorithm.\n",
    "\n",
    "    Args:\n",
    "        bounding_boxes: List of bounding boxes.\n",
    "        defined_eps: Maximum distance between two samples to be in the neighborhood of one another (center of BB).\n",
    "        min_samples: The number of samples (or total weight) for a point to be considered as core\n",
    "\n",
    "    Returns:\n",
    "        List of cluster labels.\n",
    "    \"\"\"\n",
    "    # Convert to a NumPy array (using only x_center and y_center)\n",
    "    data = np.array([box.center for box in bounding_boxes])\n",
    "\n",
    "    # DBSCAN\n",
    "    scan = DBSCAN(eps=defined_eps, min_samples=min_samples)\n",
    "    labels = scan.fit_predict(data)\n",
    "\n",
    "    return labels\n",
    "\n",
    "\n",
    "def agglomerative_clustering(\n",
    "    bounding_boxes: List[BoundingBox], possible_nclusters: List[int]\n",
    ") -> List[int]:\n",
    "    # make the bonding box data into a Numpy array\n",
    "    data = np.array([box.center for box in bounding_boxes])\n",
    "\n",
    "    # follow suit of the cluster_kmeans algorithm to measure accuracy through silhoutte scores\n",
    "    cluster_performance_map = {}\n",
    "    for number_of_clusters in possible_nclusters:\n",
    "        if number_of_clusters > len(data):\n",
    "            raise (\n",
    "                f\"Number of clusters {number_of_clusters} is greater than number of bounding boxes {len(data)}.\"\n",
    "            )\n",
    "        if number_of_clusters < 1:\n",
    "            raise (f\"Number of clusters {number_of_clusters} must be greater than 0.\")\n",
    "        # use agglomerative clustering\n",
    "        agg = AgglomerativeClustering(n_clusters=number_of_clusters, linkage=\"single\")\n",
    "        # get labels\n",
    "        labels = agg.fit_predict(data)\n",
    "        # compute the silhoutte scores\n",
    "        silhouette_avg = silhouette_score(data, labels)\n",
    "\n",
    "        cluster_performance_map[number_of_clusters] = {\n",
    "            \"score\": silhouette_avg,\n",
    "            \"labels\": labels,\n",
    "        }\n",
    "\n",
    "    # get the number of clusters with the best silhoutte score\n",
    "    n_clusters_max_silhouette = max(\n",
    "        cluster_performance_map, key=lambda x: cluster_performance_map[x][\"score\"]\n",
    "    )\n",
    "\n",
    "    best_n_clusters = (\n",
    "        n_clusters_max_silhouette\n",
    "        if (\n",
    "            (\n",
    "                cluster_performance_map[n_clusters_max_silhouette][\"score\"]\n",
    "                - cluster_performance_map[max(possible_nclusters)][\"score\"]\n",
    "            )\n",
    "            >= 0.003\n",
    "        )\n",
    "        else max(possible_nclusters)\n",
    "    )\n",
    "    return cluster_performance_map[best_n_clusters][\"labels\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to create a result dictionary that we can save as a JSON file to analyze performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_result_dictionary(\n",
    "    labels: List[str], bounding_boxes: List[BoundingBox], unit: Literal[\"mmHg\", \"mins\"]\n",
    ") -> Dict[int, int]:\n",
    "    \"\"\"\n",
    "    Create a dictionary with cluster labels as keys and lists of bounding boxes as values.\n",
    "\n",
    "    Args:\n",
    "        labels: List of cluster labels.\n",
    "        bounding_boxes: List of bounding boxes.\n",
    "        suffix: Suffix to append to the category of the bounding box. One of [\"mmHg\", \"mins\"].\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with cluster labels as keys and bounding box values as values.\n",
    "    \"\"\"\n",
    "    # Create a dictionary to store labelled elements\n",
    "    label_dict = {}\n",
    "\n",
    "    # Iterate over both lists\n",
    "    for label, element in zip(labels, bounding_boxes):\n",
    "        label = int(label)\n",
    "        if label not in label_dict:\n",
    "            # Create a new list for this label if it doesn't exist\n",
    "            label_dict[label] = []\n",
    "        # Append the element to the corresponding label list\n",
    "        label_dict[label].append(f\"{element.category} {element.center[0]}\")\n",
    "\n",
    "    # Sort the lists in the dictionary by x_center\n",
    "    for key in label_dict:\n",
    "        label_dict[key] = sorted(label_dict[key], key=lambda x: float(x.split(\" \")[1]))\n",
    "        label_dict[key] = [element.split(\" \")[0] for element in label_dict[key]]\n",
    "        # Turn list of strings into a string\n",
    "        label_dict[key] = f\"{''.join(label_dict[key])}_{unit}\"\n",
    "\n",
    "    return label_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to generate colors!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw bounding boxes on the image\n",
    "def generate_color():\n",
    "    return \"#%06x\" % random.randint(0, 0xFFFFFF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to generate random Bounding Box formatted occurances.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_time_generate(x):\n",
    "    # erroneous bounding boxes for time ROI\n",
    "    category_int = random.randint(0, 9)\n",
    "    left_int = random.randint(105, 720)\n",
    "\n",
    "    # slope and random points ABOVE the line (but coordinates flipped)\n",
    "    slope, intercept = 1 / 3, 225\n",
    "    top_int = random.uniform(225, slope * left_int + intercept)\n",
    "\n",
    "    # input generated integers to bounding box\n",
    "    box = BoundingBox(\n",
    "        category=f\"{category_int}\",\n",
    "        left=left_int,\n",
    "        top=top_int,\n",
    "        right=left_int + 4,\n",
    "        bottom=top_int + 6,\n",
    "    )\n",
    "    return box\n",
    "\n",
    "\n",
    "def random_number_generate(x):\n",
    "    # erroneous bounding boxes for number ROI\n",
    "    category_int = random.randint(0, 9)\n",
    "    left_int = random.randint(105, 720)\n",
    "\n",
    "    # slope and random points BELOW the line (but coordinates flipped)\n",
    "    slope, intercept = 1 / 3, 225\n",
    "    top_int = random.uniform(slope * left_int + intercept, 430)\n",
    "\n",
    "    # input generated integers to bounding box\n",
    "    box = BoundingBox(\n",
    "        category=f\"{category_int}\",\n",
    "        left=left_int,\n",
    "        top=top_int,\n",
    "        right=left_int + 4,\n",
    "        bottom=top_int + 6,\n",
    "    )\n",
    "    return box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to remove 5% bounding boxes and create 5% erroneous.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def erroneous_bounding_boxes(\n",
    "    time_BB: List[str], number_BB: List[str]\n",
    ") -> Tuple[List[str], List[str]]:\n",
    "    \"\"\"\n",
    "    Create 5% erroneous bounding boxes by simultaneously removing and generating time and number BB.\n",
    "\n",
    "    Args:\n",
    "        time_BB: list of time bounding boxes in BoundingBox format\n",
    "        number_BB: list of number bounding boxes in BoundingBox format\n",
    "\n",
    "    Returns:\n",
    "        Tuple: lists of time and number bounding boxes in BoundingBox format\n",
    "    \"\"\"\n",
    "    # make copies of input bounding box lists to avoid unwanted manipulation\n",
    "    time_BB_copy = time_BB.copy()\n",
    "    number_BB_copy = number_BB.copy()\n",
    "\n",
    "    # subset and remove 5% of bounding boxes from time/number_bounding_boxes lists\n",
    "    ## sample\n",
    "    time_BB_sample = list(random.sample(time_BB_copy, 4))\n",
    "    number_BB_sample = list(random.sample(number_BB_copy, 4))\n",
    "    ## remove\n",
    "    time_BB_removal = [time_BB_copy.remove(line) for line in time_BB_sample]\n",
    "    number_BB_removal = [number_BB_copy.remove(line) for line in number_BB_sample]\n",
    "\n",
    "    # use random bounding box generation to refill removed BBs with erroneous boxes\n",
    "    time_BB_generate = list(map(random_time_generate, range(len(time_BB_sample))))\n",
    "    number_BB_generate = list(map(random_number_generate, range(len(number_BB_sample))))\n",
    "\n",
    "    # append BB generated list back to copy with 5% removal\n",
    "    time_BB_erroneous = time_BB_copy + time_BB_generate\n",
    "    number_BB_erroneous = number_BB_copy + number_BB_generate\n",
    "\n",
    "    return (time_BB_erroneous, number_BB_erroneous)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets use these functions to get the relevant bounding boxes for clustering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sheet: RC_0001_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images/RC_0001_intraoperative.JPG\n",
      "Sheet: RC_0002_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images/RC_0002_intraoperative.JPG\n",
      "Sheet: RC_0003_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images/RC_0003_intraoperative.JPG\n",
      "Sheet: RC_0004_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images/RC_0004_intraoperative.JPG\n",
      "Sheet: RC_0005_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images/RC_0005_intraoperative.JPG\n",
      "Sheet: RC_0006_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images/RC_0006_intraoperative.JPG\n",
      "Sheet: RC_0007_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images/RC_0007_intraoperative.JPG\n",
      "Sheet: RC_0008_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images/RC_0008_intraoperative.JPG\n",
      "Sheet: RC_0009_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images/RC_0009_intraoperative.JPG\n",
      "Sheet: RC_0010_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images/RC_0010_intraoperative.JPG\n",
      "Sheet: RC_0011_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images/RC_0011_intraoperative.JPG\n",
      "Sheet: RC_0012_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images/RC_0012_intraoperative.JPG\n",
      "Sheet: RC_0013_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images/RC_0013_intraoperative.JPG\n",
      "Sheet: RC_0014_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images/RC_0014_intraoperative.JPG\n",
      "Sheet: RC_0015_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images/RC_0015_intraoperative.JPG\n",
      "Sheet: RC_0016_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images/RC_0016_intraoperative.JPG\n",
      "Sheet: RC_0017_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images/RC_0017_intraoperative.JPG\n",
      "Sheet: RC_0018_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images/RC_0018_intraoperative.JPG\n",
      "Sheet: RC_0019_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images/RC_0019_intraoperative.JPG\n",
      "Sheet: RC_0001_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images/RC_0001_intraoperative.JPG\n",
      "Sheet: RC_0002_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images/RC_0002_intraoperative.JPG\n",
      "Sheet: RC_0003_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images/RC_0003_intraoperative.JPG\n",
      "Sheet: RC_0004_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images/RC_0004_intraoperative.JPG\n",
      "Sheet: RC_0005_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images/RC_0005_intraoperative.JPG\n",
      "Sheet: RC_0006_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images/RC_0006_intraoperative.JPG\n",
      "Sheet: RC_0007_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images/RC_0007_intraoperative.JPG\n",
      "Sheet: RC_0008_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images/RC_0008_intraoperative.JPG\n",
      "Sheet: RC_0009_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images/RC_0009_intraoperative.JPG\n",
      "Sheet: RC_0010_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images/RC_0010_intraoperative.JPG\n",
      "Sheet: RC_0011_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images/RC_0011_intraoperative.JPG\n",
      "Sheet: RC_0012_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images/RC_0012_intraoperative.JPG\n",
      "Sheet: RC_0013_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images/RC_0013_intraoperative.JPG\n",
      "Sheet: RC_0014_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images/RC_0014_intraoperative.JPG\n",
      "Sheet: RC_0015_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images/RC_0015_intraoperative.JPG\n",
      "Sheet: RC_0016_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images/RC_0016_intraoperative.JPG\n",
      "Sheet: RC_0017_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images/RC_0017_intraoperative.JPG\n",
      "Sheet: RC_0018_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images/RC_0018_intraoperative.JPG\n",
      "Sheet: RC_0019_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images/RC_0019_intraoperative.JPG\n",
      "Sheet: RC_0001_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images/RC_0001_intraoperative.JPG\n",
      "Sheet: RC_0002_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images/RC_0002_intraoperative.JPG\n",
      "Sheet: RC_0003_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images/RC_0003_intraoperative.JPG\n",
      "Sheet: RC_0004_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images/RC_0004_intraoperative.JPG\n",
      "Sheet: RC_0005_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images/RC_0005_intraoperative.JPG\n",
      "Sheet: RC_0006_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images/RC_0006_intraoperative.JPG\n",
      "Sheet: RC_0007_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images/RC_0007_intraoperative.JPG\n",
      "Sheet: RC_0008_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images/RC_0008_intraoperative.JPG\n",
      "Sheet: RC_0009_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images/RC_0009_intraoperative.JPG\n",
      "Sheet: RC_0010_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images/RC_0010_intraoperative.JPG\n",
      "Sheet: RC_0011_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images/RC_0011_intraoperative.JPG\n",
      "Sheet: RC_0012_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images/RC_0012_intraoperative.JPG\n",
      "Sheet: RC_0013_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images/RC_0013_intraoperative.JPG\n",
      "Sheet: RC_0014_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images/RC_0014_intraoperative.JPG\n",
      "Sheet: RC_0015_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images/RC_0015_intraoperative.JPG\n",
      "Sheet: RC_0016_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images/RC_0016_intraoperative.JPG\n",
      "Sheet: RC_0017_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images/RC_0017_intraoperative.JPG\n",
      "Sheet: RC_0018_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images/RC_0018_intraoperative.JPG\n",
      "Sheet: RC_0019_intraoperative.JPG\n",
      "Full image path: ../../data/registered_images/RC_0019_intraoperative.JPG\n"
     ]
    }
   ],
   "source": [
    "def test_clustering_methods() -> None:\n",
    "    \"\"\"\n",
    "    Test the clustering methods on the YOLO data.\n",
    "    Saves the clustered images and the clustered bounding boxes to JSON files.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    for method in [\"kmeans\", \"dbscan\", \"agglomerative\"]:\n",
    "        # Iterate over all images and their bounding boxes\n",
    "        for sheet, yolo_bbs in yolo_data.items():\n",
    "            print(f\"Sheet: {sheet}\")\n",
    "            full_image_path = os.path.join(PATH_TO_REGISTERED_IMAGES, sheet)\n",
    "            print(f\"Full image path: {full_image_path}\")\n",
    "\n",
    "            # Call the analyze_sheet function with data from the loop\n",
    "            time_bounding_boxes, number_bounding_boxes = select_relevant_bounding_boxes(\n",
    "                yolo_bbs, full_image_path\n",
    "            )\n",
    "\n",
    "            # make erroneous bounding boxes -- simultaneously add and remove %5 of boxes\n",
    "            time_bounding_boxes, number_bounding_boxes = erroneous_bounding_boxes(\n",
    "                time_bounding_boxes, number_bounding_boxes\n",
    "            )\n",
    "\n",
    "            # Now we need to cluster the bounding boxes that pertain to the same multi-digit number\n",
    "            if method == \"kmeans\":\n",
    "                time_labels = cluster_kmeans(time_bounding_boxes, [40, 41, 42])\n",
    "                number_labels = cluster_kmeans(number_bounding_boxes, [18, 19, 20])\n",
    "            elif method == \"dbscan\":\n",
    "                time_labels = dbscan_clustering(\n",
    "                    time_bounding_boxes, defined_eps=5, min_samples=1\n",
    "                )\n",
    "                number_labels = dbscan_clustering(\n",
    "                    number_bounding_boxes, defined_eps=5, min_samples=2\n",
    "                )\n",
    "            elif method == \"agglomerative\":\n",
    "                time_labels = agglomerative_clustering(\n",
    "                    time_bounding_boxes, [40, 41, 42]\n",
    "                )\n",
    "                number_labels = agglomerative_clustering(\n",
    "                    number_bounding_boxes, [18, 19, 20]\n",
    "                )\n",
    "            else:\n",
    "                raise ValueError(f\"Invalid clustering method: {method}\")\n",
    "\n",
    "            # Create an image object\n",
    "            image: Image = Image.open(full_image_path)\n",
    "            image_width, image_height = image.size\n",
    "\n",
    "            label_color_map = {}\n",
    "            for i, label in enumerate(time_labels):\n",
    "                # Get the bounding box\n",
    "                bounding_box = time_bounding_boxes[i]\n",
    "                x_min, y_min, x_max, y_max = [\n",
    "                    (coor / 800) * image_width\n",
    "                    if i % 2 == 0\n",
    "                    else (coor / 600) * image_height\n",
    "                    for i, coor in enumerate(bounding_box.box)\n",
    "                ]\n",
    "\n",
    "                # If the label is not in the color map, generate a new color\n",
    "                if label not in label_color_map:\n",
    "                    label_color_map[label] = generate_color()\n",
    "\n",
    "                # Open the image\n",
    "                draw = ImageDraw.Draw(image)\n",
    "\n",
    "                draw.rectangle(\n",
    "                    [\n",
    "                        x_min,\n",
    "                        y_min,\n",
    "                        x_max,\n",
    "                        y_max,\n",
    "                    ],\n",
    "                    outline=label_color_map[label],\n",
    "                    width=3,\n",
    "                )\n",
    "\n",
    "            # Save the image with the bounding boxes to the kmeans_clustered_images folder\n",
    "            image.save(f\"../../data/{method}_clustered_images/time/{sheet}\")\n",
    "\n",
    "            # Save the clustered bounding boxes to a JSON file\n",
    "            with open(\n",
    "                f\"../../data/{method}_clustered_images/results/time/{sheet.split('.')[0]}.json\",\n",
    "                \"w\",\n",
    "            ) as f:\n",
    "                json.dump(\n",
    "                    create_result_dictionary(time_labels, time_bounding_boxes, \"mins\"),\n",
    "                    f,\n",
    "                )\n",
    "\n",
    "            # Create an image object\n",
    "            image: Image = Image.open(full_image_path)\n",
    "            image_width, image_height = image.size\n",
    "            label_color_map = {}\n",
    "            for i, label in enumerate(number_labels):\n",
    "                # Get the bounding box\n",
    "                bounding_box = number_bounding_boxes[i]\n",
    "                x_min, y_min, x_max, y_max = [\n",
    "                    (coor / 800) * image_width\n",
    "                    if i % 2 == 0\n",
    "                    else (coor / 600) * image_height\n",
    "                    for i, coor in enumerate(bounding_box.box)\n",
    "                ]\n",
    "\n",
    "                # If the label is not in the color map, generate a new color\n",
    "                if label not in label_color_map:\n",
    "                    label_color_map[label] = generate_color()\n",
    "\n",
    "                # Open the image\n",
    "                draw = ImageDraw.Draw(image)\n",
    "\n",
    "                draw.rectangle(\n",
    "                    [\n",
    "                        x_min,\n",
    "                        y_min,\n",
    "                        x_max,\n",
    "                        y_max,\n",
    "                    ],\n",
    "                    outline=label_color_map[label],\n",
    "                    width=3,\n",
    "                )\n",
    "\n",
    "            # Save the image with the bounding boxes to the kmeans_clustered_images folder\n",
    "            image.save(f\"../../data/{method}_clustered_images/number/{sheet}\")\n",
    "\n",
    "            # Save the clustered bounding boxes to a JSON file\n",
    "            with open(\n",
    "                f\"../../data/{method}_clustered_images/results/number/{sheet.split('.')[0]}.json\",\n",
    "                \"w\",\n",
    "            ) as f:\n",
    "                json.dump(\n",
    "                    create_result_dictionary(\n",
    "                        number_labels, number_bounding_boxes, \"mmHg\"\n",
    "                    ),\n",
    "                    f,\n",
    "                )\n",
    "\n",
    "\n",
    "# Test the clustering methods\n",
    "test_clustering_methods()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyze accuracy\n",
    "\n",
    "Below we use assumptions on what we know the labels should represent in both the time and number groups. We check that these values are present within clusters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: kmeans\n",
      "Time labels: 651 correct clusters, 138 incorrect clusters. The accuracy is 82.51%\n",
      "Number labels: 192 correct clusters, 181 incorrect clusters. The accuracy is 51.47%\n",
      "Method: dbscan\n",
      "Time labels: 729 correct clusters, 130 incorrect clusters. The accuracy is 84.87%\n",
      "Number labels: 304 correct clusters, 57 incorrect clusters. The accuracy is 84.21%\n",
      "Method: agglomerative\n",
      "Time labels: 628 correct clusters, 165 incorrect clusters. The accuracy is 79.19%\n",
      "Number labels: 185 correct clusters, 189 incorrect clusters. The accuracy is 49.47%\n"
     ]
    }
   ],
   "source": [
    "# Since this work is done above, we can simply read in from the JSON files created in the previous step and work from there.\n",
    "for method in [\"kmeans\", \"dbscan\", \"agglomerative\"]:\n",
    "    print(f\"Method: {method}\")\n",
    "    # Paths to the JSON files\n",
    "    PATH_TO_KMEANS_RESULTS = f\"../../data/{method}_clustered_images/results\"\n",
    "    TIME_JSON = os.path.join(PATH_TO_KMEANS_RESULTS, \"time\")\n",
    "    NUMBER_JSON = os.path.join(PATH_TO_KMEANS_RESULTS, \"number\")\n",
    "\n",
    "    time_wrong_clusters_count = 0\n",
    "    time_correct_clusters_count = 0\n",
    "    number_wrong_clusters_count = 0\n",
    "    number_correct_clusters_count = 0\n",
    "\n",
    "    # Iterate over all images and their bounding boxes\n",
    "    for sheet, yolo_bb in yolo_data.items():\n",
    "        full_image_path = os.path.join(PATH_TO_REGISTERED_IMAGES, sheet)\n",
    "        time_bounding_boxes, number_bounding_boxes = select_relevant_bounding_boxes(\n",
    "            yolo_bb, full_image_path, show_images=True\n",
    "        )\n",
    "        # Convert the bounding boxes to a list of strings with proper suffixes\n",
    "        expected_time_values = [\n",
    "            \"0_mins\",\n",
    "            \"5_mins\",\n",
    "            \"10_mins\",\n",
    "            \"15_mins\",\n",
    "            \"20_mins\",\n",
    "            \"25_mins\",\n",
    "            \"30_mins\",\n",
    "            \"35_mins\",\n",
    "            \"40_mins\",\n",
    "            \"45_mins\",\n",
    "            \"50_mins\",\n",
    "            \"55_mins\",\n",
    "            \"0_mins\",\n",
    "            \"5_mins\",\n",
    "            \"10_mins\",\n",
    "            \"15_mins\",\n",
    "            \"20_mins\",\n",
    "            \"25_mins\",\n",
    "            \"30_mins\",\n",
    "            \"35_mins\",\n",
    "            \"40_mins\",\n",
    "            \"45_mins\",\n",
    "            \"50_mins\",\n",
    "            \"55_mins\",\n",
    "            \"0_mins\",\n",
    "            \"5_mins\",\n",
    "            \"10_mins\",\n",
    "            \"15_mins\",\n",
    "            \"20_mins\",\n",
    "            \"25_mins\",\n",
    "            \"30_mins\",\n",
    "            \"35_mins\",\n",
    "            \"40_mins\",\n",
    "            \"45_mins\",\n",
    "            \"50_mins\",\n",
    "            \"55_mins\",\n",
    "            \"0_mins\",\n",
    "            \"5_mins\",\n",
    "            \"10_mins\",\n",
    "            \"15_mins\",\n",
    "            \"20_mins\",\n",
    "            \"25_mins\",\n",
    "        ]\n",
    "\n",
    "        expected_number_values = [\n",
    "            \"30_mmHg\",\n",
    "            \"40_mmHg\",\n",
    "            \"50_mmHg\",\n",
    "            \"60_mmHg\",\n",
    "            \"70_mmHg\",\n",
    "            \"80_mmHg\",\n",
    "            \"90_mmHg\",\n",
    "            \"100_mmHg\",\n",
    "            \"110_mmHg\",\n",
    "            \"120_mmHg\",\n",
    "            \"130_mmHg\",\n",
    "            \"140_mmHg\",\n",
    "            \"150_mmHg\",\n",
    "            \"160_mmHg\",\n",
    "            \"170_mmHg\",\n",
    "            \"180_mmHg\",\n",
    "            \"190_mmHg\",\n",
    "            \"200_mmHg\",\n",
    "            \"210_mmHg\",\n",
    "            \"220_mmHg\",\n",
    "        ]\n",
    "\n",
    "        # Load JSON\n",
    "        with open(os.path.join(TIME_JSON, f\"{sheet.split('.')[0]}.json\")) as f:\n",
    "            time_clusters = json.load(f)\n",
    "\n",
    "        # Each cluster contains the number (integer) that the cluster represents\n",
    "        # We know what integers should be represented in the time labels, lets check that they are all there.\n",
    "        # Keep track of any false positives (new clusters that don't exist) or negatives (missing clusters)\n",
    "        for cluster, value in time_clusters.items():\n",
    "            if value not in expected_time_values:\n",
    "                # Print the sheet, value that is not in the expected values\n",
    "                # print(f\"Time -> Sheet: {sheet}, Value: {value}\")\n",
    "                # We have an erroneous cluster\n",
    "                time_wrong_clusters_count += 1\n",
    "            else:\n",
    "                # We have a correct cluster\n",
    "                expected_time_values.remove(value)\n",
    "                time_correct_clusters_count += 1\n",
    "\n",
    "        # Load JSON\n",
    "        with open(os.path.join(NUMBER_JSON, f\"{sheet.split('.')[0]}.json\")) as f:\n",
    "            number_clusters = json.load(f)\n",
    "\n",
    "        # Each cluster contains the number (integer) that the cluster represents\n",
    "        # We know what integers should be represented in the time labels, lets check that they are all there.\n",
    "        # Keep track of any false positives (new clusters that don't exist) or negatives (missing clusters)\n",
    "        for cluster, value in number_clusters.items():\n",
    "            if value not in expected_number_values:\n",
    "                # print(f\"Time -> Sheet: {sheet}, Value: {value}\")\n",
    "                # We have an erroneous cluster\n",
    "                number_wrong_clusters_count += 1\n",
    "            else:\n",
    "                # We have a correct cluster\n",
    "                expected_number_values.remove(value)\n",
    "                number_correct_clusters_count += 1\n",
    "\n",
    "    print(\n",
    "        f\"Time labels: {time_correct_clusters_count} correct clusters, {time_wrong_clusters_count} incorrect clusters. The accuracy is {time_correct_clusters_count / (time_correct_clusters_count + time_wrong_clusters_count) * 100:.2f}%\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Number labels: {number_correct_clusters_count} correct clusters, {number_wrong_clusters_count} incorrect clusters. The accuracy is {number_correct_clusters_count / (number_correct_clusters_count + number_wrong_clusters_count) * 100:.2f}%\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
