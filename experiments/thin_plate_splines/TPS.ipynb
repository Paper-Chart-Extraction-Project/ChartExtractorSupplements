{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thin Plate Splines Transformations\n",
    "\n",
    "**Purpose:** The purpose of this experiment to implement thin plate spline transformations on images. The goal is to help normalize images of charts that have been folded or bent. TPS registration will be performed post-homography"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are Thin Plate Splines\n",
    "\n",
    "For our purpose, a thin plate spline transformation can be defined as follows:  \n",
    "Given a set of \"source\" points $P_s$ and a corresponding set of \"destination\" points $P_d$, the thin plate spline transformation is a function  \n",
    "$f_{tps}(p) | \\forall p_s \\in P_s, f_{tps}$ and $f$ is the function when \"bends\" all other points the least among all differentiable functions (meaning it minimizes an energy function).  \n",
    "\n",
    "![thin_plate_spline_example](https://github.com/user-attachments/assets/9f269c79-6d5d-4090-988c-39ee9e928ff0)\n",
    "\n",
    "In this image there are two sets of points which form fish shapes. The red '+' points represent the destination points, and the green 'o' points represent the source points. On the right we see the thin plate spline deformation which makes all the green points exactly match all the red points, and we can also see a grid that shows where all other points on the plane will be mapped as well.  \n",
    "\n",
    "## Benefits for Image Registration\n",
    "While the homography is a very reliable transformation, it is limited to purely linear transformations (ex: rotation, scaling, shear).  \n",
    "Very commonly, pages will be creased or folded, the edge of pages will curl inwards or outwards, or some cameras will cause barrel/pinhole distortions.  \n",
    "This leads to a whole subset of issues that cannot be corrected linearly, but still must be accounted for.\n",
    "\n",
    "![smaller_RC_0033_preoperative_postoperative](https://github.com/user-attachments/assets/f22374e1-75b4-4a07-816f-d3ad51e84921)\n",
    "An example of a paper which has been folded. and unfolded, causing non-linear distortions. This is a *very* modest example. In practice, we have seen photographs of papers that are raised at least an inch off the table in certain areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import  Path\n",
    "from typing import Dict, List, Tuple\n",
    "from utils.annotations import BoundingBox\n",
    "from collections import Counter\n",
    "from PIL import Image\n",
    "from scipy.interpolate import Rbf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data for testing:\n",
    "- \"intraop_document_landmarks.json\"\n",
    "    - Used for the destination points in the transformation. We are using the landmarks from the unified image\n",
    "    - Also has landmarks for each of the images. We currently are not using them\n",
    "- \"yolo_data.json\"\n",
    "    - Used for the source points in the transformation.\n",
    "    - May need to be replace with the landmarks from the other file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19 sheets in yolo_data.json\n"
     ]
    }
   ],
   "source": [
    "# Load yolo_data.json which will be used as src_points\n",
    "PATH_TO_YOLO_DATA = \"../../data/yolo_data.json\"\n",
    "PATH_TO_REGISTERED_IMAGES = \"../../data/registered_images\"\n",
    "\n",
    "with open(PATH_TO_YOLO_DATA) as json_file:\n",
    "    yolo_data = json.load(json_file)\n",
    "\n",
    "print(f\"Found {len(yolo_data)} sheets in yolo_data.json\")\n",
    "\n",
    "# load introp_document_landmarks.json which will be used as dst_points\n",
    "PATH_TO_LANDMARKS = \"../../data/intraop_document_landmarks.json\"\n",
    "\n",
    "DESIRED_IMAGE_WIDTH = 800\n",
    "DESIRED_IMAGE_HEIGHT = 600\n",
    "\n",
    "def label_studio_to_bboxes(path_to_json_data: Path) -> List[BoundingBox]:\n",
    "    json_data: List[Dict] = json.loads(open(str(path_to_json_data)).read())\n",
    "    return {\n",
    "        sheet_data['data']['image'].split(\"-\")[-1]:[\n",
    "            BoundingBox(\n",
    "                category=label['value']['rectanglelabels'][0],\n",
    "                left=label['value']['x']/100*DESIRED_IMAGE_WIDTH,\n",
    "                top=label['value']['y']/100*DESIRED_IMAGE_HEIGHT,\n",
    "                right=(label['value']['x']/100+label['value']['width']/100)*DESIRED_IMAGE_WIDTH,\n",
    "                bottom=(label['value']['y']/100+label['value']['height']/100)*DESIRED_IMAGE_HEIGHT,\n",
    "            )\n",
    "            for label in sheet_data['annotations'][0]['result']\n",
    "        ]\n",
    "        for sheet_data in json_data\n",
    "    }\n",
    "\n",
    "landmark_location_data: Dict[str, List[BoundingBox]] = label_studio_to_bboxes(PATH_TO_LANDMARKS)\n",
    "\n",
    "landmarks = landmark_location_data['unified_intraoperative_preoperative_flowsheet_v1_1_front.png']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TPS Tranformation**\n",
    "Steps:\n",
    "1. Filter to keep only the relevant bounding boxes\n",
    "    - remove all bounding boxes from the source points that do not match a category in the destination points\n",
    "    - Find all of the duplicates in the source and destination points and remove them\n",
    "    - sort the source and destination points alphabetically via their category\n",
    "2. Get lists of the x and y coordinates for both the source and destination points\n",
    "    - Primary purpose is to enable the use of scipy's Rbf function\n",
    "    - We are using the top left corner of the bounding boxes\n",
    "3. Estimate the transformation\n",
    "    - Use the Rbf function to apply the TPS transformation\n",
    "4. Apply the transformation and Warp the image\n",
    "     - Create a grid from 0 to maximum value of the image\n",
    "     - Apply the transformation to the grids\n",
    "     - Ensure that the transformed points are within bounds\n",
    "     - Use those grids to warp the original image\n",
    "\n",
    "*Note:* There are a lot of different outputs that are currently commented out that can be used for debugging purposes:\n",
    "- Print the lists of duplicate keys and the categories being used in the source and destination points\n",
    "- Plot of the source and destination points on the image\n",
    "- View the bounds of the transformed points\n",
    "- View the distribution of the transformed points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tps_transform(image, src_points: List[BoundingBox], dst_points: List[BoundingBox]):\n",
    "\n",
    "    # get the categories from dst_points\n",
    "    landmark_cats = [bb.category for bb in dst_points]\n",
    "    # remove all bbs in src that are not in those categories\n",
    "    src_points = [bb for bb in src_points if bb.category in landmark_cats]\n",
    "    # get list of duplicate keys\n",
    "    duplicate_count_src = dict(Counter([bb.category for bb in src_points]))\n",
    "    duplicates = [k for k, v in duplicate_count_src.items() if v > 1]\n",
    "    duplicate_count_dst = dict(Counter([bb.category for bb in dst_points]))\n",
    "    duplicates.extend([k for k, v in duplicate_count_dst.items() if v > 1])\n",
    "    duplicates = list(set(duplicates)) \n",
    "    # print(duplicates)\n",
    "    # remove duplicates\n",
    "    src_points = [bb for bb in src_points if bb.category not in duplicates]\n",
    "    dst_points = [bb for bb in dst_points if bb.category not in duplicates]\n",
    "    # sort categories alphabetically\n",
    "    src_points = sorted(src_points, key = lambda bb: bb.category)\n",
    "    # print([bb.category for bb in src_points])\n",
    "    dst_points = sorted(dst_points, key = lambda bb: bb.category)\n",
    "    # print([bb.category for bb in dst_points])\n",
    "\n",
    "    # get lists of the x and y coordinates\n",
    "    src_x , src_y = zip(*[(bb.left, bb.top) for bb in src_points])\n",
    "    dst_x, dst_y = zip(*[(bb.left, bb.top) for bb in dst_points])\n",
    "\n",
    "    # remove source points with suspiciously high distances to their destination counterparts\n",
    "    threshold = 2.0\n",
    "    # difference in source and destination x\n",
    "    delta_x = np.array(src_x) - np.array(dst_x)\n",
    "    # boolean list for source points if larger than the threshold\n",
    "    tf_x = [abs(point) < threshold for point in delta_x]\n",
    "    # difference in source and destination y\n",
    "    delta_y = np.array(src_y) - np.array(dst_y)\n",
    "    # boolean list for source points if larger than the threshold\n",
    "    tf_y = [abs(point) < threshold for point in delta_y]\n",
    "    # compare x and y boolean lists and combine to remove points with either above thershold\n",
    "    delta_combo = [np.False_ if (x==np.False_ or  y==np.False_) else np.True_ for x, y in zip(tf_x, tf_y)]\n",
    "    # remove source and destination x points if their delta is too large\n",
    "    new_src_x = [point for point, delta in zip(src_x, delta_combo) if delta == np.True_]\n",
    "    new_dst_x = [point for point, delta in zip(dst_x, delta_combo) if delta == np.True_]\n",
    "    # remove source and destination y points if their delta is too large\n",
    "    new_src_y = [point for point, delta in zip(src_y, delta_combo) if delta == np.True_]\n",
    "    new_dst_y = [point for point, delta in zip(dst_y, delta_combo) if delta == np.True_]\n",
    "\n",
    "\n",
    "    # plt.imshow(image)\n",
    "    # plt.scatter(src_x, src_y, color='blue', label='Source Points')\n",
    "    # plt.scatter(dst_x, dst_y, color='red', label='Destination Points')\n",
    "    # plt.legend()\n",
    "    # plt.title(\"Source and Destination Control Points\")\n",
    "    # plt.show()\n",
    "\n",
    "    # use RBF function to do the thin plate splines\n",
    "    rbf_x = Rbf(new_dst_x, new_dst_y, new_src_x, function=\"thin_plate\")\n",
    "    rbf_y = Rbf(new_dst_x, new_dst_y, new_src_y, function=\"thin_plate\")\n",
    "\n",
    "\n",
    "    # Alter the image according to the transformation\n",
    "    h, w, _ = image.shape\n",
    "    # create grid\n",
    "    x = np.linspace(0, w-1, w)\n",
    "    y = np.linspace(0, h-1, h)\n",
    "    grid_x, grid_y = np.meshgrid(x, y)\n",
    "\n",
    "    # apply the transformation\n",
    "    # reshape into grid\n",
    "    transformed_x = rbf_x(grid_x, grid_y).astype(np.float32)\n",
    "    transformed_y = rbf_y(grid_x, grid_y).astype(np.float32)\n",
    "\n",
    "    transformed_x = np.clip(transformed_x, 0, image.shape[1] - 1)\n",
    "    transformed_y = np.clip(transformed_y, 0, image.shape[0] - 1)\n",
    "\n",
    "\n",
    "    # print(f\"Transformed X range: {np.min(transformed_x)}, {np.max(transformed_x)}\")\n",
    "    # print(f\"Transformed Y range: {np.min(transformed_y)}, {np.max(transformed_y)}\")\n",
    "\n",
    "    # plt.imshow(transformed_x, cmap='coolwarm', interpolation='nearest')\n",
    "    # plt.title(\"Transformed X Coordinates\")\n",
    "    # plt.show()\n",
    "\n",
    "    # plt.imshow(transformed_y, cmap='coolwarm', interpolation='nearest')\n",
    "    # plt.title(\"Transformed Y Coordinates\")\n",
    "    # plt.show()\n",
    "\n",
    "    # warp the image\n",
    "    warp_img = cv2.remap(image, transformed_x, transformed_y, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    return warp_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(87987) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(87989) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(88008) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(88010) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(88020) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(88029) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(88039) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(88040) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(88049) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(88050) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(88059) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(88066) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(88077) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(88078) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(88088) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(88089) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(88098) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(88099) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(88108) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(88109) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(88119) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(88120) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(88129) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(88130) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(88140) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(88141) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(88150) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(88151) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(88160) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(88161) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(88170) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(88171) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(88172) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(88173) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(88191) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(88192) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(88201) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(88202) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    }
   ],
   "source": [
    "for sheet, yolo_bbs in yolo_data.items():\n",
    "    # get path to current image\n",
    "    full_image_path = os.path.join(PATH_TO_REGISTERED_IMAGES, sheet)\n",
    "    image = cv2.imread(full_image_path)\n",
    "    resized_img = cv2.resize(image, (DESIRED_IMAGE_WIDTH, DESIRED_IMAGE_HEIGHT))\n",
    "    # get the sheet's bounding boxes\n",
    "    sheet_bbs = [BoundingBox.from_yolo(bb, DESIRED_IMAGE_WIDTH, DESIRED_IMAGE_HEIGHT) for bb in yolo_bbs]\n",
    "    transformed_img = tps_transform(resized_img, sheet_bbs, landmarks)\n",
    "    transformed_img = Image.fromarray(transformed_img)\n",
    "    transformed_img.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tps_transform_ransac(image, src_points: List[BoundingBox], dst_points: List[BoundingBox]):\n",
    "\n",
    "    # get the categories from dst_points\n",
    "    landmark_cats = [bb.category for bb in dst_points]\n",
    "    # remove all bbs in src that are not in those categories\n",
    "    src_points = [bb for bb in src_points if bb.category in landmark_cats]\n",
    "    # get list of duplicate keys\n",
    "    duplicate_count_src = dict(Counter([bb.category for bb in src_points]))\n",
    "    duplicates = [k for k, v in duplicate_count_src.items() if v > 1]\n",
    "    duplicate_count_dst = dict(Counter([bb.category for bb in dst_points]))\n",
    "    duplicates.extend([k for k, v in duplicate_count_dst.items() if v > 1])\n",
    "    duplicates = list(set(duplicates)) \n",
    "    # print(duplicates)\n",
    "    # remove duplicates\n",
    "    src_points = [bb for bb in src_points if bb.category not in duplicates]\n",
    "    dst_points = [bb for bb in dst_points if bb.category not in duplicates]\n",
    "    # sort categories alphabetically\n",
    "    src_points = sorted(src_points, key = lambda bb: bb.category)\n",
    "    # print([bb.category for bb in src_points])\n",
    "    dst_points = sorted(dst_points, key = lambda bb: bb.category)\n",
    "    # print([bb.category for bb in dst_points])\n",
    "\n",
    "    src_points = np.array([[bb.left, bb.top] for bb in src_points], dtype=np.float32)\n",
    "    dst_points = np.array([[bb.left, bb.top] for bb in dst_points], dtype=np.float32)\n",
    "\n",
    "    _, mask = cv2.findHomography(dst_points, src_points, method=cv2.RANSAC, ransacReprojThreshold=10.0, maxIters=5000, confidence=0.99)\n",
    "    inlier_mask = mask.ravel() == 1\n",
    "\n",
    "    filtered_src = src_points[inlier_mask]\n",
    "    filtered_dst = dst_points[inlier_mask]\n",
    "\n",
    "    new_src_x, new_src_y = filtered_src[:, 0], filtered_src[:, 1]\n",
    "    new_dst_x, new_dst_y = filtered_dst[:, 0], filtered_dst[:, 1]\n",
    "\n",
    "    if len(new_src_x) < 4:\n",
    "        return image\n",
    "\n",
    "    # plt.imshow(image)\n",
    "    # plt.scatter(src_x, src_y, color='blue', label='Source Points')\n",
    "    # plt.scatter(dst_x, dst_y, color='red', label='Destination Points')\n",
    "    # plt.legend()\n",
    "    # plt.title(\"Source and Destination Control Points\")\n",
    "    # plt.show()\n",
    "\n",
    "    # use RBF function to do the thin plate splines\n",
    "    rbf_x = Rbf(new_dst_x, new_dst_y, new_src_x, function=\"thin_plate\")\n",
    "    rbf_y = Rbf(new_dst_x, new_dst_y, new_src_y, function=\"thin_plate\")\n",
    "\n",
    "\n",
    "    # Alter the image according to the transformation\n",
    "    h, w, _ = image.shape\n",
    "    # create grid\n",
    "    x = np.linspace(0, w-1, w)\n",
    "    y = np.linspace(0, h-1, h)\n",
    "    grid_x, grid_y = np.meshgrid(x, y)\n",
    "\n",
    "    # apply the transformation\n",
    "    # reshape into grid\n",
    "    transformed_x = rbf_x(grid_x, grid_y).astype(np.float32)\n",
    "    transformed_y = rbf_y(grid_x, grid_y).astype(np.float32)\n",
    "\n",
    "    transformed_x = np.clip(transformed_x, 0, image.shape[1] - 1)\n",
    "    transformed_y = np.clip(transformed_y, 0, image.shape[0] - 1)\n",
    "\n",
    "\n",
    "    # print(f\"Transformed X range: {np.min(transformed_x)}, {np.max(transformed_x)}\")\n",
    "    # print(f\"Transformed Y range: {np.min(transformed_y)}, {np.max(transformed_y)}\")\n",
    "\n",
    "    # plt.imshow(transformed_x, cmap='coolwarm', interpolation='nearest')\n",
    "    # plt.title(\"Transformed X Coordinates\")\n",
    "    # plt.show()\n",
    "\n",
    "    # plt.imshow(transformed_y, cmap='coolwarm', interpolation='nearest')\n",
    "    # plt.title(\"Transformed Y Coordinates\")\n",
    "    # plt.show()\n",
    "\n",
    "    # warp the image\n",
    "    warp_img = cv2.remap(image, transformed_x, transformed_y, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    return warp_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(88211) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(88212) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(88221) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(88222) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(88232) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(88233) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(88242) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(88243) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(88252) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(88253) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(88262) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(88263) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(88272) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(88273) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(88283) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(88284) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(88293) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(88294) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(88303) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(88304) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(88313) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(88314) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(88323) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(88324) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(88334) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(88335) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(88344) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(88345) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(88354) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(88363) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(88365) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(88366) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(88384) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(88385) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(88394) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(88395) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(88404) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(88405) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    }
   ],
   "source": [
    "for sheet, yolo_bbs in yolo_data.items():\n",
    "    # get path to current image\n",
    "    full_image_path = os.path.join(PATH_TO_REGISTERED_IMAGES, sheet)\n",
    "    image = cv2.imread(full_image_path)\n",
    "    resized_img = cv2.resize(image, (DESIRED_IMAGE_WIDTH, DESIRED_IMAGE_HEIGHT))\n",
    "    # get the sheet's bounding boxes\n",
    "    sheet_bbs = [BoundingBox.from_yolo(bb, DESIRED_IMAGE_WIDTH, DESIRED_IMAGE_HEIGHT) for bb in yolo_bbs]\n",
    "    transformed_img = tps_transform_ransac(resized_img, sheet_bbs, landmarks)\n",
    "    transformed_img = Image.fromarray(transformed_img)\n",
    "    transformed_img.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
