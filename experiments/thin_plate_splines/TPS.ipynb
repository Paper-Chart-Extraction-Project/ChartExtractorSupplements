{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thin Plate Splines Transformations\n",
    "\n",
    "**Purpose:** The purpose of this experiment to implement thin plate spline transformations on images. The goal is to help normalize images of charts that have been folded or bent. TPS registration will be performed post-homography\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are Thin Plate Splines\n",
    "\n",
    "For our purpose, a thin plate spline transformation can be defined as follows:  \n",
    "Given a set of \"source\" points $P_s$ and a corresponding set of \"destination\" points $P_d$, the thin plate spline transformation is a function  \n",
    "$f_{tps}(p) | \\forall p_s \\in P_s, f_{tps}$ and $f$ is the function when \"bends\" all other points the least among all differentiable functions (meaning it minimizes an energy function).\n",
    "\n",
    "![thin_plate_spline_example](https://github.com/user-attachments/assets/9f269c79-6d5d-4090-988c-39ee9e928ff0)\n",
    "\n",
    "In this image there are two sets of points which form fish shapes. The red '+' points represent the destination points, and the green 'o' points represent the source points. On the right we see the thin plate spline deformation which makes all the green points exactly match all the red points, and we can also see a grid that shows where all other points on the plane will be mapped as well.\n",
    "\n",
    "## Benefits for Image Registration\n",
    "\n",
    "While the homography is a very reliable transformation, it is limited to purely linear transformations (ex: rotation, scaling, shear).  \n",
    "Very commonly, pages will be creased or folded, the edge of pages will curl inwards or outwards, or some cameras will cause barrel/pinhole distortions.  \n",
    "This leads to a whole subset of issues that cannot be corrected linearly, but still must be accounted for.\n",
    "\n",
    "![smaller_RC_0033_preoperative_postoperative](https://github.com/user-attachments/assets/f22374e1-75b4-4a07-816f-d3ad51e84921)\n",
    "An example of a paper which has been folded. and unfolded, causing non-linear distortions. This is a _very_ modest example. In practice, we have seen photographs of papers that are raised at least an inch off the table in certain areas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "from utils.annotations import BoundingBox\n",
    "from collections import Counter\n",
    "from PIL import Image\n",
    "from scipy.interpolate import Rbf\n",
    "\n",
    "from memory_profiler import profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data for testing:\n",
    "\n",
    "- \"intraop_document_landmarks.json\"\n",
    "  - Used for the destination points in the transformation. We are using the landmarks from the unified image\n",
    "  - Also has landmarks for each of the images. We currently are not using them\n",
    "- \"yolo_data.json\"\n",
    "  - Used for the source points in the transformation.\n",
    "  - May need to be replace with the landmarks from the other file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22 sheets in yolo_data.json\n"
     ]
    }
   ],
   "source": [
    "# Load yolo_data.json which will be used as src_bbs\n",
    "PATH_TO_YOLO_DATA = \"../../data/yolo_data.json\"\n",
    "PATH_TO_REGISTERED_IMAGES = \"../../data/registered_images\"\n",
    "\n",
    "with open(PATH_TO_YOLO_DATA) as json_file:\n",
    "    yolo_data = json.load(json_file)\n",
    "\n",
    "print(f\"Found {len(yolo_data)} sheets in yolo_data.json\")\n",
    "\n",
    "# load introp_document_landmarks.json which will be used as dst_points\n",
    "PATH_TO_LANDMARKS = \"../../data/intraop_document_landmarks.json\"\n",
    "\n",
    "DESIRED_IMAGE_WIDTH = 800\n",
    "DESIRED_IMAGE_HEIGHT = 600\n",
    "\n",
    "\n",
    "def label_studio_to_bboxes(path_to_json_data: Path) -> List[BoundingBox]:\n",
    "    \"\"\"\n",
    "    Convert the json data from label studio to a list of BoundingBox objects\n",
    "\n",
    "    Args:\n",
    "        path_to_json_data (Path): Path to the json data from label studio\n",
    "\n",
    "    Returns:\n",
    "        List[BoundingBox]: List of BoundingBox objects\n",
    "    \"\"\"\n",
    "    json_data: List[Dict] = json.loads(open(str(path_to_json_data)).read())\n",
    "    return {\n",
    "        sheet_data[\"data\"][\"image\"].split(\"-\")[-1]: [\n",
    "            BoundingBox(\n",
    "                category=label[\"value\"][\"rectanglelabels\"][0],\n",
    "                left=label[\"value\"][\"x\"] / 100 * DESIRED_IMAGE_WIDTH,\n",
    "                top=label[\"value\"][\"y\"] / 100 * DESIRED_IMAGE_HEIGHT,\n",
    "                right=(label[\"value\"][\"x\"] / 100 + label[\"value\"][\"width\"] / 100)\n",
    "                * DESIRED_IMAGE_WIDTH,\n",
    "                bottom=(label[\"value\"][\"y\"] / 100 + label[\"value\"][\"height\"] / 100)\n",
    "                * DESIRED_IMAGE_HEIGHT,\n",
    "            )\n",
    "            for label in sheet_data[\"annotations\"][0][\"result\"]\n",
    "        ]\n",
    "        for sheet_data in json_data\n",
    "    }\n",
    "\n",
    "\n",
    "landmark_location_data: Dict[str, List[BoundingBox]] = label_studio_to_bboxes(\n",
    "    PATH_TO_LANDMARKS\n",
    ")\n",
    "\n",
    "landmarks = landmark_location_data[\n",
    "    \"unified_intraoperative_preoperative_flowsheet_v1_1_front.png\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TPS Tranformation**\n",
    "Steps:\n",
    "\n",
    "1. Filter to keep only the relevant bounding boxes\n",
    "   - remove all bounding boxes from the source points that do not match a category in the destination points\n",
    "   - Find all of the duplicates in the source and destination points and remove them\n",
    "   - sort the source and destination points alphabetically via their category\n",
    "2. Get lists of the x and y coordinates for both the source and destination points\n",
    "   - Primary purpose is to enable the use of scipy's Rbf function\n",
    "   - We are using the top left corner of the bounding boxes\n",
    "3. Estimate the transformation\n",
    "   - Use the Rbf function to apply the TPS transformation\n",
    "4. Apply the transformation and Warp the image\n",
    "   - Create a grid from 0 to maximum value of the image\n",
    "   - Apply the transformation to the grids\n",
    "   - Ensure that the transformed points are within bounds\n",
    "   - Use those grids to warp the original image\n",
    "\n",
    "_Note:_ There are a lot of different outputs that are currently commented out that can be used for debugging purposes:\n",
    "\n",
    "- Print the lists of duplicate keys and the categories being used in the source and destination points\n",
    "- Plot of the source and destination points on the image\n",
    "- View the bounds of the transformed points\n",
    "- View the distribution of the transformed points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tps_transform(image: np.ndarray, src_bbs: List[BoundingBox], dst_bbs: List[BoundingBox], scale_factor: float = 0.25) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Perform a memory-efficient thin plate spline transformation by computing the warp field at low resolution.\n",
    "\n",
    "    Args:\n",
    "        image (np.ndarray): The image to be transformed.\n",
    "        src_bbs (List[BoundingBox]): List of source BoundingBox objects.\n",
    "        dst_bbs (List[BoundingBox]): List of destination BoundingBox objects.\n",
    "        scale_factor (float): Factor to downscale the image for computing warp (default: 0.25).\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The transformed image at original size.\n",
    "    \"\"\"\n",
    "\n",
    "    # Image dimensions\n",
    "    h, w = image.shape[:2]\n",
    "    small_h, small_w = int(h * scale_factor), int(w * scale_factor)\n",
    "\n",
    "    # Scale bounding boxes\n",
    "    def scale_bbs(bbs, factor):\n",
    "        return [\n",
    "            BoundingBox(\n",
    "                category=bb.category,\n",
    "                left=bb.left * factor,\n",
    "                top=bb.top * factor,\n",
    "                right=bb.right * factor,\n",
    "                bottom=bb.bottom * factor,\n",
    "            ) for bb in bbs\n",
    "        ]\n",
    "\n",
    "    scaled_src_bbs = scale_bbs(src_bbs, scale_factor)\n",
    "    scaled_dst_bbs = scale_bbs(dst_bbs, scale_factor)\n",
    "\n",
    "    # Remove duplicate category points\n",
    "    duplicate_cats = {k for k, v in Counter([bb.category for bb in scaled_src_bbs]).items() if v > 1}\n",
    "    duplicate_cats |= {k for k, v in Counter([bb.category for bb in scaled_dst_bbs]).items() if v > 1}\n",
    "\n",
    "    scaled_src_bbs = [bb for bb in scaled_src_bbs if bb.category not in duplicate_cats]\n",
    "    scaled_dst_bbs = [bb for bb in scaled_dst_bbs if bb.category not in duplicate_cats]\n",
    "\n",
    "    # Sort bounding boxes by category\n",
    "    scaled_src_bbs.sort(key=lambda bb: bb.category)\n",
    "    scaled_dst_bbs.sort(key=lambda bb: bb.category)\n",
    "\n",
    "    # Extract bounding box centers\n",
    "    def get_centers(bbs):\n",
    "        return np.array(\n",
    "            [[(bb.left + bb.right) / 2, (bb.top + bb.bottom) / 2] for bb in bbs], dtype=np.float32\n",
    "        )\n",
    "\n",
    "    src_points = get_centers(scaled_src_bbs)\n",
    "    dst_points = get_centers(scaled_dst_bbs)\n",
    "\n",
    "    # Apply RANSAC filtering\n",
    "    _, mask = cv2.findHomography(dst_points, src_points, method=cv2.RANSAC, ransacReprojThreshold=5.0)\n",
    "    inlier_mask = mask.ravel() == 1\n",
    "    filtered_src = src_points[inlier_mask]\n",
    "    filtered_dst = dst_points[inlier_mask]\n",
    "\n",
    "    if len(filtered_src) < 4:\n",
    "        return image  # Not enough inliers for TPS\n",
    "\n",
    "    # Apply Thin Plate Splines using RBF\n",
    "    rbf_x = Rbf(filtered_dst[:, 0], filtered_dst[:, 1], filtered_src[:, 0] - filtered_dst[:, 0], function=\"thin_plate\")\n",
    "    rbf_y = Rbf(filtered_dst[:, 0], filtered_dst[:, 1], filtered_src[:, 1] - filtered_dst[:, 1], function=\"thin_plate\")\n",
    "\n",
    "    # Generate a low-res grid for memory-efficient TPS\n",
    "    small_grid_x, small_grid_y = np.meshgrid(np.linspace(0, small_w - 1, small_w), np.linspace(0, small_h - 1, small_h))\n",
    "\n",
    "    # Compute displacement fields at low resolution\n",
    "    disp_x_small = rbf_x(small_grid_x, small_grid_y).astype(np.float32)\n",
    "    disp_y_small = rbf_y(small_grid_x, small_grid_y).astype(np.float32)\n",
    "\n",
    "    # Upscale displacement fields to full resolution\n",
    "    disp_x_large = cv2.resize(disp_x_small, (w, h), interpolation=cv2.INTER_CUBIC)\n",
    "    disp_y_large = cv2.resize(disp_y_small, (w, h), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    # Compute final absolute positions\n",
    "    grid_x, grid_y = np.meshgrid(np.arange(w), np.arange(h))\n",
    "    transformed_x = np.clip(grid_x + disp_x_large, 0, w - 1)\n",
    "    transformed_y = np.clip(grid_y + disp_y_large, 0, h - 1)\n",
    "\n",
    "    # Apply transformation to the original image\n",
    "    warped_large = cv2.remap(image, transformed_x.astype(np.float32), transformed_y.astype(np.float32), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    return warped_large\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "for sheet, yolo_bbs in yolo_data.items():\n",
    "    # get path to current image\n",
    "    full_image_path = os.path.join(PATH_TO_REGISTERED_IMAGES, sheet)\n",
    "    image = cv2.imread(full_image_path)\n",
    "    resized_img = cv2.resize(image, (DESIRED_IMAGE_WIDTH, DESIRED_IMAGE_HEIGHT))\n",
    "    # get the sheet's bounding boxes\n",
    "    sheet_bbs = [\n",
    "        BoundingBox.from_yolo(bb, DESIRED_IMAGE_WIDTH, DESIRED_IMAGE_HEIGHT)\n",
    "        for bb in yolo_bbs\n",
    "    ]\n",
    "\n",
    "    print(len(sheet_bbs))\n",
    "    transformed_img = tps_transform(resized_img, sheet_bbs, landmarks)\n",
    "    transformed_img = Image.fromarray(transformed_img)\n",
    "    transformed_img.show()\n",
    "    # Show the image\n",
    "    cv2.imshow(\"image\", resized_img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tps_transform_ransac(image, src_bbs: List[BoundingBox], dst_bbs: List[BoundingBox]):\n",
    "    \"\"\"\n",
    "    Perform a thin plate spline transformation on the image using the src_bbs and dst_bbs, using RANSAC to filter out outliers.\n",
    "\n",
    "    Args:\n",
    "        image (np.ndarray): The image to be transformed\n",
    "        src_bbs (List[BoundingBox]): List of BoundingBox objects\n",
    "        dst_bbs (List[BoundingBox]): List of BoundingBox objects\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The transformed image\n",
    "    \"\"\"\n",
    "    # get the categories from dst_bbs\n",
    "    landmark_cats = [bb.category for bb in dst_bbs]\n",
    "    # remove all bbs in src that are not in those categories\n",
    "    src_bbs = [bb for bb in src_bbs if bb.category in landmark_cats]\n",
    "    # get list of duplicate keys\n",
    "    duplicate_count_src = dict(Counter([bb.category for bb in src_bbs]))\n",
    "    duplicates = [k for k, v in duplicate_count_src.items() if v > 1]\n",
    "    duplicate_count_dst = dict(Counter([bb.category for bb in dst_bbs]))\n",
    "    duplicates.extend([k for k, v in duplicate_count_dst.items() if v > 1])\n",
    "    duplicates = list(set(duplicates))\n",
    "    # print(duplicates)\n",
    "    # remove duplicates\n",
    "    src_bbs = [bb for bb in src_bbs if bb.category not in duplicates]\n",
    "    dst_bbs = [bb for bb in dst_bbs if bb.category not in duplicates]\n",
    "    # sort categories alphabetically\n",
    "    src_bbs = sorted(src_bbs, key=lambda bb: bb.category)\n",
    "    # print([bb.category for bb in src_bbs])\n",
    "    dst_bbs = sorted(dst_bbs, key=lambda bb: bb.category)\n",
    "    # print([bb.category for bb in dst_bbs])\n",
    "\n",
    "    src_bbs = np.array([[bb.left, bb.top] for bb in src_bbs], dtype=np.float32)\n",
    "    dst_bbs = np.array([[bb.left, bb.top] for bb in dst_bbs], dtype=np.float32)\n",
    "\n",
    "    _, mask = cv2.findHomography(\n",
    "        dst_bbs,\n",
    "        src_bbs,\n",
    "        method=cv2.RANSAC,\n",
    "        ransacReprojThreshold=10.0,\n",
    "        maxIters=5000,\n",
    "        confidence=0.99,\n",
    "    )\n",
    "    inlier_mask = mask.ravel() == 1\n",
    "\n",
    "    filtered_src = src_bbs[inlier_mask]\n",
    "    filtered_dst = dst_bbs[inlier_mask]\n",
    "\n",
    "    new_src_x, new_src_y = filtered_src[:, 0], filtered_src[:, 1]\n",
    "    new_dst_x, new_dst_y = filtered_dst[:, 0], filtered_dst[:, 1]\n",
    "\n",
    "    if len(new_src_x) < 4:\n",
    "        return image\n",
    "\n",
    "    # use RBF function to do the thin plate splines\n",
    "    rbf_x = Rbf(new_dst_x, new_dst_y, new_src_x, function=\"thin_plate\")\n",
    "    rbf_y = Rbf(new_dst_x, new_dst_y, new_src_y, function=\"thin_plate\")\n",
    "\n",
    "    # Alter the image according to the transformation\n",
    "    h, w, _ = image.shape\n",
    "    # create grid\n",
    "    x = np.linspace(0, w - 1, w)\n",
    "    y = np.linspace(0, h - 1, h)\n",
    "    grid_x, grid_y = np.meshgrid(x, y)\n",
    "\n",
    "    # apply the transformation\n",
    "    # reshape into grid\n",
    "    transformed_x = rbf_x(grid_x, grid_y).astype(np.float32)\n",
    "    transformed_y = rbf_y(grid_x, grid_y).astype(np.float32)\n",
    "\n",
    "    transformed_x = np.clip(transformed_x, 0, image.shape[1] - 1)\n",
    "    transformed_y = np.clip(transformed_y, 0, image.shape[0] - 1)\n",
    "\n",
    "    # warp the image\n",
    "    warp_img = cv2.remap(\n",
    "        image, transformed_x, transformed_y, interpolation=cv2.INTER_LINEAR\n",
    "    )\n",
    "\n",
    "    return warp_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 902.11 MiB, increment: 743.00 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "for sheet, yolo_bbs in yolo_data.items():\n",
    "    if sheet != \"RC_0031_intraoperative.JPG\":\n",
    "        continue\n",
    "    # get path to current image\n",
    "    full_image_path = os.path.join(PATH_TO_REGISTERED_IMAGES, sheet)\n",
    "    image = cv2.imread(full_image_path)\n",
    "    resized_img = cv2.resize(image, (DESIRED_IMAGE_WIDTH, DESIRED_IMAGE_HEIGHT))\n",
    "    # get the sheet's bounding boxes\n",
    "    sheet_bbs = [\n",
    "        BoundingBox.from_yolo(bb, DESIRED_IMAGE_WIDTH, DESIRED_IMAGE_HEIGHT)\n",
    "        for bb in yolo_bbs\n",
    "    ]\n",
    "    transformed_img_arr = tps_transform_ransac(resized_img, sheet_bbs, landmarks)\n",
    "    transformed_img = Image.fromarray(transformed_img_arr)\n",
    "\n",
    "    #Overlay this image with the original as a sanity check to make sure the transformation is correct\n",
    "    # Should used image from above as well as transformed_img_arr\n",
    "    transformed_img = cv2.cvtColor(transformed_img_arr, cv2.COLOR_BGR2RGB)\n",
    "    # Get data/unified_intraoperative_preoperative_flowsheet_v1_1_back.png\n",
    "    unified = cv2.imread(\"../../data/unified_intraoperative_preoperative_flowsheet_v1_1_front.png\")\n",
    "    resized_unified = cv2.resize(unified, (DESIRED_IMAGE_WIDTH, DESIRED_IMAGE_HEIGHT))\n",
    "    # Show original overlay\n",
    "    overlay = cv2.addWeighted(resized_unified, 0.5, resized_img, 0.5, 0)\n",
    "    overlay = Image.fromarray(overlay)\n",
    "    # Add a name to the window\n",
    "    overlay.name = \"Original Overlay\"\n",
    "    overlay.show()\n",
    "    overlay = cv2.addWeighted(resized_unified, 0.5, transformed_img, 0.5, 0)\n",
    "    overlay = Image.fromarray(overlay)\n",
    "    # Add a name to the window\n",
    "    overlay.name = \"Transformed Overlay\"\n",
    "    overlay.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging these two methods and priming for placing into extractor\n",
    "\n",
    "I'm going to create private functions that do RANSAC and distance measurments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with turning Hannah's code into a function\n",
    "def __filter_by_distance(\n",
    "    src_bbs: List[BoundingBox],\n",
    "    dst_bbs: List[BoundingBox],\n",
    "    threshold: float,\n",
    ") -> Tuple[List[BoundingBox], List[BoundingBox]]:\n",
    "    \"\"\"\n",
    "    Filter out source and destination points that have a distance greater than the threshold.\n",
    "    Large transformations are likely to be outliers and erroneous. We only expect small tweaks via the thin plate spline transformation.\n",
    "    Homography should already be completed prior to TPS.\n",
    "\n",
    "    Args:\n",
    "        src_bbs (List[BoundingBox]): The source points\n",
    "        dst_bbs (List[BoundingBox]): The destination points\n",
    "        threshold (float): The threshold distance\n",
    "\n",
    "    Returns:\n",
    "        Tuple[List[BoundingBox], List[BoundingBox]]: The filtered source and destination points\n",
    "\n",
    "    \"\"\"\n",
    "    filtered_points = [\n",
    "        (src_bb, dst_bb)\n",
    "        for src_bb, dst_bb in zip(src_bbs, dst_bbs)\n",
    "        if abs(src_bb.top - dst_bb.top) < threshold\n",
    "        and abs(src_bb.left - dst_bb.left) < threshold\n",
    "    ]\n",
    "\n",
    "    new_src_bbs, new_dst_bbs = zip(*filtered_points) if filtered_points else ([], [])\n",
    "\n",
    "    return list(new_src_bbs), list(new_dst_bbs)\n",
    "\n",
    "\n",
    "# Now we can turn Matt's RANSAC code into a function\n",
    "def __filter_by_RANSAC(\n",
    "    src_bbs: List[BoundingBox],\n",
    "    dst_bbs: List[BoundingBox],\n",
    "    threshold: float,\n",
    "    max_iters: int = 5000,\n",
    "    confidence_limit: float = 0.99,\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Filter out source and destination points that are not inliers according to RANSAC\n",
    "\n",
    "    Args:\n",
    "        src_bbs (np.ndarray): The source points\n",
    "        dst_bbs (np.ndarray): The destination points\n",
    "        threshold (float): The threshold distance\n",
    "        max_iters (int, optional): The maximum number of iterations for RANSAC. Defaults to 5000.\n",
    "        confidence_limit (float, optional): The confidence limit for RANSAC. Defaults to 0.99.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]: The filtered source and destination points as numpy arrays in this order (src_x, src_y, dst_x, dst_y)\n",
    "    \"\"\"\n",
    "    # Turn the BoundingBox objects into numpy arrays of coordinates\n",
    "    src_points = np.array([[bb.left, bb.top] for bb in src_bbs], dtype=np.float32)\n",
    "    dst_points = np.array([[bb.left, bb.top] for bb in dst_bbs], dtype=np.float32)\n",
    "\n",
    "    # Complete RANSAC\n",
    "    _, mask = cv2.findHomography(\n",
    "        dst_points,\n",
    "        src_points,\n",
    "        method=cv2.RANSAC,\n",
    "        ransacReprojThreshold=threshold,\n",
    "        maxIters=max_iters,\n",
    "        confidence=confidence_limit,\n",
    "    )\n",
    "    inlier_mask = mask.ravel() == 1\n",
    "\n",
    "    # Apply the mask to the source and destination points\n",
    "    filtered_src = src_points[inlier_mask]\n",
    "    filtered_dst = dst_points[inlier_mask]\n",
    "\n",
    "    # Get the x and y coordinates of the filtered points\n",
    "    src_x, src_y = filtered_src[:, 0], filtered_src[:, 1]\n",
    "    dst_x, dst_y = filtered_dst[:, 0], filtered_dst[:, 1]\n",
    "\n",
    "    return src_x, src_y, dst_x, dst_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_thin_plate_splines(\n",
    "    image: np.ndarray,\n",
    "    src_bbs: List[BoundingBox],\n",
    "    dst_bbs: List[BoundingBox],\n",
    "    threshold: float = 10.0,\n",
    "    downscale_factor: float = 0.5,\n",
    "    ransac_threshold: float = 5.0,\n",
    "    max_ransac_iters: int = 5000,\n",
    "    confidence_limit: float = 0.99,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Perform a memory-efficient thin plate spline transformation with distance and RANSAC filtering.\n",
    "\n",
    "    Args:\n",
    "        image (np.ndarray): The image to be transformed.\n",
    "        src_bbs (List[BoundingBox]): List of source BoundingBox objects.\n",
    "        dst_bbs (List[BoundingBox]): List of destination BoundingBox objects.\n",
    "        threshold (float): The threshold distance for filtering out points (default: 10.0).\n",
    "        downscale_factor (float): Factor to downscale the image for computing warp (default: 0.25).\n",
    "        ransac_threshold (float): The threshold distance for RANSAC filtering (default: 5.0).\n",
    "        max_ransac_iters (int): The maximum number of iterations for RANSAC (default: 5000).\n",
    "        confidence_limit (float): The confidence limit for RANSAC (default: 0.99).\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The transformed image at original size\n",
    "    \"\"\"\n",
    "\n",
    "    # Get image dimensions and downscale to new dimensions\n",
    "    h, w = image.shape[:2]\n",
    "    small_h, small_w = int(h * downscale_factor), int(w * downscale_factor)\n",
    "\n",
    "    # Helper function to scale bounding boxes down by a factor\n",
    "    #   Return bounding boxes as a list of BoundingBox objects\n",
    "    def scale_bbs(bbs, factor):\n",
    "        return [\n",
    "            BoundingBox(\n",
    "                category=bb.category,\n",
    "                left=bb.left * factor,\n",
    "                top=bb.top * factor,\n",
    "                right=bb.right * factor,\n",
    "                bottom=bb.bottom * factor,\n",
    "            ) for bb in bbs\n",
    "        ]\n",
    "\n",
    "    # Scale source and destination bounding boxes (destinations are landmarks)\n",
    "    scaled_src_bbs = scale_bbs(src_bbs, downscale_factor)\n",
    "    scaled_dst_bbs = scale_bbs(dst_bbs, downscale_factor)\n",
    "\n",
    "    # Remove duplicates\n",
    "    # Find duplicate categories\n",
    "    duplicate_cats = {k for k, v in Counter([bb.category for bb in scaled_src_bbs]).items() if v > 1}\n",
    "    duplicate_cats |= {k for k, v in Counter([bb.category for bb in scaled_dst_bbs]).items() if v > 1}\n",
    "\n",
    "    # Filter out the duplicates\n",
    "    scaled_src_bbs = [bb for bb in scaled_src_bbs if bb.category not in duplicate_cats]\n",
    "    scaled_dst_bbs = [bb for bb in scaled_dst_bbs if bb.category not in duplicate_cats]\n",
    "\n",
    "    # Sort bounding boxes by category\n",
    "    scaled_src_bbs.sort(key=lambda bb: bb.category)\n",
    "    scaled_dst_bbs.sort(key=lambda bb: bb.category)\n",
    "\n",
    "    # Apply distance filtering\n",
    "    # Remove points where the distance between source and destination is greater than the threshold\n",
    "    #   Defaults to 10 pixels\n",
    "    scaled_src_bbs, scaled_dst_bbs = __filter_by_distance(scaled_src_bbs, scaled_dst_bbs, threshold)\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    # The points are the centers of the bounding boxes\n",
    "    src_points = np.array([[(bb.left + bb.right) / 2, (bb.top + bb.bottom) / 2] for bb in scaled_src_bbs], dtype=np.float32)\n",
    "    dst_points = np.array([[(bb.left + bb.right) / 2, (bb.top + bb.bottom) / 2] for bb in scaled_dst_bbs], dtype=np.float32)\n",
    "\n",
    "    # Apply RANSAC filtering only if there are at least 4 points to use\n",
    "    if len(src_points) >= 4:\n",
    "        # Filter using ransac\n",
    "        src_x, src_y, dst_x, dst_y = __filter_by_RANSAC(\n",
    "            scaled_src_bbs, scaled_dst_bbs, \n",
    "            threshold=ransac_threshold, \n",
    "            max_iters=max_ransac_iters, \n",
    "            confidence_limit=confidence_limit\n",
    "        )\n",
    "\n",
    "        # If not enough inliers remain, return the original image\n",
    "        if len(src_x) < 4:\n",
    "            return image\n",
    "\n",
    "        # Update src and dst points\n",
    "        src_points = np.column_stack((src_x, src_y))\n",
    "        dst_points = np.column_stack((dst_x, dst_y))\n",
    "    else:\n",
    "        return image  # Not enough points for TPS\n",
    "\n",
    "    # Compute displacement field using TPS\n",
    "    # This uses a radial basis function with thin plate spline kernel to compute the displacement field\n",
    "    #   rbf_x and rbf_y are the radial basis functions for x and y displacements respectively\n",
    "    # Interpolation of all the images pixels can be done using these functions to get the final transformed image\n",
    "\n",
    "    rbf_x = Rbf(dst_points[:, 0], dst_points[:, 1], src_points[:, 0] - dst_points[:, 0], function='thin_plate')\n",
    "    rbf_y = Rbf(dst_points[:, 0], dst_points[:, 1], src_points[:, 1] - dst_points[:, 1], function='thin_plate')\n",
    "\n",
    "    # Generate grid for transformation\n",
    "    # This has a grid for the location of each pixel in the image\n",
    "    y, x = np.mgrid[0:small_h, 0:small_w].astype(np.float32)\n",
    "\n",
    "    # Compute displacements for each pixel\n",
    "    # This has data on the amount of movement of *each pixel* in the x and y directions\n",
    "    dx = rbf_x(x, y).astype(np.float32)\n",
    "    dy = rbf_y(x, y).astype(np.float32)\n",
    "\n",
    "    # Final coordinate mapping\n",
    "    # Here we do the actual movement of each pixel\n",
    "    map_x = (x + dx)\n",
    "    map_y = (y + dy)\n",
    "\n",
    "    # Scale back to original resolution\n",
    "    # Then we scale back to the original resolution\n",
    "    map_x = cv2.resize(map_x, (w, h)) * (1 / downscale_factor)\n",
    "    map_y = cv2.resize(map_y, (w, h)) * (1 / downscale_factor)\n",
    "\n",
    "    # Clip to image boundaries, don't have any pixels outside the image\n",
    "    #   It doesn't delete the pixels, it just moves them back inside the image\n",
    "    map_x = np.clip(map_x, 0, w - 1)\n",
    "    map_y = np.clip(map_y, 0, h - 1)\n",
    "\n",
    "    # Apply warping using a bilnear interpolation\n",
    "    #   This is the final transformed image\n",
    "    #   Border reflect reflexts the images at the endges so we don't end up with artifacts\n",
    "    #   Remaps the image and interpolates the pixel values\n",
    "    warped = cv2.remap(image, map_x.astype(np.float32), map_y.astype(np.float32), interpolation=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT)\n",
    "\n",
    "    return warped\n",
    "\n",
    "\n",
    "# Function to visualize the transformation\n",
    "def visualize_transformation(image, transformed_image):\n",
    "    cv2.imshow(\"Original Image\", image)\n",
    "    cv2.imshow(\"Transformed Image\", transformed_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need to merge the two functions into one that uses RANSAC to filter out outliers as well as those far from the destination points\n",
    "def transform_thin_plate_splines_old(\n",
    "    image: np.ndarray,\n",
    "    src_bbs: List[BoundingBox],\n",
    "    dst_bbs: List[BoundingBox],\n",
    "    max_dist: float = 4.0,\n",
    "    threshold: float = 10.0,\n",
    "    max_iters: int = 5000,\n",
    "    confidence_limit: float = 0.99,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Perform a thin plate spline transformation on the image using the src_bbs and dst_bbs, using RANSAC to filter out outliers.\n",
    "    We assume that homography was completed prior to calling this function.\n",
    "    We start by filtering by points that are too far from their destination counterparts, then we use RANSAC to filter out outliers.\n",
    "\n",
    "    Args:\n",
    "        image (np.ndarray): The image to be transformed\n",
    "        src_bbs (List[BoundingBox]): List of BoundingBox objects\n",
    "        dst_bbs (List[BoundingBox]): List of BoundingBox objects\n",
    "        max_dist (float, optional): The maximum distance for filtering out points. Defaults to 4.0.\n",
    "        threshold (float, optional): The threshold distance for RANSAC. Defaults to 10.0.\n",
    "        max_iters (int, optional): The maximum number of iterations for RANSAC. Defaults to 5000.\n",
    "        confidence_limit (float, optional): The confidence limit for RANSAC. Defaults to 0.99.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The transformed image\n",
    "    \"\"\"\n",
    "    # get the categories from dst_bbs\n",
    "    landmark_cats = [bb.category for bb in dst_bbs]\n",
    "    # remove all bbs in src that are not in those categories\n",
    "    src_bbs = [bb for bb in src_bbs if bb.category in landmark_cats]\n",
    "    # get list of duplicate keys\n",
    "    duplicate_count_src = dict(Counter([bb.category for bb in src_bbs]))\n",
    "    duplicates = [k for k, v in duplicate_count_src.items() if v > 1]\n",
    "    duplicate_count_dst = dict(Counter([bb.category for bb in dst_bbs]))\n",
    "    duplicates.extend([k for k, v in duplicate_count_dst.items() if v > 1])\n",
    "    duplicates = list(set(duplicates))\n",
    "    # print(duplicates)\n",
    "    # remove duplicates\n",
    "    src_bbs = [bb for bb in src_bbs if bb.category not in duplicates]\n",
    "    dst_bbs = [bb for bb in dst_bbs if bb.category not in duplicates]\n",
    "\n",
    "    # sort categories alphabetically\n",
    "    src_bbs = sorted(src_bbs, key=lambda bb: bb.category)\n",
    "    dst_bbs = sorted(dst_bbs, key=lambda bb: bb.category) # These are your landmarks\n",
    "\n",
    "    # remove source points with suspiciously high distances to their destination counterparts\n",
    "    src_bbs, dst_bbs = __filter_by_distance(src_bbs, dst_bbs, max_dist)\n",
    "\n",
    "    # Now lets use RAANSAC to filter out outliers\n",
    "    src_x, src_y, dst_x, dst_y = __filter_by_RANSAC(\n",
    "        src_bbs, dst_bbs, threshold, max_iters, confidence_limit\n",
    "    )\n",
    "\n",
    "    # use RBF function to do the thin plate splines\n",
    "    rbf_x = Rbf(dst_x, dst_y, src_x, function=\"thin_plate\")\n",
    "    rbf_y = Rbf(dst_x, dst_y, src_y, function=\"thin_plate\")\n",
    "\n",
    "    # Alter the image according to the transformation\n",
    "    h, w, _ = image.shape\n",
    "    # create grid\n",
    "    x = np.linspace(0, w - 1, w)\n",
    "    y = np.linspace(0, h - 1, h)\n",
    "    grid_x, grid_y = np.meshgrid(x, y)\n",
    "\n",
    "    # apply the transformation\n",
    "    # reshape into grid\n",
    "    transformed_x = rbf_x(grid_x, grid_y).astype(np.float32)\n",
    "    transformed_y = rbf_y(grid_x, grid_y).astype(np.float32)\n",
    "\n",
    "    transformed_x = np.clip(transformed_x, 0, image.shape[1] - 1)\n",
    "    transformed_y = np.clip(transformed_y, 0, image.shape[0] - 1)\n",
    "\n",
    "    # warp the image\n",
    "    warp_img = cv2.remap(\n",
    "        image, transformed_x, transformed_y, interpolation=cv2.INTER_LINEAR\n",
    "    )\n",
    "\n",
    "    return warp_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile\n",
    "import pstats\n",
    "from pstats import SortKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         1792 function calls in 0.252 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 95 to 20 due to restriction <20>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.012    0.012    0.251    0.251 C:\\Users\\15406\\AppData\\Local\\Temp\\ipykernel_12712\\1017396507.py:1(transform_thin_plate_splines)\n",
      "        2    0.007    0.004    0.217    0.109 c:\\Users\\15406\\Coding-Projects\\Paper Chart Extraction\\Supplements\\.venv\\Lib\\site-packages\\scipy\\interpolate\\_rbf.py:280(__call__)\n",
      "        4    0.165    0.041    0.165    0.041 c:\\Users\\15406\\Coding-Projects\\Paper Chart Extraction\\Supplements\\.venv\\Lib\\site-packages\\scipy\\interpolate\\_rbf.py:169(_h_thin_plate)\n",
      "        2    0.000    0.000    0.043    0.021 c:\\Users\\15406\\Coding-Projects\\Paper Chart Extraction\\Supplements\\.venv\\Lib\\site-packages\\scipy\\interpolate\\_rbf.py:277(_call_norm)\n",
      "        2    0.000    0.000    0.043    0.021 c:\\Users\\15406\\Coding-Projects\\Paper Chart Extraction\\Supplements\\.venv\\Lib\\site-packages\\scipy\\spatial\\distance.py:2649(cdist)\n",
      "        2    0.043    0.021    0.043    0.021 {built-in method scipy.spatial._distance_pybind.cdist_euclidean}\n",
      "        1    0.006    0.006    0.009    0.009 c:\\Users\\15406\\Coding-Projects\\Paper Chart Extraction\\Supplements\\.venv\\Lib\\site-packages\\numpy\\lib\\_index_tricks_impl.py:149(__getitem__)\n",
      "        1    0.002    0.002    0.003    0.003 c:\\Users\\15406\\Coding-Projects\\Paper Chart Extraction\\Supplements\\.venv\\Lib\\site-packages\\numpy\\_core\\numeric.py:1753(indices)\n",
      "        2    0.003    0.001    0.003    0.001 {resize}\n",
      "        2    0.000    0.000    0.002    0.001 c:\\Users\\15406\\Coding-Projects\\Paper Chart Extraction\\Supplements\\.venv\\Lib\\site-packages\\scipy\\interpolate\\_rbf.py:218(__init__)\n",
      "        1    0.002    0.002    0.002    0.002 {remap}\n",
      "        5    0.002    0.000    0.002    0.000 {method 'astype' of 'numpy.ndarray' objects}\n",
      "        4    0.000    0.000    0.002    0.001 c:\\Users\\15406\\Coding-Projects\\Paper Chart Extraction\\Supplements\\.venv\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:51(_wrapfunc)\n",
      "        2    0.000    0.000    0.002    0.001 c:\\Users\\15406\\Coding-Projects\\Paper Chart Extraction\\Supplements\\.venv\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:2250(clip)\n",
      "        2    0.000    0.000    0.002    0.001 {method 'clip' of 'numpy.ndarray' objects}\n",
      "        2    0.002    0.001    0.002    0.001 c:\\Users\\15406\\Coding-Projects\\Paper Chart Extraction\\Supplements\\.venv\\Lib\\site-packages\\numpy\\_core\\_methods.py:100(_clip)\n",
      "       24    0.002    0.000    0.002    0.000 {built-in method numpy.asarray}\n",
      "       10    0.001    0.000    0.001    0.000 {method 'flatten' of 'numpy.ndarray' objects}\n",
      "        2    0.001    0.000    0.001    0.000 C:\\Users\\15406\\AppData\\Local\\Temp\\ipykernel_12712\\1017396507.py:33(scale_bbs)\n",
      "        6    0.000    0.000    0.001    0.000 c:\\Users\\15406\\Coding-Projects\\Paper Chart Extraction\\Supplements\\.venv\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:69(_wrapreduction)\n",
      "\n",
      "\n",
      "peak memory: 214.05 MiB, increment: 39.16 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "# Runs the new function\n",
    "for sheet, yolo_bbs in yolo_data.items():\n",
    "    if sheet != \"RC_0031_intraoperative.JPG\":\n",
    "        continue\n",
    "    # get path to current image\n",
    "    full_image_path = os.path.join(PATH_TO_REGISTERED_IMAGES, sheet)\n",
    "    image = cv2.imread(full_image_path)\n",
    "    resized_img = cv2.resize(image, (DESIRED_IMAGE_WIDTH, DESIRED_IMAGE_HEIGHT))\n",
    "\n",
    "    # Turn resized image to an Image and show it\n",
    "    resized_img_ = Image.fromarray(resized_img)\n",
    "    resized_img_.show()\n",
    "\n",
    "    # get the sheet's bounding boxes\n",
    "    sheet_bbs = [\n",
    "        BoundingBox.from_yolo(bb, DESIRED_IMAGE_WIDTH, DESIRED_IMAGE_HEIGHT)\n",
    "        for bb in yolo_bbs\n",
    "    ]\n",
    "\n",
    "    # Run the profiler\n",
    "    profiler = cProfile.Profile()\n",
    "    profiler.enable()\n",
    "    transformed_img_arr = transform_thin_plate_splines(resized_img, sheet_bbs, landmarks)\n",
    "    profiler.disable()\n",
    "\n",
    "    # Print stats sorted by cumulative time\n",
    "    stats = pstats.Stats(profiler).sort_stats(SortKey.CUMULATIVE)\n",
    "    stats.print_stats(20)  # Show top 20 functions by time\n",
    "    \n",
    "    transformed_img = Image.fromarray(transformed_img_arr)\n",
    "    transformed_img.show()\n",
    "\n",
    "    #Overlay this image with the original as a sanity check to make sure the transformation is correct\n",
    "    # Should used image from above as well as transformed_img_arr\n",
    "    transformed_img = cv2.cvtColor(transformed_img_arr, cv2.COLOR_BGR2RGB)\n",
    "    # Get data/unified_intraoperative_preoperative_flowsheet_v1_1_back.png\n",
    "    unified = cv2.imread(\"../../data/unified_intraoperative_preoperative_flowsheet_v1_1_front.png\")\n",
    "    resized_unified = cv2.resize(unified, (DESIRED_IMAGE_WIDTH, DESIRED_IMAGE_HEIGHT))\n",
    "    # Show original overlay\n",
    "    overlay = cv2.addWeighted(resized_unified, 0.5, resized_img, 0.5, 0)\n",
    "    overlay = Image.fromarray(overlay)\n",
    "    # Add a name to the window\n",
    "    overlay.name = \"Original Overlay\"\n",
    "    overlay.show()\n",
    "    overlay = cv2.addWeighted(resized_unified, 0.5, transformed_img, 0.5, 0)\n",
    "    overlay = Image.fromarray(overlay)\n",
    "    # Add a name to the window\n",
    "    overlay.name = \"Transformed Overlay\"\n",
    "    overlay.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         584 function calls in 0.825 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 105 to 20 due to restriction <20>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.013    0.013    0.825    0.825 C:\\Users\\15406\\AppData\\Local\\Temp\\ipykernel_12712\\4190479871.py:2(transform_thin_plate_splines_old)\n",
      "        2    0.026    0.013    0.797    0.399 c:\\Users\\15406\\Coding-Projects\\Paper Chart Extraction\\Supplements\\.venv\\Lib\\site-packages\\scipy\\interpolate\\_rbf.py:280(__call__)\n",
      "        4    0.600    0.150    0.600    0.150 c:\\Users\\15406\\Coding-Projects\\Paper Chart Extraction\\Supplements\\.venv\\Lib\\site-packages\\scipy\\interpolate\\_rbf.py:169(_h_thin_plate)\n",
      "        2    0.000    0.000    0.162    0.081 c:\\Users\\15406\\Coding-Projects\\Paper Chart Extraction\\Supplements\\.venv\\Lib\\site-packages\\scipy\\interpolate\\_rbf.py:277(_call_norm)\n",
      "        2    0.000    0.000    0.162    0.081 c:\\Users\\15406\\Coding-Projects\\Paper Chart Extraction\\Supplements\\.venv\\Lib\\site-packages\\scipy\\spatial\\distance.py:2649(cdist)\n",
      "        2    0.161    0.081    0.161    0.081 {built-in method scipy.spatial._distance_pybind.cdist_euclidean}\n",
      "       10    0.005    0.001    0.005    0.001 {method 'flatten' of 'numpy.ndarray' objects}\n",
      "       24    0.005    0.000    0.005    0.000 {built-in method numpy.asarray}\n",
      "        1    0.000    0.000    0.005    0.005 c:\\Users\\15406\\Coding-Projects\\Paper Chart Extraction\\Supplements\\.venv\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:5077(meshgrid)\n",
      "        3    0.000    0.000    0.004    0.001 c:\\Users\\15406\\Coding-Projects\\Paper Chart Extraction\\Supplements\\.venv\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:5231(<genexpr>)\n",
      "        2    0.004    0.002    0.004    0.002 {method 'copy' of 'numpy.ndarray' objects}\n",
      "        2    0.000    0.000    0.004    0.002 c:\\Users\\15406\\Coding-Projects\\Paper Chart Extraction\\Supplements\\.venv\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:2250(clip)\n",
      "        4    0.000    0.000    0.004    0.001 c:\\Users\\15406\\Coding-Projects\\Paper Chart Extraction\\Supplements\\.venv\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:51(_wrapfunc)\n",
      "        2    0.000    0.000    0.004    0.002 {method 'clip' of 'numpy.ndarray' objects}\n",
      "        2    0.004    0.002    0.004    0.002 c:\\Users\\15406\\Coding-Projects\\Paper Chart Extraction\\Supplements\\.venv\\Lib\\site-packages\\numpy\\_core\\_methods.py:100(_clip)\n",
      "        1    0.003    0.003    0.003    0.003 {remap}\n",
      "        4    0.002    0.001    0.002    0.001 {method 'astype' of 'numpy.ndarray' objects}\n",
      "        2    0.000    0.000    0.001    0.000 c:\\Users\\15406\\Coding-Projects\\Paper Chart Extraction\\Supplements\\.venv\\Lib\\site-packages\\scipy\\interpolate\\_rbf.py:218(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\15406\\AppData\\Local\\Temp\\ipykernel_12712\\2105784755.py:34(__filter_by_RANSAC)\n",
      "        2    0.000    0.000    0.000    0.000 c:\\Users\\15406\\Coding-Projects\\Paper Chart Extraction\\Supplements\\.venv\\Lib\\site-packages\\scipy\\interpolate\\_rbf.py:270(A)\n",
      "\n",
      "\n",
      "peak memory: 333.93 MiB, increment: 161.16 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "# Runs the old version of the function\n",
    "for sheet, yolo_bbs in yolo_data.items():\n",
    "    if sheet != \"RC_0031_intraoperative.JPG\":\n",
    "        continue\n",
    "    # get path to current image\n",
    "    full_image_path = os.path.join(PATH_TO_REGISTERED_IMAGES, sheet)\n",
    "    image = cv2.imread(full_image_path)\n",
    "    resized_img = cv2.resize(image, (DESIRED_IMAGE_WIDTH, DESIRED_IMAGE_HEIGHT))\n",
    "\n",
    "    # Turn resized image to an Image and show it\n",
    "    resized_img_ = Image.fromarray(resized_img)\n",
    "    resized_img_.show()\n",
    "\n",
    "    # get the sheet's bounding boxes\n",
    "    sheet_bbs = [\n",
    "        BoundingBox.from_yolo(bb, DESIRED_IMAGE_WIDTH, DESIRED_IMAGE_HEIGHT)\n",
    "        for bb in yolo_bbs\n",
    "    ]\n",
    "\n",
    "    # Run the profiler\n",
    "    profiler = cProfile.Profile()\n",
    "    profiler.enable()\n",
    "    transformed_img_arr = transform_thin_plate_splines_old(resized_img, sheet_bbs, landmarks)\n",
    "    profiler.disable()\n",
    "\n",
    "    # Print stats sorted by cumulative time\n",
    "    stats = pstats.Stats(profiler).sort_stats(SortKey.CUMULATIVE)\n",
    "    stats.print_stats(20)  # Show top 20 functions by time\n",
    "    \n",
    "    transformed_img = Image.fromarray(transformed_img_arr)\n",
    "    transformed_img.show()\n",
    "\n",
    "    #Overlay this image with the original as a sanity check to make sure the transformation is correct\n",
    "    # Should used image from above as well as transformed_img_arr\n",
    "    transformed_img = cv2.cvtColor(transformed_img_arr, cv2.COLOR_BGR2RGB)\n",
    "    # Get data/unified_intraoperative_preoperative_flowsheet_v1_1_back.png\n",
    "    unified = cv2.imread(\"../../data/unified_intraoperative_preoperative_flowsheet_v1_1_front.png\")\n",
    "    resized_unified = cv2.resize(unified, (DESIRED_IMAGE_WIDTH, DESIRED_IMAGE_HEIGHT))\n",
    "    # Show original overlay\n",
    "    overlay = cv2.addWeighted(resized_unified, 0.5, resized_img, 0.5, 0)\n",
    "    overlay = Image.fromarray(overlay)\n",
    "    # Add a name to the window\n",
    "    overlay.name = \"Original Overlay\"\n",
    "    overlay.show()\n",
    "    overlay = cv2.addWeighted(resized_unified, 0.5, transformed_img, 0.5, 0)\n",
    "    overlay = Image.fromarray(overlay)\n",
    "    # Add a name to the window\n",
    "    overlay.name = \"Transformed Overlay\"\n",
    "    overlay.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
