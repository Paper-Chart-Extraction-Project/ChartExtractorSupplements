{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thin Plate Splines Transformations\n",
    "\n",
    "**Purpose:** The purpose of this experiment to implement thin plate spline transformations on images. The goal is to help normalize images of charts that have been folded or bent. TPS registration will be performed post-homography\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are Thin Plate Splines\n",
    "\n",
    "For our purpose, a thin plate spline transformation can be defined as follows:  \n",
    "Given a set of \"source\" points $P_s$ and a corresponding set of \"destination\" points $P_d$, the thin plate spline transformation is a function  \n",
    "$f_{tps}(p) | \\forall p_s \\in P_s, f_{tps}$ and $f$ is the function when \"bends\" all other points the least among all differentiable functions (meaning it minimizes an energy function).\n",
    "\n",
    "![thin_plate_spline_example](https://github.com/user-attachments/assets/9f269c79-6d5d-4090-988c-39ee9e928ff0)\n",
    "\n",
    "In this image there are two sets of points which form fish shapes. The red '+' points represent the destination points, and the green 'o' points represent the source points. On the right we see the thin plate spline deformation which makes all the green points exactly match all the red points, and we can also see a grid that shows where all other points on the plane will be mapped as well.\n",
    "\n",
    "## Benefits for Image Registration\n",
    "\n",
    "While the homography is a very reliable transformation, it is limited to purely linear transformations (ex: rotation, scaling, shear).  \n",
    "Very commonly, pages will be creased or folded, the edge of pages will curl inwards or outwards, or some cameras will cause barrel/pinhole distortions.  \n",
    "This leads to a whole subset of issues that cannot be corrected linearly, but still must be accounted for.\n",
    "\n",
    "![smaller_RC_0033_preoperative_postoperative](https://github.com/user-attachments/assets/f22374e1-75b4-4a07-816f-d3ad51e84921)\n",
    "An example of a paper which has been folded. and unfolded, causing non-linear distortions. This is a _very_ modest example. In practice, we have seen photographs of papers that are raised at least an inch off the table in certain areas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "from utils.annotations import BoundingBox\n",
    "from collections import Counter\n",
    "from PIL import Image\n",
    "from scipy.interpolate import Rbf\n",
    "\n",
    "from memory_profiler import profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data for testing:\n",
    "\n",
    "- \"intraop_document_landmarks.json\"\n",
    "  - Used for the destination points in the transformation. We are using the landmarks from the unified image\n",
    "  - Also has landmarks for each of the images. We currently are not using them\n",
    "- \"yolo_data.json\"\n",
    "  - Used for the source points in the transformation.\n",
    "  - May need to be replace with the landmarks from the other file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22 sheets in yolo_data.json\n"
     ]
    }
   ],
   "source": [
    "# Load yolo_data.json which will be used as src_bbs\n",
    "PATH_TO_YOLO_DATA = \"../../data/yolo_data.json\"\n",
    "PATH_TO_REGISTERED_IMAGES = \"../../data/registered_images\"\n",
    "\n",
    "with open(PATH_TO_YOLO_DATA) as json_file:\n",
    "    yolo_data = json.load(json_file)\n",
    "\n",
    "print(f\"Found {len(yolo_data)} sheets in yolo_data.json\")\n",
    "\n",
    "# load introp_document_landmarks.json which will be used as dst_points\n",
    "PATH_TO_LANDMARKS = \"../../data/intraop_document_landmarks.json\"\n",
    "\n",
    "DESIRED_IMAGE_WIDTH = 800\n",
    "DESIRED_IMAGE_HEIGHT = 600\n",
    "\n",
    "\n",
    "def label_studio_to_bboxes(path_to_json_data: Path) -> List[BoundingBox]:\n",
    "    \"\"\"\n",
    "    Convert the json data from label studio to a list of BoundingBox objects\n",
    "\n",
    "    Args:\n",
    "        path_to_json_data (Path): Path to the json data from label studio\n",
    "\n",
    "    Returns:\n",
    "        List[BoundingBox]: List of BoundingBox objects\n",
    "    \"\"\"\n",
    "    json_data: List[Dict] = json.loads(open(str(path_to_json_data)).read())\n",
    "    return {\n",
    "        sheet_data[\"data\"][\"image\"].split(\"-\")[-1]: [\n",
    "            BoundingBox(\n",
    "                category=label[\"value\"][\"rectanglelabels\"][0],\n",
    "                left=label[\"value\"][\"x\"] / 100 * DESIRED_IMAGE_WIDTH,\n",
    "                top=label[\"value\"][\"y\"] / 100 * DESIRED_IMAGE_HEIGHT,\n",
    "                right=(label[\"value\"][\"x\"] / 100 + label[\"value\"][\"width\"] / 100)\n",
    "                * DESIRED_IMAGE_WIDTH,\n",
    "                bottom=(label[\"value\"][\"y\"] / 100 + label[\"value\"][\"height\"] / 100)\n",
    "                * DESIRED_IMAGE_HEIGHT,\n",
    "            )\n",
    "            for label in sheet_data[\"annotations\"][0][\"result\"]\n",
    "        ]\n",
    "        for sheet_data in json_data\n",
    "    }\n",
    "\n",
    "\n",
    "landmark_location_data: Dict[str, List[BoundingBox]] = label_studio_to_bboxes(\n",
    "    PATH_TO_LANDMARKS\n",
    ")\n",
    "\n",
    "landmarks = landmark_location_data[\n",
    "    \"unified_intraoperative_preoperative_flowsheet_v1_1_front.png\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TPS Tranformation**\n",
    "Steps:\n",
    "\n",
    "1. Filter to keep only the relevant bounding boxes\n",
    "   - remove all bounding boxes from the source points that do not match a category in the destination points\n",
    "   - Find all of the duplicates in the source and destination points and remove them\n",
    "   - sort the source and destination points alphabetically via their category\n",
    "2. Get lists of the x and y coordinates for both the source and destination points\n",
    "   - Primary purpose is to enable the use of scipy's Rbf function\n",
    "   - We are using the top left corner of the bounding boxes\n",
    "3. Estimate the transformation\n",
    "   - Use the Rbf function to apply the TPS transformation\n",
    "4. Apply the transformation and Warp the image\n",
    "   - Create a grid from 0 to maximum value of the image\n",
    "   - Apply the transformation to the grids\n",
    "   - Ensure that the transformed points are within bounds\n",
    "   - Use those grids to warp the original image\n",
    "\n",
    "_Note:_ There are a lot of different outputs that are currently commented out that can be used for debugging purposes:\n",
    "\n",
    "- Print the lists of duplicate keys and the categories being used in the source and destination points\n",
    "- Plot of the source and destination points on the image\n",
    "- View the bounds of the transformed points\n",
    "- View the distribution of the transformed points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tps_transform(image: np.ndarray, src_bbs: List[BoundingBox], dst_bbs: List[BoundingBox], scale_factor: float = 0.25) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Perform a memory-efficient thin plate spline transformation by computing the warp field at low resolution.\n",
    "\n",
    "    Args:\n",
    "        image (np.ndarray): The image to be transformed.\n",
    "        src_bbs (List[BoundingBox]): List of source BoundingBox objects.\n",
    "        dst_bbs (List[BoundingBox]): List of destination BoundingBox objects.\n",
    "        scale_factor (float): Factor to downscale the image for computing warp (default: 0.25).\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The transformed image at original size.\n",
    "    \"\"\"\n",
    "\n",
    "    # Image dimensions\n",
    "    h, w = image.shape[:2]\n",
    "    small_h, small_w = int(h * scale_factor), int(w * scale_factor)\n",
    "\n",
    "    # Scale bounding boxes\n",
    "    def scale_bbs(bbs, factor):\n",
    "        return [\n",
    "            BoundingBox(\n",
    "                category=bb.category,\n",
    "                left=bb.left * factor,\n",
    "                top=bb.top * factor,\n",
    "                right=bb.right * factor,\n",
    "                bottom=bb.bottom * factor,\n",
    "            ) for bb in bbs\n",
    "        ]\n",
    "\n",
    "    scaled_src_bbs = scale_bbs(src_bbs, scale_factor)\n",
    "    scaled_dst_bbs = scale_bbs(dst_bbs, scale_factor)\n",
    "\n",
    "    # Remove duplicate category points\n",
    "    duplicate_cats = {k for k, v in Counter([bb.category for bb in scaled_src_bbs]).items() if v > 1}\n",
    "    duplicate_cats |= {k for k, v in Counter([bb.category for bb in scaled_dst_bbs]).items() if v > 1}\n",
    "\n",
    "    scaled_src_bbs = [bb for bb in scaled_src_bbs if bb.category not in duplicate_cats]\n",
    "    scaled_dst_bbs = [bb for bb in scaled_dst_bbs if bb.category not in duplicate_cats]\n",
    "\n",
    "    # Sort bounding boxes by category\n",
    "    scaled_src_bbs.sort(key=lambda bb: bb.category)\n",
    "    scaled_dst_bbs.sort(key=lambda bb: bb.category)\n",
    "\n",
    "    # Extract bounding box centers\n",
    "    def get_centers(bbs):\n",
    "        return np.array(\n",
    "            [[(bb.left + bb.right) / 2, (bb.top + bb.bottom) / 2] for bb in bbs], dtype=np.float32\n",
    "        )\n",
    "\n",
    "    src_points = get_centers(scaled_src_bbs)\n",
    "    dst_points = get_centers(scaled_dst_bbs)\n",
    "\n",
    "    # Apply RANSAC filtering\n",
    "    _, mask = cv2.findHomography(dst_points, src_points, method=cv2.RANSAC, ransacReprojThreshold=5.0)\n",
    "    inlier_mask = mask.ravel() == 1\n",
    "    filtered_src = src_points[inlier_mask]\n",
    "    filtered_dst = dst_points[inlier_mask]\n",
    "\n",
    "    if len(filtered_src) < 4:\n",
    "        return image  # Not enough inliers for TPS\n",
    "\n",
    "    # Apply Thin Plate Splines using RBF\n",
    "    rbf_x = Rbf(filtered_dst[:, 0], filtered_dst[:, 1], filtered_src[:, 0] - filtered_dst[:, 0], function=\"thin_plate\")\n",
    "    rbf_y = Rbf(filtered_dst[:, 0], filtered_dst[:, 1], filtered_src[:, 1] - filtered_dst[:, 1], function=\"thin_plate\")\n",
    "\n",
    "    # Generate a low-res grid for memory-efficient TPS\n",
    "    small_grid_x, small_grid_y = np.meshgrid(np.linspace(0, small_w - 1, small_w), np.linspace(0, small_h - 1, small_h))\n",
    "\n",
    "    # Compute displacement fields at low resolution\n",
    "    disp_x_small = rbf_x(small_grid_x, small_grid_y).astype(np.float32)\n",
    "    disp_y_small = rbf_y(small_grid_x, small_grid_y).astype(np.float32)\n",
    "\n",
    "    # Upscale displacement fields to full resolution\n",
    "    disp_x_large = cv2.resize(disp_x_small, (w, h), interpolation=cv2.INTER_CUBIC)\n",
    "    disp_y_large = cv2.resize(disp_y_small, (w, h), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    # Compute final absolute positions\n",
    "    grid_x, grid_y = np.meshgrid(np.arange(w), np.arange(h))\n",
    "    transformed_x = np.clip(grid_x + disp_x_large, 0, w - 1)\n",
    "    transformed_y = np.clip(grid_y + disp_y_large, 0, h - 1)\n",
    "\n",
    "    # Apply transformation to the original image\n",
    "    warped_large = cv2.remap(image, transformed_x.astype(np.float32), transformed_y.astype(np.float32), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    return warped_large\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304\n",
      "304\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmemit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfor sheet, yolo_bbs in yolo_data.items():\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    # get path to current image\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    full_image_path = os.path.join(PATH_TO_REGISTERED_IMAGES, sheet)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    image = cv2.imread(full_image_path)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    resized_img = cv2.resize(image, (DESIRED_IMAGE_WIDTH, DESIRED_IMAGE_HEIGHT))\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    # get the sheet\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43ms bounding boxes\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    sheet_bbs = [\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        BoundingBox.from_yolo(bb, DESIRED_IMAGE_WIDTH, DESIRED_IMAGE_HEIGHT)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        for bb in yolo_bbs\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    ]\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    print(len(sheet_bbs))\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    transformed_img = tps_transform(resized_img, sheet_bbs, landmarks)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    transformed_img = Image.fromarray(transformed_img)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    transformed_img.show()\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    # Show the image\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    cv2.imshow(\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m, resized_img)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    cv2.waitKey(0)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    cv2.destroyAllWindows()\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\15406\\Coding-Projects\\Paper Chart Extraction\\Supplements\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:2541\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[1;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[0;32m   2539\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[0;32m   2540\u001b[0m     args \u001b[38;5;241m=\u001b[39m (magic_arg_s, cell)\n\u001b[1;32m-> 2541\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2543\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[0;32m   2544\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[0;32m   2545\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[0;32m   2546\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\15406\\Coding-Projects\\Paper Chart Extraction\\Supplements\\.venv\\Lib\\site-packages\\memory_profiler.py:1113\u001b[0m, in \u001b[0;36mMemoryProfilerMagics.memit\u001b[1;34m(self, line, cell)\u001b[0m\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m counter \u001b[38;5;241m<\u001b[39m repeat:\n\u001b[0;32m   1112\u001b[0m     counter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1113\u001b[0m     tmp \u001b[38;5;241m=\u001b[39m \u001b[43mmemory_usage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_func_exec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mstmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshell\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muser_ns\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1114\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1115\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mmax_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1116\u001b[0m \u001b[43m                       \u001b[49m\u001b[43minclude_children\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_children\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1117\u001b[0m     mem_usage\u001b[38;5;241m.\u001b[39mappend(tmp)\n\u001b[0;32m   1119\u001b[0m result \u001b[38;5;241m=\u001b[39m MemitResult(mem_usage, baseline, repeat, timeout, interval,\n\u001b[0;32m   1120\u001b[0m                      include_children)\n",
      "File \u001b[1;32mc:\\Users\\15406\\Coding-Projects\\Paper Chart Extraction\\Supplements\\.venv\\Lib\\site-packages\\memory_profiler.py:379\u001b[0m, in \u001b[0;36mmemory_usage\u001b[1;34m(proc, interval, timeout, timestamps, include_children, multiprocess, max_usage, retval, stream, backend, max_iterations)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[38;5;66;03m# When there is an exception in the \"proc\" - the (spawned) monitoring processes don't get killed.\u001b[39;00m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;66;03m# Therefore, the whole process hangs indefinitely. Here, we are ensuring that the process gets killed!\u001b[39;00m\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 379\u001b[0m     returned \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    380\u001b[0m     parent_conn\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# finish timing\u001b[39;00m\n\u001b[0;32m    381\u001b[0m     ret \u001b[38;5;241m=\u001b[39m parent_conn\u001b[38;5;241m.\u001b[39mrecv()\n",
      "File \u001b[1;32mc:\\Users\\15406\\Coding-Projects\\Paper Chart Extraction\\Supplements\\.venv\\Lib\\site-packages\\memory_profiler.py:889\u001b[0m, in \u001b[0;36m_func_exec\u001b[1;34m(stmt, ns)\u001b[0m\n\u001b[0;32m    886\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_func_exec\u001b[39m(stmt, ns):\n\u001b[0;32m    887\u001b[0m     \u001b[38;5;66;03m# helper for magic_memit, just a function proxy for the exec\u001b[39;00m\n\u001b[0;32m    888\u001b[0m     \u001b[38;5;66;03m# statement\u001b[39;00m\n\u001b[1;32m--> 889\u001b[0m     \u001b[43mexec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mns\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<string>:18\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "for sheet, yolo_bbs in yolo_data.items():\n",
    "    # get path to current image\n",
    "    full_image_path = os.path.join(PATH_TO_REGISTERED_IMAGES, sheet)\n",
    "    image = cv2.imread(full_image_path)\n",
    "    resized_img = cv2.resize(image, (DESIRED_IMAGE_WIDTH, DESIRED_IMAGE_HEIGHT))\n",
    "    # get the sheet's bounding boxes\n",
    "    sheet_bbs = [\n",
    "        BoundingBox.from_yolo(bb, DESIRED_IMAGE_WIDTH, DESIRED_IMAGE_HEIGHT)\n",
    "        for bb in yolo_bbs\n",
    "    ]\n",
    "\n",
    "    print(len(sheet_bbs))\n",
    "    transformed_img = tps_transform(resized_img, sheet_bbs, landmarks)\n",
    "    transformed_img = Image.fromarray(transformed_img)\n",
    "    transformed_img.show()\n",
    "    # Show the image\n",
    "    cv2.imshow(\"image\", resized_img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tps_transform_ransac(image, src_bbs: List[BoundingBox], dst_bbs: List[BoundingBox]):\n",
    "    \"\"\"\n",
    "    Perform a thin plate spline transformation on the image using the src_bbs and dst_bbs, using RANSAC to filter out outliers.\n",
    "\n",
    "    Args:\n",
    "        image (np.ndarray): The image to be transformed\n",
    "        src_bbs (List[BoundingBox]): List of BoundingBox objects\n",
    "        dst_bbs (List[BoundingBox]): List of BoundingBox objects\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The transformed image\n",
    "    \"\"\"\n",
    "    # get the categories from dst_bbs\n",
    "    landmark_cats = [bb.category for bb in dst_bbs]\n",
    "    # remove all bbs in src that are not in those categories\n",
    "    src_bbs = [bb for bb in src_bbs if bb.category in landmark_cats]\n",
    "    # get list of duplicate keys\n",
    "    duplicate_count_src = dict(Counter([bb.category for bb in src_bbs]))\n",
    "    duplicates = [k for k, v in duplicate_count_src.items() if v > 1]\n",
    "    duplicate_count_dst = dict(Counter([bb.category for bb in dst_bbs]))\n",
    "    duplicates.extend([k for k, v in duplicate_count_dst.items() if v > 1])\n",
    "    duplicates = list(set(duplicates))\n",
    "    # print(duplicates)\n",
    "    # remove duplicates\n",
    "    src_bbs = [bb for bb in src_bbs if bb.category not in duplicates]\n",
    "    dst_bbs = [bb for bb in dst_bbs if bb.category not in duplicates]\n",
    "    # sort categories alphabetically\n",
    "    src_bbs = sorted(src_bbs, key=lambda bb: bb.category)\n",
    "    # print([bb.category for bb in src_bbs])\n",
    "    dst_bbs = sorted(dst_bbs, key=lambda bb: bb.category)\n",
    "    # print([bb.category for bb in dst_bbs])\n",
    "\n",
    "    src_bbs = np.array([[bb.left, bb.top] for bb in src_bbs], dtype=np.float32)\n",
    "    dst_bbs = np.array([[bb.left, bb.top] for bb in dst_bbs], dtype=np.float32)\n",
    "\n",
    "    _, mask = cv2.findHomography(\n",
    "        dst_bbs,\n",
    "        src_bbs,\n",
    "        method=cv2.RANSAC,\n",
    "        ransacReprojThreshold=10.0,\n",
    "        maxIters=5000,\n",
    "        confidence=0.99,\n",
    "    )\n",
    "    inlier_mask = mask.ravel() == 1\n",
    "\n",
    "    filtered_src = src_bbs[inlier_mask]\n",
    "    filtered_dst = dst_bbs[inlier_mask]\n",
    "\n",
    "    new_src_x, new_src_y = filtered_src[:, 0], filtered_src[:, 1]\n",
    "    new_dst_x, new_dst_y = filtered_dst[:, 0], filtered_dst[:, 1]\n",
    "\n",
    "    if len(new_src_x) < 4:\n",
    "        return image\n",
    "\n",
    "    # use RBF function to do the thin plate splines\n",
    "    rbf_x = Rbf(new_dst_x, new_dst_y, new_src_x, function=\"thin_plate\")\n",
    "    rbf_y = Rbf(new_dst_x, new_dst_y, new_src_y, function=\"thin_plate\")\n",
    "\n",
    "    # Alter the image according to the transformation\n",
    "    h, w, _ = image.shape\n",
    "    # create grid\n",
    "    x = np.linspace(0, w - 1, w)\n",
    "    y = np.linspace(0, h - 1, h)\n",
    "    grid_x, grid_y = np.meshgrid(x, y)\n",
    "\n",
    "    # apply the transformation\n",
    "    # reshape into grid\n",
    "    transformed_x = rbf_x(grid_x, grid_y).astype(np.float32)\n",
    "    transformed_y = rbf_y(grid_x, grid_y).astype(np.float32)\n",
    "\n",
    "    transformed_x = np.clip(transformed_x, 0, image.shape[1] - 1)\n",
    "    transformed_y = np.clip(transformed_y, 0, image.shape[0] - 1)\n",
    "\n",
    "    # warp the image\n",
    "    warp_img = cv2.remap(\n",
    "        image, transformed_x, transformed_y, interpolation=cv2.INTER_LINEAR\n",
    "    )\n",
    "\n",
    "    return warp_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\15406\\Coding-Projects\\Paper Chart Extraction\\Supplements\\.venv\\Lib\\site-packages\\PIL\\ImageFile.py:554\u001b[0m, in \u001b[0;36m_save\u001b[1;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 554\u001b[0m     fh \u001b[38;5;241m=\u001b[39m \u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfileno\u001b[49m()\n\u001b[0;32m    555\u001b[0m     fp\u001b[38;5;241m.\u001b[39mflush()\n",
      "\u001b[1;31mAttributeError\u001b[0m: '_idat' object has no attribute 'fileno'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m transformed_img \u001b[38;5;241m=\u001b[39m tps_transform_ransac(resized_img, sheet_bbs, landmarks)\n\u001b[0;32m     12\u001b[0m transformed_img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(transformed_img)\n\u001b[1;32m---> 13\u001b[0m \u001b[43mtransformed_img\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\15406\\Coding-Projects\\Paper Chart Extraction\\Supplements\\.venv\\Lib\\site-packages\\PIL\\Image.py:2660\u001b[0m, in \u001b[0;36mImage.show\u001b[1;34m(self, title)\u001b[0m\n\u001b[0;32m   2640\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshow\u001b[39m(\u001b[38;5;28mself\u001b[39m, title: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2641\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2642\u001b[0m \u001b[38;5;124;03m    Displays this image. This method is mainly intended for debugging purposes.\u001b[39;00m\n\u001b[0;32m   2643\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2657\u001b[0m \u001b[38;5;124;03m    :param title: Optional title to use for the image window, where possible.\u001b[39;00m\n\u001b[0;32m   2658\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2660\u001b[0m     \u001b[43m_show\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtitle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtitle\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\15406\\Coding-Projects\\Paper Chart Extraction\\Supplements\\.venv\\Lib\\site-packages\\PIL\\Image.py:3775\u001b[0m, in \u001b[0;36m_show\u001b[1;34m(image, **options)\u001b[0m\n\u001b[0;32m   3772\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_show\u001b[39m(image: Image, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3773\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageShow\n\u001b[1;32m-> 3775\u001b[0m     \u001b[43mImageShow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\15406\\Coding-Projects\\Paper Chart Extraction\\Supplements\\.venv\\Lib\\site-packages\\PIL\\ImageShow.py:61\u001b[0m, in \u001b[0;36mshow\u001b[1;34m(image, title, **options)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;124;03mDisplay a given image.\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;124;03m:returns: ``True`` if a suitable viewer was found, ``False`` otherwise.\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m viewer \u001b[38;5;129;01min\u001b[39;00m _viewers:\n\u001b[1;32m---> 61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mviewer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtitle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtitle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     62\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\15406\\Coding-Projects\\Paper Chart Extraction\\Supplements\\.venv\\Lib\\site-packages\\PIL\\ImageShow.py:85\u001b[0m, in \u001b[0;36mViewer.show\u001b[1;34m(self, image, **options)\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m image\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m!=\u001b[39m base:\n\u001b[0;32m     83\u001b[0m         image \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mconvert(base)\n\u001b[1;32m---> 85\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\15406\\Coding-Projects\\Paper Chart Extraction\\Supplements\\.venv\\Lib\\site-packages\\PIL\\ImageShow.py:112\u001b[0m, in \u001b[0;36mViewer.show_image\u001b[1;34m(self, image, **options)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshow_image\u001b[39m(\u001b[38;5;28mself\u001b[39m, image: Image\u001b[38;5;241m.\u001b[39mImage, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[0;32m    111\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Display the given image.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshow_file(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[1;32mc:\\Users\\15406\\Coding-Projects\\Paper Chart Extraction\\Supplements\\.venv\\Lib\\site-packages\\PIL\\ImageShow.py:108\u001b[0m, in \u001b[0;36mViewer.save_image\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_image\u001b[39m(\u001b[38;5;28mself\u001b[39m, image: Image\u001b[38;5;241m.\u001b[39mImage) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m    107\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Save to temporary file and return filename.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dump\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\15406\\Coding-Projects\\Paper Chart Extraction\\Supplements\\.venv\\Lib\\site-packages\\PIL\\Image.py:678\u001b[0m, in \u001b[0;36mImage._dump\u001b[1;34m(self, file, format, **options)\u001b[0m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mim\u001b[38;5;241m.\u001b[39msave_ppm(filename)\n\u001b[0;32m    677\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 678\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m filename\n",
      "File \u001b[1;32mc:\\Users\\15406\\Coding-Projects\\Paper Chart Extraction\\Supplements\\.venv\\Lib\\site-packages\\PIL\\Image.py:2605\u001b[0m, in \u001b[0;36mImage.save\u001b[1;34m(self, fp, format, **params)\u001b[0m\n\u001b[0;32m   2602\u001b[0m     fp \u001b[38;5;241m=\u001b[39m cast(IO[\u001b[38;5;28mbytes\u001b[39m], fp)\n\u001b[0;32m   2604\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2605\u001b[0m     \u001b[43msave_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2606\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   2607\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m open_fp:\n",
      "File \u001b[1;32mc:\\Users\\15406\\Coding-Projects\\Paper Chart Extraction\\Supplements\\.venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:1297\u001b[0m, in \u001b[0;36m_save_all\u001b[1;34m(im, fp, filename)\u001b[0m\n\u001b[0;32m   1296\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_save_all\u001b[39m(im: Image\u001b[38;5;241m.\u001b[39mImage, fp: IO[\u001b[38;5;28mbytes\u001b[39m], filename: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mbytes\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1297\u001b[0m     \u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_all\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\15406\\Coding-Projects\\Paper Chart Extraction\\Supplements\\.venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:1488\u001b[0m, in \u001b[0;36m_save\u001b[1;34m(im, fp, filename, chunk, save_all)\u001b[0m\n\u001b[0;32m   1484\u001b[0m     single_im \u001b[38;5;241m=\u001b[39m _write_multiple_frames(\n\u001b[0;32m   1485\u001b[0m         im, fp, chunk, mode, rawmode, default_image, append_images\n\u001b[0;32m   1486\u001b[0m     )\n\u001b[0;32m   1487\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m single_im:\n\u001b[1;32m-> 1488\u001b[0m     \u001b[43mImageFile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1489\u001b[0m \u001b[43m        \u001b[49m\u001b[43msingle_im\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mIO\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mbytes\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_idat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1491\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mImageFile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Tile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mzip\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msingle_im\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrawmode\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1492\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1494\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info:\n\u001b[0;32m   1495\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m info_chunk \u001b[38;5;129;01min\u001b[39;00m info\u001b[38;5;241m.\u001b[39mchunks:\n",
      "File \u001b[1;32mc:\\Users\\15406\\Coding-Projects\\Paper Chart Extraction\\Supplements\\.venv\\Lib\\site-packages\\PIL\\ImageFile.py:558\u001b[0m, in \u001b[0;36m_save\u001b[1;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[0;32m    556\u001b[0m     _encode_tile(im, fp, tile, bufsize, fh)\n\u001b[0;32m    557\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, io\u001b[38;5;241m.\u001b[39mUnsupportedOperation) \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m--> 558\u001b[0m     \u001b[43m_encode_tile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbufsize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflush\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    560\u001b[0m     fp\u001b[38;5;241m.\u001b[39mflush()\n",
      "File \u001b[1;32mc:\\Users\\15406\\Coding-Projects\\Paper Chart Extraction\\Supplements\\.venv\\Lib\\site-packages\\PIL\\ImageFile.py:584\u001b[0m, in \u001b[0;36m_encode_tile\u001b[1;34m(im, fp, tile, bufsize, fh, exc)\u001b[0m\n\u001b[0;32m    581\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exc:\n\u001b[0;32m    582\u001b[0m     \u001b[38;5;66;03m# compress to Python file-compatible object\u001b[39;00m\n\u001b[0;32m    583\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 584\u001b[0m         errcode, data \u001b[38;5;241m=\u001b[39m \u001b[43mencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbufsize\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m    585\u001b[0m         fp\u001b[38;5;241m.\u001b[39mwrite(data)\n\u001b[0;32m    586\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m errcode:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for sheet, yolo_bbs in yolo_data.items():\n",
    "    # get path to current image\n",
    "    full_image_path = os.path.join(PATH_TO_REGISTERED_IMAGES, sheet)\n",
    "    image = cv2.imread(full_image_path)\n",
    "    resized_img = cv2.resize(image, (DESIRED_IMAGE_WIDTH, DESIRED_IMAGE_HEIGHT))\n",
    "    # get the sheet's bounding boxes\n",
    "    sheet_bbs = [\n",
    "        BoundingBox.from_yolo(bb, DESIRED_IMAGE_WIDTH, DESIRED_IMAGE_HEIGHT)\n",
    "        for bb in yolo_bbs\n",
    "    ]\n",
    "    transformed_img = tps_transform_ransac(resized_img, sheet_bbs, landmarks)\n",
    "    transformed_img = Image.fromarray(transformed_img)\n",
    "    transformed_img.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging these two methods and priming for placing into extractor\n",
    "\n",
    "I'm going to create private functions that do RANSAC and distance measurments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with turning Hannah's code into a function\n",
    "def __filter_by_distance(\n",
    "    src_bbs: List[BoundingBox],\n",
    "    dst_bbs: List[BoundingBox],\n",
    "    threshold: float,\n",
    ") -> Tuple[List[BoundingBox], List[BoundingBox]]:\n",
    "    \"\"\"\n",
    "    Filter out source and destination points that have a distance greater than the threshold.\n",
    "    Large transformations are likely to be outliers and erroneous. We only expect small tweaks via the thin plate spline transformation.\n",
    "    Homography should already be completed prior to TPS.\n",
    "\n",
    "    Args:\n",
    "        src_bbs (List[BoundingBox]): The source points\n",
    "        dst_bbs (List[BoundingBox]): The destination points\n",
    "        threshold (float): The threshold distance\n",
    "\n",
    "    Returns:\n",
    "        Tuple[List[BoundingBox], List[BoundingBox]]: The filtered source and destination points\n",
    "\n",
    "    \"\"\"\n",
    "    filtered_points = [\n",
    "        (src_bb, dst_bb)\n",
    "        for src_bb, dst_bb in zip(src_bbs, dst_bbs)\n",
    "        if abs(src_bb.top - dst_bb.top) < threshold\n",
    "        and abs(src_bb.left - dst_bb.left) < threshold\n",
    "    ]\n",
    "\n",
    "    new_src_bbs, new_dst_bbs = zip(*filtered_points) if filtered_points else ([], [])\n",
    "\n",
    "    return list(new_src_bbs), list(new_dst_bbs)\n",
    "\n",
    "\n",
    "# Now we can turn Matt's RANSAC code into a function\n",
    "def __filter_by_RANSAC(\n",
    "    src_bbs: List[BoundingBox],\n",
    "    dst_bbs: List[BoundingBox],\n",
    "    threshold: float,\n",
    "    max_iters: int = 5000,\n",
    "    confidence_limit: float = 0.99,\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Filter out source and destination points that are not inliers according to RANSAC\n",
    "\n",
    "    Args:\n",
    "        src_bbs (np.ndarray): The source points\n",
    "        dst_bbs (np.ndarray): The destination points\n",
    "        threshold (float): The threshold distance\n",
    "        max_iters (int, optional): The maximum number of iterations for RANSAC. Defaults to 5000.\n",
    "        confidence_limit (float, optional): The confidence limit for RANSAC. Defaults to 0.99.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]: The filtered source and destination points as numpy arrays in this order (src_x, src_y, dst_x, dst_y)\n",
    "    \"\"\"\n",
    "    # Turn the BoundingBox objects into numpy arrays of coordinates\n",
    "    src_points = np.array([[bb.left, bb.top] for bb in src_bbs], dtype=np.float32)\n",
    "    dst_points = np.array([[bb.left, bb.top] for bb in dst_bbs], dtype=np.float32)\n",
    "\n",
    "    # Complete RANSAC\n",
    "    _, mask = cv2.findHomography(\n",
    "        dst_points,\n",
    "        src_points,\n",
    "        method=cv2.RANSAC,\n",
    "        ransacReprojThreshold=threshold,\n",
    "        maxIters=max_iters,\n",
    "        confidence=confidence_limit,\n",
    "    )\n",
    "    inlier_mask = mask.ravel() == 1\n",
    "\n",
    "    # Apply the mask to the source and destination points\n",
    "    filtered_src = src_points[inlier_mask]\n",
    "    filtered_dst = dst_points[inlier_mask]\n",
    "\n",
    "    # Get the x and y coordinates of the filtered points\n",
    "    src_x, src_y = filtered_src[:, 0], filtered_src[:, 1]\n",
    "    dst_x, dst_y = filtered_dst[:, 0], filtered_dst[:, 1]\n",
    "\n",
    "    return src_x, src_y, dst_x, dst_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_thin_plate_splines(\n",
    "    image: np.ndarray,\n",
    "    src_bbs: List[BoundingBox],\n",
    "    dst_bbs: List[BoundingBox],\n",
    "    threshold: float = 10.0,\n",
    "    downscale_factor: float = 0.25,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Perform a memory-efficient thin plate spline transformation.\n",
    "    \"\"\"\n",
    "    # Image dimensions\n",
    "    h, w = image.shape[:2]\n",
    "    small_h, small_w = int(h * downscale_factor), int(w * downscale_factor)\n",
    "\n",
    "    # Scale down image first to save memory\n",
    "    small_image = cv2.resize(image, (small_w, small_h))\n",
    "\n",
    "    # Process at low resolution\n",
    "    def scale_bbs(bbs, factor):\n",
    "        return [\n",
    "            BoundingBox(\n",
    "                category=bb.category,\n",
    "                left=bb.left * factor,\n",
    "                top=bb.top * factor,\n",
    "                right=bb.right * factor,\n",
    "                bottom=bb.bottom * factor,\n",
    "            ) for bb in bbs\n",
    "        ]\n",
    "\n",
    "    # Scale bounding boxes\n",
    "    scaled_src_bbs = scale_bbs(src_bbs, downscale_factor)\n",
    "    scaled_dst_bbs = scale_bbs(dst_bbs, downscale_factor)\n",
    "\n",
    "    # Remove duplicates and sort\n",
    "    duplicate_cats = {k for k, v in Counter([bb.category for bb in scaled_src_bbs]).items() if v > 1}\n",
    "    duplicate_cats |= {k for k, v in Counter([bb.category for bb in scaled_dst_bbs]).items() if v > 1}\n",
    "    \n",
    "    scaled_src_bbs = [bb for bb in scaled_src_bbs if bb.category not in duplicate_cats]\n",
    "    scaled_dst_bbs = [bb for bb in scaled_dst_bbs if bb.category not in duplicate_cats]\n",
    "    \n",
    "    scaled_src_bbs.sort(key=lambda bb: bb.category)\n",
    "    scaled_dst_bbs.sort(key=lambda bb: bb.category)\n",
    "\n",
    "    # Get center points\n",
    "    src_points = np.array([[\n",
    "        (bb.left + bb.right) / 2, \n",
    "        (bb.top + bb.bottom) / 2\n",
    "    ] for bb in scaled_src_bbs], dtype=np.float32)\n",
    "    \n",
    "    dst_points = np.array([[\n",
    "        (bb.left + bb.right) / 2, \n",
    "        (bb.top + bb.bottom) / 2\n",
    "    ] for bb in scaled_dst_bbs], dtype=np.float32)\n",
    "\n",
    "    if len(src_points) < 4:\n",
    "        return image\n",
    "\n",
    "    # Calculate displacement field\n",
    "    rbf_x = Rbf(\n",
    "        dst_points[:, 0], dst_points[:, 1],\n",
    "        src_points[:, 0] - dst_points[:, 0],\n",
    "        function='thin_plate'\n",
    "    )\n",
    "    rbf_y = Rbf(\n",
    "        dst_points[:, 0], dst_points[:, 1],\n",
    "        src_points[:, 1] - dst_points[:, 1],\n",
    "        function='thin_plate'\n",
    "    )\n",
    "\n",
    "    # Create small grid\n",
    "    y, x = np.mgrid[0:small_h, 0:small_w].astype(np.float32)\n",
    "    \n",
    "    # Calculate displacements\n",
    "    dx = rbf_x(x, y).astype(np.float32)\n",
    "    dy = rbf_y(x, y).astype(np.float32)\n",
    "\n",
    "    # Add displacements to get final coordinates\n",
    "    map_x = (x + dx)\n",
    "    map_y = (y + dy)\n",
    "\n",
    "    # Scale back to original resolution\n",
    "    map_x = cv2.resize(map_x, (w, h)) * (1/downscale_factor)\n",
    "    map_y = cv2.resize(map_y, (w, h)) * (1/downscale_factor)\n",
    "\n",
    "    # Ensure coordinates are within bounds\n",
    "    map_x = np.clip(map_x, 0, w - 1)\n",
    "    map_y = np.clip(map_y, 0, h - 1)\n",
    "\n",
    "    # Apply transformation\n",
    "    warped = cv2.remap(\n",
    "        image,\n",
    "        map_x.astype(np.float32),\n",
    "        map_y.astype(np.float32),\n",
    "        interpolation=cv2.INTER_LINEAR,\n",
    "        borderMode=cv2.BORDER_REFLECT\n",
    "    )\n",
    "\n",
    "    return warped\n",
    "\n",
    "# Function to visualize the transformation\n",
    "def visualize_transformation(image, transformed_image):\n",
    "    cv2.imshow(\"Original Image\", image)\n",
    "    cv2.imshow(\"Transformed Image\", transformed_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 241.33 MiB, increment: 45.27 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "for sheet, yolo_bbs in yolo_data.items():\n",
    "    if sheet != \"RC_0031_intraoperative.JPG\":\n",
    "        continue\n",
    "    # get path to current image\n",
    "    full_image_path = os.path.join(PATH_TO_REGISTERED_IMAGES, sheet)\n",
    "    image = cv2.imread(full_image_path)\n",
    "    resized_img = cv2.resize(image, (DESIRED_IMAGE_WIDTH, DESIRED_IMAGE_HEIGHT))\n",
    "    # get the sheet's bounding boxes\n",
    "    sheet_bbs = [\n",
    "        BoundingBox.from_yolo(bb, DESIRED_IMAGE_WIDTH, DESIRED_IMAGE_HEIGHT)\n",
    "        for bb in yolo_bbs\n",
    "    ]\n",
    "    transformed_img_arr = transform_thin_plate_splines(resized_img, sheet_bbs, landmarks)\n",
    "    transformed_img = Image.fromarray(transformed_img_arr)\n",
    "    transformed_img.show()\n",
    "\n",
    "    #Overlay this image with the original as a sanity check to make sure the transformation is correct\n",
    "    # Should used image from above as well as transformed_img_arr\n",
    "    transformed_img = cv2.cvtColor(transformed_img_arr, cv2.COLOR_BGR2RGB)\n",
    "    # Get data/unified_intraoperative_preoperative_flowsheet_v1_1_back.png\n",
    "    unified = cv2.imread(\"../../data/unified_intraoperative_preoperative_flowsheet_v1_1_front.png\")\n",
    "    resized_unified = cv2.resize(unified, (DESIRED_IMAGE_WIDTH, DESIRED_IMAGE_HEIGHT))\n",
    "    # Show original overlay\n",
    "    overlay = cv2.addWeighted(resized_unified, 0.5, resized_img, 0.5, 0)\n",
    "    overlay = Image.fromarray(overlay)\n",
    "    # Add a name to the window\n",
    "    overlay.name = \"Original Overlay\"\n",
    "    overlay.show()\n",
    "    overlay = cv2.addWeighted(resized_unified, 0.5, transformed_img, 0.5, 0)\n",
    "    overlay = Image.fromarray(overlay)\n",
    "    # Add a name to the window\n",
    "    overlay.name = \"Transformed Overlay\"\n",
    "    overlay.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
