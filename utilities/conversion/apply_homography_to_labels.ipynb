{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b9d8dbd-5c0d-44c4-8054-ceb6d1f130fb",
   "metadata": {},
   "source": [
    "# Apply Homography to Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f322da5-10f8-49ee-a81a-5edc7bac12cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(\"..\", \"..\", \"..\", \"ChartExtractor\", \"src\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95997450-a2a0-4035-b040-3c8fb532836b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "from PIL import Image, ImageDraw\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "from tqdm import tqdm\n",
    "from utilities.annotations import BoundingBox, Point\n",
    "from utilities.image_conversion import pil_to_cv2, cv2_to_pil\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "820c4efa-bb9c-489c-9e44-07417836f3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import attrgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ca02ed3-a7fc-44ea-9f47-2c3b90a0ea48",
   "metadata": {},
   "outputs": [],
   "source": [
    "Point.__repr__ = lambda self: f\"Point({self.x}, {self.y})\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfd5339-e298-4223-a19f-94203044e543",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd0d783-7093-4e21-9907-fa112f6deb57",
   "metadata": {},
   "source": [
    "## 1 - Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd2294bd-3749-4872-b7e8-918218191c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_studio_to_bboxes(path_to_json_data: Path) -> List[BoundingBox]:\n",
    "    \"\"\"Loads data from LabelStudio's json format into BoundingBoxes.\"\"\"\n",
    "    json_data: List[Dict] = json.loads(open(str(path_to_json_data)).read())\n",
    "    return {\n",
    "        sheet_data['data']['image'].split(\"-\")[-1]:[\n",
    "            BoundingBox(\n",
    "                category=label['value']['rectanglelabels'][0],\n",
    "                left=label['value']['x']/100,\n",
    "                top=label['value']['y']/100,\n",
    "                right=label['value']['x']/100+label['value']['width']/100,\n",
    "                bottom=label['value']['y']/100+label['value']['height']/100,\n",
    "            )\n",
    "            for label in sheet_data['annotations'][0]['result']\n",
    "        ]\n",
    "        for sheet_data in json_data\n",
    "    }\n",
    "\n",
    "\n",
    "data_path: Path = Path(\"..\")/\"..\"/\"data\"\n",
    "landmark_location_data: Dict[str, List[BoundingBox]] = label_studio_to_bboxes(data_path/\"intraop_document_landmarks.json\")\n",
    "checkbox_location_data: Dict[str, List[BoundingBox]] = label_studio_to_bboxes(data_path/\"intraop_checkbox_names.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c169a1f4-dc7f-4242-b8a4-bb5062fa6cdc",
   "metadata": {},
   "source": [
    "This is a slightly different version of the homography function from the main program. The only thing it changes is to return the homography matrix along with the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a24eb52-c5f0-4c69-972f-6193117efe19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def homography_transform(\n",
    "    src_image: Image.Image,\n",
    "    src_points: List[Tuple[float, float]],\n",
    "    dest_points: List[Tuple[float, float]],\n",
    "    original_image_size: Tuple[float, float] = (3300, 2250),\n",
    ") -> Tuple[List[List[float]], Image.Image]:\n",
    "    \"\"\"Performs homography transformation on an image.\n",
    "\n",
    "    This function transforms an image (src_image) based on corresponding points\n",
    "    between the source and destination images. It calculates the homography matrix\n",
    "    and uses it to warp the source image to the perspective of the destination points.\n",
    "\n",
    "    Args:\n",
    "        src_image (Image.Image):\n",
    "            A PIL image object representing the source image.\n",
    "        src_points (List[Tuple[int, int]]):\n",
    "            A list of tuples (x, y) representing points in the source image that correspond\n",
    "            to points in the destination image.\n",
    "        dest_points (List[Tuple[int, int]]):\n",
    "            A list of tuples (x, y) representing points in the destination image that points\n",
    "            in the source image correspond to (where the source image should be warped to).\n",
    "        original_image_size (Tuple[float, float]):\n",
    "            A tuple (width, height) representing the size of the control image.\n",
    "            Defaults to (3300, 2250).\n",
    "\n",
    "    Returns:\n",
    "        A PIL image object representing the transformed source image.\n",
    "\n",
    "    Raises:\n",
    "        ValueError:\n",
    "            If the length of src_points and dest_points don't match (must have the same\n",
    "            number of corresponding points), or if there are less than 4 points.\n",
    "    \"\"\"\n",
    "    src_points: np.ndarray = np.array(src_points)\n",
    "    dest_points: np.ndarray = np.array(dest_points)\n",
    "\n",
    "    if len(src_points) != len(dest_points):\n",
    "        raise ValueError(\n",
    "            \"Source and destination points must have the same number of elements.\"\n",
    "        )\n",
    "    if len(src_points) < 4 or len(dest_points) < 4:\n",
    "        raise ValueError(\"Must have 4 or more points to compute the homography.\")\n",
    "\n",
    "    src_image = pil_to_cv2(src_image)\n",
    "    h, _ = cv2.findHomography(src_points, dest_points)\n",
    "    dest_image = cv2.warpPerspective(src_image, h, original_image_size)\n",
    "    return h, cv2_to_pil(dest_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36bfc243-75e8-4aff-ba61-5a92a06ba7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corresponding_points(bboxes, imsize) -> List[Tuple[float, float]]:\n",
    "    \"\"\"Gets and sorts the points used for the homography from all the bounding boxes that are labeled.\"\"\"\n",
    "    categories_to_get = ['anesthesia_start', 'lateral', 'safety_checklist', 'units']\n",
    "    if not all([c in [bb.category for bb in bboxes] for c in categories_to_get]):\n",
    "        raise ValueError(f\"Necessary labels not found: {categories_to_get}\")\n",
    "    \n",
    "    points = list(map(\n",
    "        attrgetter('center'),\n",
    "        sorted(\n",
    "            list(filter(lambda bb: bb.category in categories_to_get, bboxes)), \n",
    "            key=lambda bb: bb.category\n",
    "        )\n",
    "    ))\n",
    "    return [(p[0]*imsize[0], p[1]*imsize[1]) for p in points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a18e97c6-e438-461a-a701-2bf320da275f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'h' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 26\u001b[0m\n\u001b[0;32m     22\u001b[0m remap_all_bboxes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m bboxes, h: [remap_bbox(bb, h) \u001b[38;5;28;01mfor\u001b[39;00m bb \u001b[38;5;129;01min\u001b[39;00m bboxes]\n\u001b[0;32m     25\u001b[0m locations \u001b[38;5;241m=\u001b[39m landmark_location_data[sheet]\n\u001b[1;32m---> 26\u001b[0m remapped_locations \u001b[38;5;241m=\u001b[39m remap_all_bboxes(locations, \u001b[43mh\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'h' is not defined"
     ]
    }
   ],
   "source": [
    "remap_point = lambda p, h: cv2.perspectiveTransform(np.array(p, dtype=np.float32).reshape(-1, 1, 2), h).tolist()[0][0]\n",
    "\n",
    "\n",
    "def remap_bbox(\n",
    "    bbox: BoundingBox, \n",
    "    h, \n",
    "    original_width:int=4032, \n",
    "    original_height:int=3024,\n",
    "    new_width:int=3300,\n",
    "    new_height:int=2250,\n",
    ") -> BoundingBox:\n",
    "    \"\"\"Maps boundingboxes to a new space using the homography matrix.\n",
    "    \n",
    "    Given a bounding box, homography matrix, and the image sizes of the original \n",
    "    and destination (new) image, this function returns a remapped bounding box.\n",
    "    \"\"\"\n",
    "    new_left, new_top = remap_point((bbox.left*original_width, bbox.top*original_height), h)\n",
    "    new_right, new_bottom = remap_point((bbox.right*original_width, bbox.bottom*original_height), h)\n",
    "    return BoundingBox(bbox.category, new_left/new_width, new_top/new_height, new_right/new_width, new_bottom/new_height)\n",
    "\n",
    "\n",
    "remap_all_bboxes = lambda bboxes, h: [remap_bbox(bb, h) for bb in bboxes]\n",
    "\n",
    "\n",
    "locations = landmark_location_data[sheet]\n",
    "remapped_locations = remap_all_bboxes(locations, h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2414bd30-4ba1-490e-b3cd-4aeedf9e0397",
   "metadata": {},
   "source": [
    "Get landmarks that show up only once."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990d45a9-9aac-4765-99f1-50a0d44447b7",
   "metadata": {},
   "source": [
    "Check labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fd84989-134e-441f-a7ae-b86cc8e61ae4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transformed_img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;28mstr\u001b[39m(data_path\u001b[38;5;241m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchart_images\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m/\u001b[39msheet))\n\u001b[0;32m      5\u001b[0m original_width, original_height \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39msize\n\u001b[1;32m----> 6\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mtransformed_img\u001b[49m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m      7\u001b[0m width, height \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39msize\n\u001b[0;32m      8\u001b[0m draw \u001b[38;5;241m=\u001b[39m ImageDraw\u001b[38;5;241m.\u001b[39mDraw(img)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'transformed_img' is not defined"
     ]
    }
   ],
   "source": [
    "generate_color = lambda: \"#%06x\" % random.randint(0, 0xFFFFFF)\n",
    "\n",
    "sheet = \"RC_0001_intraoperative.JPG\"\n",
    "img = Image.open(str(data_path/\"chart_images\"/sheet))\n",
    "original_width, original_height = img.size\n",
    "img = transformed_img.copy()\n",
    "width, height = img.size\n",
    "draw = ImageDraw.Draw(img)\n",
    "\n",
    "for bounding_box in remapped_locations:\n",
    "    box = [\n",
    "        bounding_box.left*width,\n",
    "        bounding_box.top*height,\n",
    "        bounding_box.right*width,\n",
    "        bounding_box.bottom*height,\n",
    "    ]\n",
    "    draw.rectangle(box, outline=generate_color(), width=3)\n",
    "img.resize((800, 600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02674b37-4648-46e5-b6fd-ec681e7664dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump your BoundingBoxes to the format of your choosing here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
